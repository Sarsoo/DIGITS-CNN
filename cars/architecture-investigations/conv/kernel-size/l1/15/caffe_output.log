I0422 00:46:12.314806 16011 upgrade_proto.cpp:1082] Attempting to upgrade input file specified using deprecated 'solver_type' field (enum)': /mnt/bigdisk/DIGITS-MAN-3/digits/jobs/20210421-230741-dbb0/solver.prototxt
I0422 00:46:12.315019 16011 upgrade_proto.cpp:1089] Successfully upgraded file specified using deprecated 'solver_type' field (enum) to 'type' field (string).
W0422 00:46:12.315028 16011 upgrade_proto.cpp:1091] Note that future Caffe releases will only support 'type' field (string) for a solver's type.
I0422 00:46:12.315115 16011 caffe.cpp:218] Using GPUs 0
I0422 00:46:12.332890 16011 caffe.cpp:223] GPU 0: GeForce GTX 1080 Ti
I0422 00:46:12.696630 16011 solver.cpp:44] Initializing solver from parameters:
test_iter: 51
test_interval: 102
base_lr: 0.01
display: 12
max_iter: 10200
lr_policy: "exp"
gamma: 0.99980193
momentum: 0.9
weight_decay: 0.0001
snapshot: 102
snapshot_prefix: "snapshot"
solver_mode: GPU
device_id: 0
net: "train_val.prototxt"
train_state {
level: 0
stage: ""
}
type: "SGD"
I0422 00:46:13.014164 16011 solver.cpp:87] Creating training net from net file: train_val.prototxt
I0422 00:46:13.014804 16011 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer val-data
I0422 00:46:13.014819 16011 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0422 00:46:13.014966 16011 net.cpp:51] Initializing net from parameters:
state {
phase: TRAIN
level: 0
stage: ""
}
layer {
name: "train-data"
type: "Data"
top: "data"
top: "label"
include {
phase: TRAIN
}
transform_param {
mirror: true
crop_size: 227
mean_file: "/mnt/bigdisk/DIGITS-MAN-3/digits/jobs/20210421-230320-902c/mean.binaryproto"
}
data_param {
source: "/mnt/bigdisk/DIGITS-MAN-3/digits/jobs/20210421-230320-902c/train_db"
batch_size: 128
backend: LMDB
}
}
layer {
name: "conv1"
type: "Convolution"
bottom: "data"
top: "conv1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 15
stride: 4
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu1"
type: "ReLU"
bottom: "conv1"
top: "conv1"
}
layer {
name: "norm1"
type: "LRN"
bottom: "conv1"
top: "norm1"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool1"
type: "Pooling"
bottom: "norm1"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv2"
type: "Convolution"
bottom: "pool1"
top: "conv2"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 2
kernel_size: 5
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu2"
type: "ReLU"
bottom: "conv2"
top: "conv2"
}
layer {
name: "norm2"
type: "LRN"
bottom: "conv2"
top: "norm2"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool2"
type: "Pooling"
bottom: "norm2"
top: "pool2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv3"
type: "Convolution"
bottom: "pool2"
top: "conv3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu3"
type: "ReLU"
bottom: "conv3"
top: "conv3"
}
layer {
name: "conv4"
type: "Convolution"
bottom: "conv3"
top: "conv4"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu4"
type: "ReLU"
bottom: "conv4"
top: "conv4"
}
layer {
name: "conv5"
type: "Convolution"
bottom: "conv4"
top: "conv5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu5"
type: "ReLU"
bottom: "conv5"
top: "conv5"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "conv5"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fc6"
type: "InnerProduct"
bottom: "pool5"
top: "fc6"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu6"
type: "ReLU"
bottom: "fc6"
top: "fc6"
}
layer {
name: "drop6"
type: "Dropout"
bottom: "fc6"
top: "fc6"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc7"
type: "InnerProduct"
bottom: "fc6"
top: "fc7"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu7"
type: "ReLU"
bottom: "fc7"
top: "fc7"
}
layer {
name: "drop7"
type: "Dropout"
bottom: "fc7"
top: "fc7"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc8"
type: "InnerProduct"
bottom: "fc7"
top: "fc8"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 196
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "fc8"
bottom: "label"
top: "loss"
}
I0422 00:46:13.015058 16011 layer_factory.hpp:77] Creating layer train-data
I0422 00:46:13.016873 16011 db_lmdb.cpp:35] Opened lmdb /mnt/bigdisk/DIGITS-MAN-3/digits/jobs/20210421-230320-902c/train_db
I0422 00:46:13.017100 16011 net.cpp:84] Creating Layer train-data
I0422 00:46:13.017112 16011 net.cpp:380] train-data -> data
I0422 00:46:13.017130 16011 net.cpp:380] train-data -> label
I0422 00:46:13.017141 16011 data_transformer.cpp:25] Loading mean file from: /mnt/bigdisk/DIGITS-MAN-3/digits/jobs/20210421-230320-902c/mean.binaryproto
I0422 00:46:13.022331 16011 data_layer.cpp:45] output data size: 128,3,227,227
I0422 00:46:13.215306 16011 net.cpp:122] Setting up train-data
I0422 00:46:13.215329 16011 net.cpp:129] Top shape: 128 3 227 227 (19787136)
I0422 00:46:13.215335 16011 net.cpp:129] Top shape: 128 (128)
I0422 00:46:13.215342 16011 net.cpp:137] Memory required for data: 79149056
I0422 00:46:13.215351 16011 layer_factory.hpp:77] Creating layer conv1
I0422 00:46:13.215373 16011 net.cpp:84] Creating Layer conv1
I0422 00:46:13.215381 16011 net.cpp:406] conv1 <- data
I0422 00:46:13.215394 16011 net.cpp:380] conv1 -> conv1
I0422 00:46:14.449471 16011 net.cpp:122] Setting up conv1
I0422 00:46:14.449494 16011 net.cpp:129] Top shape: 128 96 54 54 (35831808)
I0422 00:46:14.449499 16011 net.cpp:137] Memory required for data: 222476288
I0422 00:46:14.449520 16011 layer_factory.hpp:77] Creating layer relu1
I0422 00:46:14.449532 16011 net.cpp:84] Creating Layer relu1
I0422 00:46:14.449537 16011 net.cpp:406] relu1 <- conv1
I0422 00:46:14.449542 16011 net.cpp:367] relu1 -> conv1 (in-place)
I0422 00:46:14.449857 16011 net.cpp:122] Setting up relu1
I0422 00:46:14.449867 16011 net.cpp:129] Top shape: 128 96 54 54 (35831808)
I0422 00:46:14.449872 16011 net.cpp:137] Memory required for data: 365803520
I0422 00:46:14.449875 16011 layer_factory.hpp:77] Creating layer norm1
I0422 00:46:14.449885 16011 net.cpp:84] Creating Layer norm1
I0422 00:46:14.449889 16011 net.cpp:406] norm1 <- conv1
I0422 00:46:14.449919 16011 net.cpp:380] norm1 -> norm1
I0422 00:46:14.450402 16011 net.cpp:122] Setting up norm1
I0422 00:46:14.450413 16011 net.cpp:129] Top shape: 128 96 54 54 (35831808)
I0422 00:46:14.450417 16011 net.cpp:137] Memory required for data: 509130752
I0422 00:46:14.450423 16011 layer_factory.hpp:77] Creating layer pool1
I0422 00:46:14.450430 16011 net.cpp:84] Creating Layer pool1
I0422 00:46:14.450435 16011 net.cpp:406] pool1 <- norm1
I0422 00:46:14.450441 16011 net.cpp:380] pool1 -> pool1
I0422 00:46:14.450480 16011 net.cpp:122] Setting up pool1
I0422 00:46:14.450487 16011 net.cpp:129] Top shape: 128 96 27 27 (8957952)
I0422 00:46:14.450491 16011 net.cpp:137] Memory required for data: 544962560
I0422 00:46:14.450495 16011 layer_factory.hpp:77] Creating layer conv2
I0422 00:46:14.450506 16011 net.cpp:84] Creating Layer conv2
I0422 00:46:14.450511 16011 net.cpp:406] conv2 <- pool1
I0422 00:46:14.450517 16011 net.cpp:380] conv2 -> conv2
I0422 00:46:14.544914 16011 net.cpp:122] Setting up conv2
I0422 00:46:14.544934 16011 net.cpp:129] Top shape: 128 256 27 27 (23887872)
I0422 00:46:14.544937 16011 net.cpp:137] Memory required for data: 640514048
I0422 00:46:14.544950 16011 layer_factory.hpp:77] Creating layer relu2
I0422 00:46:14.544960 16011 net.cpp:84] Creating Layer relu2
I0422 00:46:14.544963 16011 net.cpp:406] relu2 <- conv2
I0422 00:46:14.544970 16011 net.cpp:367] relu2 -> conv2 (in-place)
I0422 00:46:14.582655 16011 net.cpp:122] Setting up relu2
I0422 00:46:14.582675 16011 net.cpp:129] Top shape: 128 256 27 27 (23887872)
I0422 00:46:14.582679 16011 net.cpp:137] Memory required for data: 736065536
I0422 00:46:14.582684 16011 layer_factory.hpp:77] Creating layer norm2
I0422 00:46:14.582696 16011 net.cpp:84] Creating Layer norm2
I0422 00:46:14.582700 16011 net.cpp:406] norm2 <- conv2
I0422 00:46:14.582710 16011 net.cpp:380] norm2 -> norm2
I0422 00:46:14.583057 16011 net.cpp:122] Setting up norm2
I0422 00:46:14.583068 16011 net.cpp:129] Top shape: 128 256 27 27 (23887872)
I0422 00:46:14.583071 16011 net.cpp:137] Memory required for data: 831617024
I0422 00:46:14.583076 16011 layer_factory.hpp:77] Creating layer pool2
I0422 00:46:14.583086 16011 net.cpp:84] Creating Layer pool2
I0422 00:46:14.583089 16011 net.cpp:406] pool2 <- norm2
I0422 00:46:14.583096 16011 net.cpp:380] pool2 -> pool2
I0422 00:46:14.583127 16011 net.cpp:122] Setting up pool2
I0422 00:46:14.583133 16011 net.cpp:129] Top shape: 128 256 13 13 (5537792)
I0422 00:46:14.583137 16011 net.cpp:137] Memory required for data: 853768192
I0422 00:46:14.583142 16011 layer_factory.hpp:77] Creating layer conv3
I0422 00:46:14.583153 16011 net.cpp:84] Creating Layer conv3
I0422 00:46:14.583163 16011 net.cpp:406] conv3 <- pool2
I0422 00:46:14.583168 16011 net.cpp:380] conv3 -> conv3
I0422 00:46:14.610417 16011 net.cpp:122] Setting up conv3
I0422 00:46:14.610440 16011 net.cpp:129] Top shape: 128 384 13 13 (8306688)
I0422 00:46:14.610445 16011 net.cpp:137] Memory required for data: 886994944
I0422 00:46:14.610457 16011 layer_factory.hpp:77] Creating layer relu3
I0422 00:46:14.610468 16011 net.cpp:84] Creating Layer relu3
I0422 00:46:14.610472 16011 net.cpp:406] relu3 <- conv3
I0422 00:46:14.610479 16011 net.cpp:367] relu3 -> conv3 (in-place)
I0422 00:46:14.611454 16011 net.cpp:122] Setting up relu3
I0422 00:46:14.611464 16011 net.cpp:129] Top shape: 128 384 13 13 (8306688)
I0422 00:46:14.611467 16011 net.cpp:137] Memory required for data: 920221696
I0422 00:46:14.611471 16011 layer_factory.hpp:77] Creating layer conv4
I0422 00:46:14.611485 16011 net.cpp:84] Creating Layer conv4
I0422 00:46:14.611488 16011 net.cpp:406] conv4 <- conv3
I0422 00:46:14.611495 16011 net.cpp:380] conv4 -> conv4
I0422 00:46:14.622958 16011 net.cpp:122] Setting up conv4
I0422 00:46:14.622977 16011 net.cpp:129] Top shape: 128 384 13 13 (8306688)
I0422 00:46:14.622982 16011 net.cpp:137] Memory required for data: 953448448
I0422 00:46:14.622990 16011 layer_factory.hpp:77] Creating layer relu4
I0422 00:46:14.623001 16011 net.cpp:84] Creating Layer relu4
I0422 00:46:14.623024 16011 net.cpp:406] relu4 <- conv4
I0422 00:46:14.623030 16011 net.cpp:367] relu4 -> conv4 (in-place)
I0422 00:46:14.623401 16011 net.cpp:122] Setting up relu4
I0422 00:46:14.623409 16011 net.cpp:129] Top shape: 128 384 13 13 (8306688)
I0422 00:46:14.623414 16011 net.cpp:137] Memory required for data: 986675200
I0422 00:46:14.623417 16011 layer_factory.hpp:77] Creating layer conv5
I0422 00:46:14.623430 16011 net.cpp:84] Creating Layer conv5
I0422 00:46:14.623433 16011 net.cpp:406] conv5 <- conv4
I0422 00:46:14.623440 16011 net.cpp:380] conv5 -> conv5
I0422 00:46:14.632637 16011 net.cpp:122] Setting up conv5
I0422 00:46:14.632656 16011 net.cpp:129] Top shape: 128 256 13 13 (5537792)
I0422 00:46:14.632660 16011 net.cpp:137] Memory required for data: 1008826368
I0422 00:46:14.632673 16011 layer_factory.hpp:77] Creating layer relu5
I0422 00:46:14.632681 16011 net.cpp:84] Creating Layer relu5
I0422 00:46:14.632685 16011 net.cpp:406] relu5 <- conv5
I0422 00:46:14.632692 16011 net.cpp:367] relu5 -> conv5 (in-place)
I0422 00:46:14.633343 16011 net.cpp:122] Setting up relu5
I0422 00:46:14.633353 16011 net.cpp:129] Top shape: 128 256 13 13 (5537792)
I0422 00:46:14.633358 16011 net.cpp:137] Memory required for data: 1030977536
I0422 00:46:14.633361 16011 layer_factory.hpp:77] Creating layer pool5
I0422 00:46:14.633369 16011 net.cpp:84] Creating Layer pool5
I0422 00:46:14.633373 16011 net.cpp:406] pool5 <- conv5
I0422 00:46:14.633379 16011 net.cpp:380] pool5 -> pool5
I0422 00:46:14.633420 16011 net.cpp:122] Setting up pool5
I0422 00:46:14.633427 16011 net.cpp:129] Top shape: 128 256 6 6 (1179648)
I0422 00:46:14.633430 16011 net.cpp:137] Memory required for data: 1035696128
I0422 00:46:14.633433 16011 layer_factory.hpp:77] Creating layer fc6
I0422 00:46:14.633443 16011 net.cpp:84] Creating Layer fc6
I0422 00:46:14.633446 16011 net.cpp:406] fc6 <- pool5
I0422 00:46:14.633453 16011 net.cpp:380] fc6 -> fc6
I0422 00:46:15.004966 16011 net.cpp:122] Setting up fc6
I0422 00:46:15.004990 16011 net.cpp:129] Top shape: 128 4096 (524288)
I0422 00:46:15.004994 16011 net.cpp:137] Memory required for data: 1037793280
I0422 00:46:15.005003 16011 layer_factory.hpp:77] Creating layer relu6
I0422 00:46:15.005012 16011 net.cpp:84] Creating Layer relu6
I0422 00:46:15.005017 16011 net.cpp:406] relu6 <- fc6
I0422 00:46:15.005024 16011 net.cpp:367] relu6 -> fc6 (in-place)
I0422 00:46:15.014595 16011 net.cpp:122] Setting up relu6
I0422 00:46:15.014607 16011 net.cpp:129] Top shape: 128 4096 (524288)
I0422 00:46:15.014611 16011 net.cpp:137] Memory required for data: 1039890432
I0422 00:46:15.014616 16011 layer_factory.hpp:77] Creating layer drop6
I0422 00:46:15.014623 16011 net.cpp:84] Creating Layer drop6
I0422 00:46:15.014628 16011 net.cpp:406] drop6 <- fc6
I0422 00:46:15.014636 16011 net.cpp:367] drop6 -> fc6 (in-place)
I0422 00:46:15.014667 16011 net.cpp:122] Setting up drop6
I0422 00:46:15.014673 16011 net.cpp:129] Top shape: 128 4096 (524288)
I0422 00:46:15.014678 16011 net.cpp:137] Memory required for data: 1041987584
I0422 00:46:15.014681 16011 layer_factory.hpp:77] Creating layer fc7
I0422 00:46:15.014689 16011 net.cpp:84] Creating Layer fc7
I0422 00:46:15.014693 16011 net.cpp:406] fc7 <- fc6
I0422 00:46:15.014699 16011 net.cpp:380] fc7 -> fc7
I0422 00:46:15.175937 16011 net.cpp:122] Setting up fc7
I0422 00:46:15.175958 16011 net.cpp:129] Top shape: 128 4096 (524288)
I0422 00:46:15.175963 16011 net.cpp:137] Memory required for data: 1044084736
I0422 00:46:15.175973 16011 layer_factory.hpp:77] Creating layer relu7
I0422 00:46:15.175984 16011 net.cpp:84] Creating Layer relu7
I0422 00:46:15.175988 16011 net.cpp:406] relu7 <- fc7
I0422 00:46:15.175994 16011 net.cpp:367] relu7 -> fc7 (in-place)
I0422 00:46:15.176403 16011 net.cpp:122] Setting up relu7
I0422 00:46:15.176411 16011 net.cpp:129] Top shape: 128 4096 (524288)
I0422 00:46:15.176416 16011 net.cpp:137] Memory required for data: 1046181888
I0422 00:46:15.176419 16011 layer_factory.hpp:77] Creating layer drop7
I0422 00:46:15.176426 16011 net.cpp:84] Creating Layer drop7
I0422 00:46:15.176447 16011 net.cpp:406] drop7 <- fc7
I0422 00:46:15.176453 16011 net.cpp:367] drop7 -> fc7 (in-place)
I0422 00:46:15.176481 16011 net.cpp:122] Setting up drop7
I0422 00:46:15.176506 16011 net.cpp:129] Top shape: 128 4096 (524288)
I0422 00:46:15.176509 16011 net.cpp:137] Memory required for data: 1048279040
I0422 00:46:15.176513 16011 layer_factory.hpp:77] Creating layer fc8
I0422 00:46:15.176522 16011 net.cpp:84] Creating Layer fc8
I0422 00:46:15.176525 16011 net.cpp:406] fc8 <- fc7
I0422 00:46:15.176530 16011 net.cpp:380] fc8 -> fc8
I0422 00:46:15.184198 16011 net.cpp:122] Setting up fc8
I0422 00:46:15.184208 16011 net.cpp:129] Top shape: 128 196 (25088)
I0422 00:46:15.184212 16011 net.cpp:137] Memory required for data: 1048379392
I0422 00:46:15.184218 16011 layer_factory.hpp:77] Creating layer loss
I0422 00:46:15.184226 16011 net.cpp:84] Creating Layer loss
I0422 00:46:15.184229 16011 net.cpp:406] loss <- fc8
I0422 00:46:15.184234 16011 net.cpp:406] loss <- label
I0422 00:46:15.184242 16011 net.cpp:380] loss -> loss
I0422 00:46:15.184252 16011 layer_factory.hpp:77] Creating layer loss
I0422 00:46:15.185065 16011 net.cpp:122] Setting up loss
I0422 00:46:15.185075 16011 net.cpp:129] Top shape: (1)
I0422 00:46:15.185077 16011 net.cpp:132]     with loss weight 1
I0422 00:46:15.185093 16011 net.cpp:137] Memory required for data: 1048379396
I0422 00:46:15.185097 16011 net.cpp:198] loss needs backward computation.
I0422 00:46:15.185104 16011 net.cpp:198] fc8 needs backward computation.
I0422 00:46:15.185108 16011 net.cpp:198] drop7 needs backward computation.
I0422 00:46:15.185112 16011 net.cpp:198] relu7 needs backward computation.
I0422 00:46:15.185115 16011 net.cpp:198] fc7 needs backward computation.
I0422 00:46:15.185119 16011 net.cpp:198] drop6 needs backward computation.
I0422 00:46:15.185123 16011 net.cpp:198] relu6 needs backward computation.
I0422 00:46:15.185127 16011 net.cpp:198] fc6 needs backward computation.
I0422 00:46:15.185130 16011 net.cpp:198] pool5 needs backward computation.
I0422 00:46:15.185133 16011 net.cpp:198] relu5 needs backward computation.
I0422 00:46:15.185137 16011 net.cpp:198] conv5 needs backward computation.
I0422 00:46:15.185142 16011 net.cpp:198] relu4 needs backward computation.
I0422 00:46:15.185145 16011 net.cpp:198] conv4 needs backward computation.
I0422 00:46:15.185149 16011 net.cpp:198] relu3 needs backward computation.
I0422 00:46:15.185153 16011 net.cpp:198] conv3 needs backward computation.
I0422 00:46:15.185158 16011 net.cpp:198] pool2 needs backward computation.
I0422 00:46:15.185161 16011 net.cpp:198] norm2 needs backward computation.
I0422 00:46:15.185164 16011 net.cpp:198] relu2 needs backward computation.
I0422 00:46:15.185168 16011 net.cpp:198] conv2 needs backward computation.
I0422 00:46:15.185173 16011 net.cpp:198] pool1 needs backward computation.
I0422 00:46:15.185176 16011 net.cpp:198] norm1 needs backward computation.
I0422 00:46:15.185180 16011 net.cpp:198] relu1 needs backward computation.
I0422 00:46:15.185184 16011 net.cpp:198] conv1 needs backward computation.
I0422 00:46:15.185187 16011 net.cpp:200] train-data does not need backward computation.
I0422 00:46:15.185191 16011 net.cpp:242] This network produces output loss
I0422 00:46:15.185204 16011 net.cpp:255] Network initialization done.
I0422 00:46:15.185704 16011 solver.cpp:172] Creating test net (#0) specified by net file: train_val.prototxt
I0422 00:46:15.185735 16011 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer train-data
I0422 00:46:15.185873 16011 net.cpp:51] Initializing net from parameters:
state {
phase: TEST
}
layer {
name: "val-data"
type: "Data"
top: "data"
top: "label"
include {
phase: TEST
}
transform_param {
crop_size: 227
mean_file: "/mnt/bigdisk/DIGITS-MAN-3/digits/jobs/20210421-230320-902c/mean.binaryproto"
}
data_param {
source: "/mnt/bigdisk/DIGITS-MAN-3/digits/jobs/20210421-230320-902c/val_db"
batch_size: 32
backend: LMDB
}
}
layer {
name: "conv1"
type: "Convolution"
bottom: "data"
top: "conv1"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 96
kernel_size: 15
stride: 4
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu1"
type: "ReLU"
bottom: "conv1"
top: "conv1"
}
layer {
name: "norm1"
type: "LRN"
bottom: "conv1"
top: "norm1"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool1"
type: "Pooling"
bottom: "norm1"
top: "pool1"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv2"
type: "Convolution"
bottom: "pool1"
top: "conv2"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 2
kernel_size: 5
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu2"
type: "ReLU"
bottom: "conv2"
top: "conv2"
}
layer {
name: "norm2"
type: "LRN"
bottom: "conv2"
top: "norm2"
lrn_param {
local_size: 5
alpha: 0.0001
beta: 0.75
}
}
layer {
name: "pool2"
type: "Pooling"
bottom: "norm2"
top: "pool2"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "conv3"
type: "Convolution"
bottom: "pool2"
top: "conv3"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "relu3"
type: "ReLU"
bottom: "conv3"
top: "conv3"
}
layer {
name: "conv4"
type: "Convolution"
bottom: "conv3"
top: "conv4"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 384
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu4"
type: "ReLU"
bottom: "conv4"
top: "conv4"
}
layer {
name: "conv5"
type: "Convolution"
bottom: "conv4"
top: "conv5"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
convolution_param {
num_output: 256
pad: 1
kernel_size: 3
group: 2
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu5"
type: "ReLU"
bottom: "conv5"
top: "conv5"
}
layer {
name: "pool5"
type: "Pooling"
bottom: "conv5"
top: "pool5"
pooling_param {
pool: MAX
kernel_size: 3
stride: 2
}
}
layer {
name: "fc6"
type: "InnerProduct"
bottom: "pool5"
top: "fc6"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu6"
type: "ReLU"
bottom: "fc6"
top: "fc6"
}
layer {
name: "drop6"
type: "Dropout"
bottom: "fc6"
top: "fc6"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc7"
type: "InnerProduct"
bottom: "fc6"
top: "fc7"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 4096
weight_filler {
type: "gaussian"
std: 0.005
}
bias_filler {
type: "constant"
value: 0.1
}
}
}
layer {
name: "relu7"
type: "ReLU"
bottom: "fc7"
top: "fc7"
}
layer {
name: "drop7"
type: "Dropout"
bottom: "fc7"
top: "fc7"
dropout_param {
dropout_ratio: 0.5
}
}
layer {
name: "fc8"
type: "InnerProduct"
bottom: "fc7"
top: "fc8"
param {
lr_mult: 1
decay_mult: 1
}
param {
lr_mult: 2
decay_mult: 0
}
inner_product_param {
num_output: 196
weight_filler {
type: "gaussian"
std: 0.01
}
bias_filler {
type: "constant"
value: 0
}
}
}
layer {
name: "accuracy"
type: "Accuracy"
bottom: "fc8"
bottom: "label"
top: "accuracy"
include {
phase: TEST
}
}
layer {
name: "loss"
type: "SoftmaxWithLoss"
bottom: "fc8"
bottom: "label"
top: "loss"
}
I0422 00:46:15.185966 16011 layer_factory.hpp:77] Creating layer val-data
I0422 00:46:15.188822 16011 db_lmdb.cpp:35] Opened lmdb /mnt/bigdisk/DIGITS-MAN-3/digits/jobs/20210421-230320-902c/val_db
I0422 00:46:15.188982 16011 net.cpp:84] Creating Layer val-data
I0422 00:46:15.188990 16011 net.cpp:380] val-data -> data
I0422 00:46:15.188999 16011 net.cpp:380] val-data -> label
I0422 00:46:15.189007 16011 data_transformer.cpp:25] Loading mean file from: /mnt/bigdisk/DIGITS-MAN-3/digits/jobs/20210421-230320-902c/mean.binaryproto
I0422 00:46:15.192376 16011 data_layer.cpp:45] output data size: 32,3,227,227
I0422 00:46:15.309840 16011 net.cpp:122] Setting up val-data
I0422 00:46:15.309862 16011 net.cpp:129] Top shape: 32 3 227 227 (4946784)
I0422 00:46:15.309867 16011 net.cpp:129] Top shape: 32 (32)
I0422 00:46:15.309870 16011 net.cpp:137] Memory required for data: 19787264
I0422 00:46:15.309876 16011 layer_factory.hpp:77] Creating layer label_val-data_1_split
I0422 00:46:15.309890 16011 net.cpp:84] Creating Layer label_val-data_1_split
I0422 00:46:15.309895 16011 net.cpp:406] label_val-data_1_split <- label
I0422 00:46:15.309902 16011 net.cpp:380] label_val-data_1_split -> label_val-data_1_split_0
I0422 00:46:15.309911 16011 net.cpp:380] label_val-data_1_split -> label_val-data_1_split_1
I0422 00:46:15.309993 16011 net.cpp:122] Setting up label_val-data_1_split
I0422 00:46:15.309999 16011 net.cpp:129] Top shape: 32 (32)
I0422 00:46:15.310003 16011 net.cpp:129] Top shape: 32 (32)
I0422 00:46:15.310005 16011 net.cpp:137] Memory required for data: 19787520
I0422 00:46:15.310009 16011 layer_factory.hpp:77] Creating layer conv1
I0422 00:46:15.310020 16011 net.cpp:84] Creating Layer conv1
I0422 00:46:15.310024 16011 net.cpp:406] conv1 <- data
I0422 00:46:15.310029 16011 net.cpp:380] conv1 -> conv1
I0422 00:46:15.314157 16011 net.cpp:122] Setting up conv1
I0422 00:46:15.314168 16011 net.cpp:129] Top shape: 32 96 54 54 (8957952)
I0422 00:46:15.314172 16011 net.cpp:137] Memory required for data: 55619328
I0422 00:46:15.314182 16011 layer_factory.hpp:77] Creating layer relu1
I0422 00:46:15.314188 16011 net.cpp:84] Creating Layer relu1
I0422 00:46:15.314193 16011 net.cpp:406] relu1 <- conv1
I0422 00:46:15.314198 16011 net.cpp:367] relu1 -> conv1 (in-place)
I0422 00:46:15.314476 16011 net.cpp:122] Setting up relu1
I0422 00:46:15.314483 16011 net.cpp:129] Top shape: 32 96 54 54 (8957952)
I0422 00:46:15.314486 16011 net.cpp:137] Memory required for data: 91451136
I0422 00:46:15.314491 16011 layer_factory.hpp:77] Creating layer norm1
I0422 00:46:15.314498 16011 net.cpp:84] Creating Layer norm1
I0422 00:46:15.314502 16011 net.cpp:406] norm1 <- conv1
I0422 00:46:15.314507 16011 net.cpp:380] norm1 -> norm1
I0422 00:46:15.314954 16011 net.cpp:122] Setting up norm1
I0422 00:46:15.314965 16011 net.cpp:129] Top shape: 32 96 54 54 (8957952)
I0422 00:46:15.314967 16011 net.cpp:137] Memory required for data: 127282944
I0422 00:46:15.314971 16011 layer_factory.hpp:77] Creating layer pool1
I0422 00:46:15.314978 16011 net.cpp:84] Creating Layer pool1
I0422 00:46:15.314981 16011 net.cpp:406] pool1 <- norm1
I0422 00:46:15.314987 16011 net.cpp:380] pool1 -> pool1
I0422 00:46:15.315016 16011 net.cpp:122] Setting up pool1
I0422 00:46:15.315021 16011 net.cpp:129] Top shape: 32 96 27 27 (2239488)
I0422 00:46:15.315023 16011 net.cpp:137] Memory required for data: 136240896
I0422 00:46:15.315026 16011 layer_factory.hpp:77] Creating layer conv2
I0422 00:46:15.315034 16011 net.cpp:84] Creating Layer conv2
I0422 00:46:15.315037 16011 net.cpp:406] conv2 <- pool1
I0422 00:46:15.315061 16011 net.cpp:380] conv2 -> conv2
I0422 00:46:15.322605 16011 net.cpp:122] Setting up conv2
I0422 00:46:15.322620 16011 net.cpp:129] Top shape: 32 256 27 27 (5971968)
I0422 00:46:15.322624 16011 net.cpp:137] Memory required for data: 160128768
I0422 00:46:15.322634 16011 layer_factory.hpp:77] Creating layer relu2
I0422 00:46:15.322643 16011 net.cpp:84] Creating Layer relu2
I0422 00:46:15.322646 16011 net.cpp:406] relu2 <- conv2
I0422 00:46:15.322652 16011 net.cpp:367] relu2 -> conv2 (in-place)
I0422 00:46:15.323159 16011 net.cpp:122] Setting up relu2
I0422 00:46:15.323171 16011 net.cpp:129] Top shape: 32 256 27 27 (5971968)
I0422 00:46:15.323175 16011 net.cpp:137] Memory required for data: 184016640
I0422 00:46:15.323179 16011 layer_factory.hpp:77] Creating layer norm2
I0422 00:46:15.323189 16011 net.cpp:84] Creating Layer norm2
I0422 00:46:15.323192 16011 net.cpp:406] norm2 <- conv2
I0422 00:46:15.323199 16011 net.cpp:380] norm2 -> norm2
I0422 00:46:15.323724 16011 net.cpp:122] Setting up norm2
I0422 00:46:15.323735 16011 net.cpp:129] Top shape: 32 256 27 27 (5971968)
I0422 00:46:15.323740 16011 net.cpp:137] Memory required for data: 207904512
I0422 00:46:15.323743 16011 layer_factory.hpp:77] Creating layer pool2
I0422 00:46:15.323750 16011 net.cpp:84] Creating Layer pool2
I0422 00:46:15.323755 16011 net.cpp:406] pool2 <- norm2
I0422 00:46:15.323760 16011 net.cpp:380] pool2 -> pool2
I0422 00:46:15.323792 16011 net.cpp:122] Setting up pool2
I0422 00:46:15.323797 16011 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I0422 00:46:15.323801 16011 net.cpp:137] Memory required for data: 213442304
I0422 00:46:15.323804 16011 layer_factory.hpp:77] Creating layer conv3
I0422 00:46:15.323814 16011 net.cpp:84] Creating Layer conv3
I0422 00:46:15.323818 16011 net.cpp:406] conv3 <- pool2
I0422 00:46:15.323824 16011 net.cpp:380] conv3 -> conv3
I0422 00:46:15.342934 16011 net.cpp:122] Setting up conv3
I0422 00:46:15.342955 16011 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I0422 00:46:15.342960 16011 net.cpp:137] Memory required for data: 221748992
I0422 00:46:15.342976 16011 layer_factory.hpp:77] Creating layer relu3
I0422 00:46:15.342986 16011 net.cpp:84] Creating Layer relu3
I0422 00:46:15.342990 16011 net.cpp:406] relu3 <- conv3
I0422 00:46:15.342998 16011 net.cpp:367] relu3 -> conv3 (in-place)
I0422 00:46:15.343533 16011 net.cpp:122] Setting up relu3
I0422 00:46:15.343544 16011 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I0422 00:46:15.343549 16011 net.cpp:137] Memory required for data: 230055680
I0422 00:46:15.343554 16011 layer_factory.hpp:77] Creating layer conv4
I0422 00:46:15.343566 16011 net.cpp:84] Creating Layer conv4
I0422 00:46:15.343570 16011 net.cpp:406] conv4 <- conv3
I0422 00:46:15.343577 16011 net.cpp:380] conv4 -> conv4
I0422 00:46:15.354414 16011 net.cpp:122] Setting up conv4
I0422 00:46:15.354431 16011 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I0422 00:46:15.354435 16011 net.cpp:137] Memory required for data: 238362368
I0422 00:46:15.354442 16011 layer_factory.hpp:77] Creating layer relu4
I0422 00:46:15.354451 16011 net.cpp:84] Creating Layer relu4
I0422 00:46:15.354455 16011 net.cpp:406] relu4 <- conv4
I0422 00:46:15.354460 16011 net.cpp:367] relu4 -> conv4 (in-place)
I0422 00:46:15.354807 16011 net.cpp:122] Setting up relu4
I0422 00:46:15.354815 16011 net.cpp:129] Top shape: 32 384 13 13 (2076672)
I0422 00:46:15.354818 16011 net.cpp:137] Memory required for data: 246669056
I0422 00:46:15.354821 16011 layer_factory.hpp:77] Creating layer conv5
I0422 00:46:15.354831 16011 net.cpp:84] Creating Layer conv5
I0422 00:46:15.354835 16011 net.cpp:406] conv5 <- conv4
I0422 00:46:15.354842 16011 net.cpp:380] conv5 -> conv5
I0422 00:46:15.363586 16011 net.cpp:122] Setting up conv5
I0422 00:46:15.363603 16011 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I0422 00:46:15.363607 16011 net.cpp:137] Memory required for data: 252206848
I0422 00:46:15.363618 16011 layer_factory.hpp:77] Creating layer relu5
I0422 00:46:15.363626 16011 net.cpp:84] Creating Layer relu5
I0422 00:46:15.363631 16011 net.cpp:406] relu5 <- conv5
I0422 00:46:15.363656 16011 net.cpp:367] relu5 -> conv5 (in-place)
I0422 00:46:15.364147 16011 net.cpp:122] Setting up relu5
I0422 00:46:15.364156 16011 net.cpp:129] Top shape: 32 256 13 13 (1384448)
I0422 00:46:15.364159 16011 net.cpp:137] Memory required for data: 257744640
I0422 00:46:15.364163 16011 layer_factory.hpp:77] Creating layer pool5
I0422 00:46:15.364174 16011 net.cpp:84] Creating Layer pool5
I0422 00:46:15.364178 16011 net.cpp:406] pool5 <- conv5
I0422 00:46:15.364183 16011 net.cpp:380] pool5 -> pool5
I0422 00:46:15.364223 16011 net.cpp:122] Setting up pool5
I0422 00:46:15.364228 16011 net.cpp:129] Top shape: 32 256 6 6 (294912)
I0422 00:46:15.364231 16011 net.cpp:137] Memory required for data: 258924288
I0422 00:46:15.364234 16011 layer_factory.hpp:77] Creating layer fc6
I0422 00:46:15.364243 16011 net.cpp:84] Creating Layer fc6
I0422 00:46:15.364246 16011 net.cpp:406] fc6 <- pool5
I0422 00:46:15.364251 16011 net.cpp:380] fc6 -> fc6
I0422 00:46:15.719027 16011 net.cpp:122] Setting up fc6
I0422 00:46:15.719048 16011 net.cpp:129] Top shape: 32 4096 (131072)
I0422 00:46:15.719053 16011 net.cpp:137] Memory required for data: 259448576
I0422 00:46:15.719061 16011 layer_factory.hpp:77] Creating layer relu6
I0422 00:46:15.719070 16011 net.cpp:84] Creating Layer relu6
I0422 00:46:15.719075 16011 net.cpp:406] relu6 <- fc6
I0422 00:46:15.719082 16011 net.cpp:367] relu6 -> fc6 (in-place)
I0422 00:46:15.739569 16011 net.cpp:122] Setting up relu6
I0422 00:46:15.739588 16011 net.cpp:129] Top shape: 32 4096 (131072)
I0422 00:46:15.739593 16011 net.cpp:137] Memory required for data: 259972864
I0422 00:46:15.739598 16011 layer_factory.hpp:77] Creating layer drop6
I0422 00:46:15.739609 16011 net.cpp:84] Creating Layer drop6
I0422 00:46:15.739614 16011 net.cpp:406] drop6 <- fc6
I0422 00:46:15.739619 16011 net.cpp:367] drop6 -> fc6 (in-place)
I0422 00:46:15.739653 16011 net.cpp:122] Setting up drop6
I0422 00:46:15.739658 16011 net.cpp:129] Top shape: 32 4096 (131072)
I0422 00:46:15.739661 16011 net.cpp:137] Memory required for data: 260497152
I0422 00:46:15.739665 16011 layer_factory.hpp:77] Creating layer fc7
I0422 00:46:15.739673 16011 net.cpp:84] Creating Layer fc7
I0422 00:46:15.739677 16011 net.cpp:406] fc7 <- fc6
I0422 00:46:15.739684 16011 net.cpp:380] fc7 -> fc7
I0422 00:46:15.926369 16011 net.cpp:122] Setting up fc7
I0422 00:46:15.926394 16011 net.cpp:129] Top shape: 32 4096 (131072)
I0422 00:46:15.926398 16011 net.cpp:137] Memory required for data: 261021440
I0422 00:46:15.926409 16011 layer_factory.hpp:77] Creating layer relu7
I0422 00:46:15.926419 16011 net.cpp:84] Creating Layer relu7
I0422 00:46:15.926424 16011 net.cpp:406] relu7 <- fc7
I0422 00:46:15.926430 16011 net.cpp:367] relu7 -> fc7 (in-place)
I0422 00:46:15.926888 16011 net.cpp:122] Setting up relu7
I0422 00:46:15.926898 16011 net.cpp:129] Top shape: 32 4096 (131072)
I0422 00:46:15.926901 16011 net.cpp:137] Memory required for data: 261545728
I0422 00:46:15.926904 16011 layer_factory.hpp:77] Creating layer drop7
I0422 00:46:15.926911 16011 net.cpp:84] Creating Layer drop7
I0422 00:46:15.926915 16011 net.cpp:406] drop7 <- fc7
I0422 00:46:15.926923 16011 net.cpp:367] drop7 -> fc7 (in-place)
I0422 00:46:15.926947 16011 net.cpp:122] Setting up drop7
I0422 00:46:15.926954 16011 net.cpp:129] Top shape: 32 4096 (131072)
I0422 00:46:15.926957 16011 net.cpp:137] Memory required for data: 262070016
I0422 00:46:15.926961 16011 layer_factory.hpp:77] Creating layer fc8
I0422 00:46:15.926968 16011 net.cpp:84] Creating Layer fc8
I0422 00:46:15.926971 16011 net.cpp:406] fc8 <- fc7
I0422 00:46:15.926978 16011 net.cpp:380] fc8 -> fc8
I0422 00:46:15.935549 16011 net.cpp:122] Setting up fc8
I0422 00:46:15.935561 16011 net.cpp:129] Top shape: 32 196 (6272)
I0422 00:46:15.935565 16011 net.cpp:137] Memory required for data: 262095104
I0422 00:46:15.935572 16011 layer_factory.hpp:77] Creating layer fc8_fc8_0_split
I0422 00:46:15.935580 16011 net.cpp:84] Creating Layer fc8_fc8_0_split
I0422 00:46:15.935583 16011 net.cpp:406] fc8_fc8_0_split <- fc8
I0422 00:46:15.935608 16011 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_0
I0422 00:46:15.935618 16011 net.cpp:380] fc8_fc8_0_split -> fc8_fc8_0_split_1
I0422 00:46:15.935654 16011 net.cpp:122] Setting up fc8_fc8_0_split
I0422 00:46:15.935660 16011 net.cpp:129] Top shape: 32 196 (6272)
I0422 00:46:15.935664 16011 net.cpp:129] Top shape: 32 196 (6272)
I0422 00:46:15.935668 16011 net.cpp:137] Memory required for data: 262145280
I0422 00:46:15.935672 16011 layer_factory.hpp:77] Creating layer accuracy
I0422 00:46:15.935680 16011 net.cpp:84] Creating Layer accuracy
I0422 00:46:15.935684 16011 net.cpp:406] accuracy <- fc8_fc8_0_split_0
I0422 00:46:15.935689 16011 net.cpp:406] accuracy <- label_val-data_1_split_0
I0422 00:46:15.935695 16011 net.cpp:380] accuracy -> accuracy
I0422 00:46:15.935703 16011 net.cpp:122] Setting up accuracy
I0422 00:46:15.935707 16011 net.cpp:129] Top shape: (1)
I0422 00:46:15.935711 16011 net.cpp:137] Memory required for data: 262145284
I0422 00:46:15.935715 16011 layer_factory.hpp:77] Creating layer loss
I0422 00:46:15.935721 16011 net.cpp:84] Creating Layer loss
I0422 00:46:15.935725 16011 net.cpp:406] loss <- fc8_fc8_0_split_1
I0422 00:46:15.935729 16011 net.cpp:406] loss <- label_val-data_1_split_1
I0422 00:46:15.935734 16011 net.cpp:380] loss -> loss
I0422 00:46:15.935741 16011 layer_factory.hpp:77] Creating layer loss
I0422 00:46:15.936395 16011 net.cpp:122] Setting up loss
I0422 00:46:15.936405 16011 net.cpp:129] Top shape: (1)
I0422 00:46:15.936409 16011 net.cpp:132]     with loss weight 1
I0422 00:46:15.936419 16011 net.cpp:137] Memory required for data: 262145288
I0422 00:46:15.936424 16011 net.cpp:198] loss needs backward computation.
I0422 00:46:15.936429 16011 net.cpp:200] accuracy does not need backward computation.
I0422 00:46:15.936432 16011 net.cpp:198] fc8_fc8_0_split needs backward computation.
I0422 00:46:15.936435 16011 net.cpp:198] fc8 needs backward computation.
I0422 00:46:15.936439 16011 net.cpp:198] drop7 needs backward computation.
I0422 00:46:15.936444 16011 net.cpp:198] relu7 needs backward computation.
I0422 00:46:15.936447 16011 net.cpp:198] fc7 needs backward computation.
I0422 00:46:15.936451 16011 net.cpp:198] drop6 needs backward computation.
I0422 00:46:15.936455 16011 net.cpp:198] relu6 needs backward computation.
I0422 00:46:15.936460 16011 net.cpp:198] fc6 needs backward computation.
I0422 00:46:15.936463 16011 net.cpp:198] pool5 needs backward computation.
I0422 00:46:15.936467 16011 net.cpp:198] relu5 needs backward computation.
I0422 00:46:15.936471 16011 net.cpp:198] conv5 needs backward computation.
I0422 00:46:15.936475 16011 net.cpp:198] relu4 needs backward computation.
I0422 00:46:15.936480 16011 net.cpp:198] conv4 needs backward computation.
I0422 00:46:15.936506 16011 net.cpp:198] relu3 needs backward computation.
I0422 00:46:15.936512 16011 net.cpp:198] conv3 needs backward computation.
I0422 00:46:15.936517 16011 net.cpp:198] pool2 needs backward computation.
I0422 00:46:15.936522 16011 net.cpp:198] norm2 needs backward computation.
I0422 00:46:15.936525 16011 net.cpp:198] relu2 needs backward computation.
I0422 00:46:15.936528 16011 net.cpp:198] conv2 needs backward computation.
I0422 00:46:15.936533 16011 net.cpp:198] pool1 needs backward computation.
I0422 00:46:15.936537 16011 net.cpp:198] norm1 needs backward computation.
I0422 00:46:15.936540 16011 net.cpp:198] relu1 needs backward computation.
I0422 00:46:15.936544 16011 net.cpp:198] conv1 needs backward computation.
I0422 00:46:15.936549 16011 net.cpp:200] label_val-data_1_split does not need backward computation.
I0422 00:46:15.936553 16011 net.cpp:200] val-data does not need backward computation.
I0422 00:46:15.936556 16011 net.cpp:242] This network produces output accuracy
I0422 00:46:15.936561 16011 net.cpp:242] This network produces output loss
I0422 00:46:15.936579 16011 net.cpp:255] Network initialization done.
I0422 00:46:15.936650 16011 solver.cpp:56] Solver scaffolding done.
I0422 00:46:15.937114 16011 caffe.cpp:248] Starting Optimization
I0422 00:46:15.937124 16011 solver.cpp:272] Solving
I0422 00:46:15.937137 16011 solver.cpp:273] Learning Rate Policy: exp
I0422 00:46:15.938513 16011 solver.cpp:330] Iteration 0, Testing net (#0)
I0422 00:46:15.938522 16011 net.cpp:676] Ignoring source layer train-data
I0422 00:46:16.027710 16011 blocking_queue.cpp:49] Waiting for data
I0422 00:46:20.397934 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:46:20.443877 16011 solver.cpp:397]     Test net output #0: accuracy = 0.00367647
I0422 00:46:20.443920 16011 solver.cpp:397]     Test net output #1: loss = 5.28128 (* 1 = 5.28128 loss)
I0422 00:46:20.689726 16011 solver.cpp:218] Iteration 0 (2.68637e+37 iter/s, 4.75243s/12 iters), loss = 5.28927
I0422 00:46:20.689769 16011 solver.cpp:237]     Train net output #0: loss = 5.28927 (* 1 = 5.28927 loss)
I0422 00:46:20.689793 16011 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I0422 00:46:24.778880 16011 solver.cpp:218] Iteration 12 (2.93471 iter/s, 4.08899s/12 iters), loss = 5.26588
I0422 00:46:24.778924 16011 solver.cpp:237]     Train net output #0: loss = 5.26588 (* 1 = 5.26588 loss)
I0422 00:46:24.778934 16011 sgd_solver.cpp:105] Iteration 12, lr = 0.00997626
I0422 00:46:29.953586 16011 solver.cpp:218] Iteration 24 (2.31905 iter/s, 5.17453s/12 iters), loss = 5.27266
I0422 00:46:29.953624 16011 solver.cpp:237]     Train net output #0: loss = 5.27266 (* 1 = 5.27266 loss)
I0422 00:46:29.953634 16011 sgd_solver.cpp:105] Iteration 24, lr = 0.00995257
I0422 00:46:35.256981 16011 solver.cpp:218] Iteration 36 (2.26278 iter/s, 5.30321s/12 iters), loss = 5.32238
I0422 00:46:35.257030 16011 solver.cpp:237]     Train net output #0: loss = 5.32238 (* 1 = 5.32238 loss)
I0422 00:46:35.257040 16011 sgd_solver.cpp:105] Iteration 36, lr = 0.00992894
I0422 00:46:40.526347 16011 solver.cpp:218] Iteration 48 (2.2774 iter/s, 5.26918s/12 iters), loss = 5.26961
I0422 00:46:40.526389 16011 solver.cpp:237]     Train net output #0: loss = 5.26961 (* 1 = 5.26961 loss)
I0422 00:46:40.526397 16011 sgd_solver.cpp:105] Iteration 48, lr = 0.00990537
I0422 00:46:45.608906 16011 solver.cpp:218] Iteration 60 (2.3611 iter/s, 5.08238s/12 iters), loss = 5.30723
I0422 00:46:45.609045 16011 solver.cpp:237]     Train net output #0: loss = 5.30723 (* 1 = 5.30723 loss)
I0422 00:46:45.609055 16011 sgd_solver.cpp:105] Iteration 60, lr = 0.00988185
I0422 00:46:50.786902 16011 solver.cpp:218] Iteration 72 (2.31762 iter/s, 5.17773s/12 iters), loss = 5.28551
I0422 00:46:50.786944 16011 solver.cpp:237]     Train net output #0: loss = 5.28551 (* 1 = 5.28551 loss)
I0422 00:46:50.786953 16011 sgd_solver.cpp:105] Iteration 72, lr = 0.00985839
I0422 00:46:55.988756 16011 solver.cpp:218] Iteration 84 (2.30695 iter/s, 5.20167s/12 iters), loss = 5.30399
I0422 00:46:55.988816 16011 solver.cpp:237]     Train net output #0: loss = 5.30399 (* 1 = 5.30399 loss)
I0422 00:46:55.988826 16011 sgd_solver.cpp:105] Iteration 84, lr = 0.00983498
I0422 00:47:01.167024 16011 solver.cpp:218] Iteration 96 (2.31746 iter/s, 5.17808s/12 iters), loss = 5.28426
I0422 00:47:01.167066 16011 solver.cpp:237]     Train net output #0: loss = 5.28426 (* 1 = 5.28426 loss)
I0422 00:47:01.167075 16011 sgd_solver.cpp:105] Iteration 96, lr = 0.00981163
I0422 00:47:02.976155 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:47:03.302021 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_102.caffemodel
I0422 00:47:08.289675 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_102.solverstate
I0422 00:47:10.697175 16011 solver.cpp:330] Iteration 102, Testing net (#0)
I0422 00:47:10.697202 16011 net.cpp:676] Ignoring source layer train-data
I0422 00:47:15.077018 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:47:15.158907 16011 solver.cpp:397]     Test net output #0: accuracy = 0.00245098
I0422 00:47:15.158937 16011 solver.cpp:397]     Test net output #1: loss = 5.28901 (* 1 = 5.28901 loss)
I0422 00:47:17.143543 16011 solver.cpp:218] Iteration 108 (0.751122 iter/s, 15.9761s/12 iters), loss = 5.2773
I0422 00:47:17.193929 16011 solver.cpp:237]     Train net output #0: loss = 5.2773 (* 1 = 5.2773 loss)
I0422 00:47:17.193943 16011 sgd_solver.cpp:105] Iteration 108, lr = 0.00978834
I0422 00:47:22.382550 16011 solver.cpp:218] Iteration 120 (2.31281 iter/s, 5.1885s/12 iters), loss = 5.27178
I0422 00:47:22.382593 16011 solver.cpp:237]     Train net output #0: loss = 5.27178 (* 1 = 5.27178 loss)
I0422 00:47:22.382602 16011 sgd_solver.cpp:105] Iteration 120, lr = 0.0097651
I0422 00:47:27.559268 16011 solver.cpp:218] Iteration 132 (2.31815 iter/s, 5.17654s/12 iters), loss = 5.26949
I0422 00:47:27.559311 16011 solver.cpp:237]     Train net output #0: loss = 5.26949 (* 1 = 5.26949 loss)
I0422 00:47:27.559320 16011 sgd_solver.cpp:105] Iteration 132, lr = 0.00974192
I0422 00:47:32.818188 16011 solver.cpp:218] Iteration 144 (2.28192 iter/s, 5.25874s/12 iters), loss = 5.28816
I0422 00:47:32.818240 16011 solver.cpp:237]     Train net output #0: loss = 5.28816 (* 1 = 5.28816 loss)
I0422 00:47:32.818251 16011 sgd_solver.cpp:105] Iteration 144, lr = 0.00971879
I0422 00:47:37.994374 16011 solver.cpp:218] Iteration 156 (2.31839 iter/s, 5.176s/12 iters), loss = 5.2747
I0422 00:47:37.994418 16011 solver.cpp:237]     Train net output #0: loss = 5.2747 (* 1 = 5.2747 loss)
I0422 00:47:37.994427 16011 sgd_solver.cpp:105] Iteration 156, lr = 0.00969571
I0422 00:47:43.407801 16011 solver.cpp:218] Iteration 168 (2.21679 iter/s, 5.41324s/12 iters), loss = 5.23752
I0422 00:47:43.407842 16011 solver.cpp:237]     Train net output #0: loss = 5.23752 (* 1 = 5.23752 loss)
I0422 00:47:43.407853 16011 sgd_solver.cpp:105] Iteration 168, lr = 0.00967269
I0422 00:47:48.742578 16011 solver.cpp:218] Iteration 180 (2.24947 iter/s, 5.3346s/12 iters), loss = 5.25571
I0422 00:47:48.742697 16011 solver.cpp:237]     Train net output #0: loss = 5.25571 (* 1 = 5.25571 loss)
I0422 00:47:48.742709 16011 sgd_solver.cpp:105] Iteration 180, lr = 0.00964973
I0422 00:47:53.849872 16011 solver.cpp:218] Iteration 192 (2.3497 iter/s, 5.10704s/12 iters), loss = 5.22949
I0422 00:47:53.849921 16011 solver.cpp:237]     Train net output #0: loss = 5.22949 (* 1 = 5.22949 loss)
I0422 00:47:53.849933 16011 sgd_solver.cpp:105] Iteration 192, lr = 0.00962682
I0422 00:47:57.770350 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:47:58.469352 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_204.caffemodel
I0422 00:48:02.814397 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_204.solverstate
I0422 00:48:05.748962 16011 solver.cpp:330] Iteration 204, Testing net (#0)
I0422 00:48:05.748988 16011 net.cpp:676] Ignoring source layer train-data
I0422 00:48:10.319415 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:48:10.447340 16011 solver.cpp:397]     Test net output #0: accuracy = 0.00612745
I0422 00:48:10.447368 16011 solver.cpp:397]     Test net output #1: loss = 5.20446 (* 1 = 5.20446 loss)
I0422 00:48:10.542532 16011 solver.cpp:218] Iteration 204 (0.718898 iter/s, 16.6922s/12 iters), loss = 5.15906
I0422 00:48:10.542572 16011 solver.cpp:237]     Train net output #0: loss = 5.15906 (* 1 = 5.15906 loss)
I0422 00:48:10.542579 16011 sgd_solver.cpp:105] Iteration 204, lr = 0.00960396
I0422 00:48:14.824199 16011 solver.cpp:218] Iteration 216 (2.80275 iter/s, 4.28151s/12 iters), loss = 5.21959
I0422 00:48:14.824239 16011 solver.cpp:237]     Train net output #0: loss = 5.21959 (* 1 = 5.21959 loss)
I0422 00:48:14.824246 16011 sgd_solver.cpp:105] Iteration 216, lr = 0.00958116
I0422 00:48:19.957738 16011 solver.cpp:218] Iteration 228 (2.33765 iter/s, 5.13336s/12 iters), loss = 5.11576
I0422 00:48:19.957844 16011 solver.cpp:237]     Train net output #0: loss = 5.11576 (* 1 = 5.11576 loss)
I0422 00:48:19.957855 16011 sgd_solver.cpp:105] Iteration 228, lr = 0.00955841
I0422 00:48:25.171584 16011 solver.cpp:218] Iteration 240 (2.30167 iter/s, 5.21361s/12 iters), loss = 5.23501
I0422 00:48:25.171625 16011 solver.cpp:237]     Train net output #0: loss = 5.23501 (* 1 = 5.23501 loss)
I0422 00:48:25.171633 16011 sgd_solver.cpp:105] Iteration 240, lr = 0.00953572
I0422 00:48:30.509675 16011 solver.cpp:218] Iteration 252 (2.24807 iter/s, 5.33791s/12 iters), loss = 5.1694
I0422 00:48:30.509713 16011 solver.cpp:237]     Train net output #0: loss = 5.1694 (* 1 = 5.1694 loss)
I0422 00:48:30.509722 16011 sgd_solver.cpp:105] Iteration 252, lr = 0.00951308
I0422 00:48:35.643211 16011 solver.cpp:218] Iteration 264 (2.33765 iter/s, 5.13337s/12 iters), loss = 5.13505
I0422 00:48:35.643255 16011 solver.cpp:237]     Train net output #0: loss = 5.13505 (* 1 = 5.13505 loss)
I0422 00:48:35.643265 16011 sgd_solver.cpp:105] Iteration 264, lr = 0.00949049
I0422 00:48:40.780808 16011 solver.cpp:218] Iteration 276 (2.3358 iter/s, 5.13742s/12 iters), loss = 5.16847
I0422 00:48:40.780848 16011 solver.cpp:237]     Train net output #0: loss = 5.16847 (* 1 = 5.16847 loss)
I0422 00:48:40.780855 16011 sgd_solver.cpp:105] Iteration 276, lr = 0.00946796
I0422 00:48:45.861449 16011 solver.cpp:218] Iteration 288 (2.36199 iter/s, 5.08047s/12 iters), loss = 5.21319
I0422 00:48:45.861491 16011 solver.cpp:237]     Train net output #0: loss = 5.21319 (* 1 = 5.21319 loss)
I0422 00:48:45.861500 16011 sgd_solver.cpp:105] Iteration 288, lr = 0.00944548
I0422 00:48:51.061859 16011 solver.cpp:218] Iteration 300 (2.30759 iter/s, 5.20023s/12 iters), loss = 5.23586
I0422 00:48:51.064929 16011 solver.cpp:237]     Train net output #0: loss = 5.23586 (* 1 = 5.23586 loss)
I0422 00:48:51.064944 16011 sgd_solver.cpp:105] Iteration 300, lr = 0.00942305
I0422 00:48:52.084388 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:48:53.178719 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_306.caffemodel
I0422 00:48:57.600353 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_306.solverstate
I0422 00:49:03.773030 16011 solver.cpp:330] Iteration 306, Testing net (#0)
I0422 00:49:03.773052 16011 net.cpp:676] Ignoring source layer train-data
I0422 00:49:08.063032 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:49:08.223029 16011 solver.cpp:397]     Test net output #0: accuracy = 0.0116422
I0422 00:49:08.223065 16011 solver.cpp:397]     Test net output #1: loss = 5.16323 (* 1 = 5.16323 loss)
I0422 00:49:10.152786 16011 solver.cpp:218] Iteration 312 (0.628687 iter/s, 19.0874s/12 iters), loss = 5.20335
I0422 00:49:10.152829 16011 solver.cpp:237]     Train net output #0: loss = 5.20335 (* 1 = 5.20335 loss)
I0422 00:49:10.152839 16011 sgd_solver.cpp:105] Iteration 312, lr = 0.00940068
I0422 00:49:15.467782 16011 solver.cpp:218] Iteration 324 (2.25784 iter/s, 5.31481s/12 iters), loss = 5.1723
I0422 00:49:15.467819 16011 solver.cpp:237]     Train net output #0: loss = 5.1723 (* 1 = 5.1723 loss)
I0422 00:49:15.467829 16011 sgd_solver.cpp:105] Iteration 324, lr = 0.00937836
I0422 00:49:20.615211 16011 solver.cpp:218] Iteration 336 (2.33134 iter/s, 5.14726s/12 iters), loss = 5.19711
I0422 00:49:20.615252 16011 solver.cpp:237]     Train net output #0: loss = 5.19711 (* 1 = 5.19711 loss)
I0422 00:49:20.615259 16011 sgd_solver.cpp:105] Iteration 336, lr = 0.0093561
I0422 00:49:25.796741 16011 solver.cpp:218] Iteration 348 (2.31599 iter/s, 5.18136s/12 iters), loss = 5.15488
I0422 00:49:25.796968 16011 solver.cpp:237]     Train net output #0: loss = 5.15488 (* 1 = 5.15488 loss)
I0422 00:49:25.796978 16011 sgd_solver.cpp:105] Iteration 348, lr = 0.00933388
I0422 00:49:31.008333 16011 solver.cpp:218] Iteration 360 (2.30272 iter/s, 5.21123s/12 iters), loss = 5.1239
I0422 00:49:31.008370 16011 solver.cpp:237]     Train net output #0: loss = 5.1239 (* 1 = 5.1239 loss)
I0422 00:49:31.008378 16011 sgd_solver.cpp:105] Iteration 360, lr = 0.00931172
I0422 00:49:36.400519 16011 solver.cpp:218] Iteration 372 (2.22552 iter/s, 5.39199s/12 iters), loss = 5.13539
I0422 00:49:36.400561 16011 solver.cpp:237]     Train net output #0: loss = 5.13539 (* 1 = 5.13539 loss)
I0422 00:49:36.400569 16011 sgd_solver.cpp:105] Iteration 372, lr = 0.00928961
I0422 00:49:41.760514 16011 solver.cpp:218] Iteration 384 (2.23889 iter/s, 5.35979s/12 iters), loss = 5.08704
I0422 00:49:41.760557 16011 solver.cpp:237]     Train net output #0: loss = 5.08704 (* 1 = 5.08704 loss)
I0422 00:49:41.760566 16011 sgd_solver.cpp:105] Iteration 384, lr = 0.00926756
I0422 00:49:47.163746 16011 solver.cpp:218] Iteration 396 (2.22097 iter/s, 5.40305s/12 iters), loss = 5.07089
I0422 00:49:47.163789 16011 solver.cpp:237]     Train net output #0: loss = 5.07089 (* 1 = 5.07089 loss)
I0422 00:49:47.163797 16011 sgd_solver.cpp:105] Iteration 396, lr = 0.00924556
I0422 00:49:50.512034 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:49:51.988174 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_408.caffemodel
I0422 00:49:55.949955 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_408.solverstate
I0422 00:50:02.184909 16011 solver.cpp:330] Iteration 408, Testing net (#0)
I0422 00:50:02.184927 16011 net.cpp:676] Ignoring source layer train-data
I0422 00:50:06.470069 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:50:06.679772 16011 solver.cpp:397]     Test net output #0: accuracy = 0.0159314
I0422 00:50:06.679800 16011 solver.cpp:397]     Test net output #1: loss = 5.08565 (* 1 = 5.08565 loss)
I0422 00:50:06.774958 16011 solver.cpp:218] Iteration 408 (0.611911 iter/s, 19.6107s/12 iters), loss = 5.14094
I0422 00:50:06.775002 16011 solver.cpp:237]     Train net output #0: loss = 5.14094 (* 1 = 5.14094 loss)
I0422 00:50:06.775012 16011 sgd_solver.cpp:105] Iteration 408, lr = 0.00922361
I0422 00:50:10.980806 16011 solver.cpp:218] Iteration 420 (2.85327 iter/s, 4.2057s/12 iters), loss = 4.93391
I0422 00:50:10.980841 16011 solver.cpp:237]     Train net output #0: loss = 4.93391 (* 1 = 4.93391 loss)
I0422 00:50:10.980850 16011 sgd_solver.cpp:105] Iteration 420, lr = 0.00920171
I0422 00:50:16.240087 16011 solver.cpp:218] Iteration 432 (2.28176 iter/s, 5.25911s/12 iters), loss = 4.90339
I0422 00:50:16.240134 16011 solver.cpp:237]     Train net output #0: loss = 4.90339 (* 1 = 4.90339 loss)
I0422 00:50:16.240146 16011 sgd_solver.cpp:105] Iteration 432, lr = 0.00917986
I0422 00:50:21.313364 16011 solver.cpp:218] Iteration 444 (2.36542 iter/s, 5.0731s/12 iters), loss = 5.11317
I0422 00:50:21.313410 16011 solver.cpp:237]     Train net output #0: loss = 5.11317 (* 1 = 5.11317 loss)
I0422 00:50:21.313421 16011 sgd_solver.cpp:105] Iteration 444, lr = 0.00915807
I0422 00:50:26.616154 16011 solver.cpp:218] Iteration 456 (2.26304 iter/s, 5.30261s/12 iters), loss = 5.04513
I0422 00:50:26.616250 16011 solver.cpp:237]     Train net output #0: loss = 5.04513 (* 1 = 5.04513 loss)
I0422 00:50:26.616261 16011 sgd_solver.cpp:105] Iteration 456, lr = 0.00913632
I0422 00:50:31.820107 16011 solver.cpp:218] Iteration 468 (2.30604 iter/s, 5.20372s/12 iters), loss = 5.09189
I0422 00:50:31.820148 16011 solver.cpp:237]     Train net output #0: loss = 5.09189 (* 1 = 5.09189 loss)
I0422 00:50:31.820158 16011 sgd_solver.cpp:105] Iteration 468, lr = 0.00911463
I0422 00:50:36.960382 16011 solver.cpp:218] Iteration 480 (2.33459 iter/s, 5.1401s/12 iters), loss = 5.03665
I0422 00:50:36.960427 16011 solver.cpp:237]     Train net output #0: loss = 5.03665 (* 1 = 5.03665 loss)
I0422 00:50:36.960436 16011 sgd_solver.cpp:105] Iteration 480, lr = 0.00909299
I0422 00:50:42.239828 16011 solver.cpp:218] Iteration 492 (2.27305 iter/s, 5.27925s/12 iters), loss = 5.04855
I0422 00:50:42.239887 16011 solver.cpp:237]     Train net output #0: loss = 5.04855 (* 1 = 5.04855 loss)
I0422 00:50:42.239897 16011 sgd_solver.cpp:105] Iteration 492, lr = 0.0090714
I0422 00:50:47.489078 16011 solver.cpp:218] Iteration 504 (2.28613 iter/s, 5.24906s/12 iters), loss = 5.09202
I0422 00:50:47.489121 16011 solver.cpp:237]     Train net output #0: loss = 5.09202 (* 1 = 5.09202 loss)
I0422 00:50:47.489130 16011 sgd_solver.cpp:105] Iteration 504, lr = 0.00904986
I0422 00:50:47.740909 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:50:49.633850 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_510.caffemodel
I0422 00:50:56.441247 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_510.solverstate
I0422 00:50:58.723490 16011 solver.cpp:330] Iteration 510, Testing net (#0)
I0422 00:50:58.723619 16011 net.cpp:676] Ignoring source layer train-data
I0422 00:51:03.158239 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:51:03.403013 16011 solver.cpp:397]     Test net output #0: accuracy = 0.0171569
I0422 00:51:03.403049 16011 solver.cpp:397]     Test net output #1: loss = 5.02747 (* 1 = 5.02747 loss)
I0422 00:51:05.266670 16011 solver.cpp:218] Iteration 516 (0.675025 iter/s, 17.7771s/12 iters), loss = 4.8598
I0422 00:51:05.266713 16011 solver.cpp:237]     Train net output #0: loss = 4.8598 (* 1 = 4.8598 loss)
I0422 00:51:05.266723 16011 sgd_solver.cpp:105] Iteration 516, lr = 0.00902838
I0422 00:51:10.476246 16011 solver.cpp:218] Iteration 528 (2.30353 iter/s, 5.20939s/12 iters), loss = 4.99844
I0422 00:51:10.476286 16011 solver.cpp:237]     Train net output #0: loss = 4.99844 (* 1 = 4.99844 loss)
I0422 00:51:10.476295 16011 sgd_solver.cpp:105] Iteration 528, lr = 0.00900694
I0422 00:51:15.579696 16011 solver.cpp:218] Iteration 540 (2.35143 iter/s, 5.10327s/12 iters), loss = 5.00552
I0422 00:51:15.579738 16011 solver.cpp:237]     Train net output #0: loss = 5.00552 (* 1 = 5.00552 loss)
I0422 00:51:15.579747 16011 sgd_solver.cpp:105] Iteration 540, lr = 0.00898556
I0422 00:51:20.721365 16011 solver.cpp:218] Iteration 552 (2.33395 iter/s, 5.14149s/12 iters), loss = 5.07867
I0422 00:51:20.721415 16011 solver.cpp:237]     Train net output #0: loss = 5.07867 (* 1 = 5.07867 loss)
I0422 00:51:20.721426 16011 sgd_solver.cpp:105] Iteration 552, lr = 0.00896423
I0422 00:51:26.146325 16011 solver.cpp:218] Iteration 564 (2.21207 iter/s, 5.42477s/12 iters), loss = 5.05469
I0422 00:51:26.146368 16011 solver.cpp:237]     Train net output #0: loss = 5.05469 (* 1 = 5.05469 loss)
I0422 00:51:26.146376 16011 sgd_solver.cpp:105] Iteration 564, lr = 0.00894294
I0422 00:51:31.281189 16011 solver.cpp:218] Iteration 576 (2.33705 iter/s, 5.13469s/12 iters), loss = 4.90326
I0422 00:51:31.281318 16011 solver.cpp:237]     Train net output #0: loss = 4.90326 (* 1 = 4.90326 loss)
I0422 00:51:31.281332 16011 sgd_solver.cpp:105] Iteration 576, lr = 0.00892171
I0422 00:51:36.582127 16011 solver.cpp:218] Iteration 588 (2.26386 iter/s, 5.30067s/12 iters), loss = 4.94463
I0422 00:51:36.582172 16011 solver.cpp:237]     Train net output #0: loss = 4.94463 (* 1 = 4.94463 loss)
I0422 00:51:36.582181 16011 sgd_solver.cpp:105] Iteration 588, lr = 0.00890053
I0422 00:51:41.919432 16011 solver.cpp:218] Iteration 600 (2.2484 iter/s, 5.33713s/12 iters), loss = 5.0186
I0422 00:51:41.919471 16011 solver.cpp:237]     Train net output #0: loss = 5.0186 (* 1 = 5.0186 loss)
I0422 00:51:41.919478 16011 sgd_solver.cpp:105] Iteration 600, lr = 0.0088794
I0422 00:51:44.366139 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:51:46.656917 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_612.caffemodel
I0422 00:51:53.308385 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_612.solverstate
I0422 00:51:55.613627 16011 solver.cpp:330] Iteration 612, Testing net (#0)
I0422 00:51:55.613649 16011 net.cpp:676] Ignoring source layer train-data
I0422 00:51:59.942080 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:52:00.233211 16011 solver.cpp:397]     Test net output #0: accuracy = 0.033701
I0422 00:52:00.233239 16011 solver.cpp:397]     Test net output #1: loss = 4.96109 (* 1 = 4.96109 loss)
I0422 00:52:00.328696 16011 solver.cpp:218] Iteration 612 (0.651863 iter/s, 18.4088s/12 iters), loss = 4.93751
I0422 00:52:00.328745 16011 solver.cpp:237]     Train net output #0: loss = 4.93751 (* 1 = 4.93751 loss)
I0422 00:52:00.328758 16011 sgd_solver.cpp:105] Iteration 612, lr = 0.00885831
I0422 00:52:04.827440 16011 solver.cpp:218] Iteration 624 (2.66751 iter/s, 4.49858s/12 iters), loss = 5.03949
I0422 00:52:04.827580 16011 solver.cpp:237]     Train net output #0: loss = 5.03949 (* 1 = 5.03949 loss)
I0422 00:52:04.827590 16011 sgd_solver.cpp:105] Iteration 624, lr = 0.00883728
I0422 00:52:09.983836 16011 solver.cpp:218] Iteration 636 (2.32733 iter/s, 5.15613s/12 iters), loss = 5.01515
I0422 00:52:09.983876 16011 solver.cpp:237]     Train net output #0: loss = 5.01515 (* 1 = 5.01515 loss)
I0422 00:52:09.983886 16011 sgd_solver.cpp:105] Iteration 636, lr = 0.0088163
I0422 00:52:15.327209 16011 solver.cpp:218] Iteration 648 (2.24585 iter/s, 5.3432s/12 iters), loss = 4.91613
I0422 00:52:15.327246 16011 solver.cpp:237]     Train net output #0: loss = 4.91613 (* 1 = 4.91613 loss)
I0422 00:52:15.327255 16011 sgd_solver.cpp:105] Iteration 648, lr = 0.00879537
I0422 00:52:20.574717 16011 solver.cpp:218] Iteration 660 (2.28688 iter/s, 5.24733s/12 iters), loss = 4.91935
I0422 00:52:20.574759 16011 solver.cpp:237]     Train net output #0: loss = 4.91935 (* 1 = 4.91935 loss)
I0422 00:52:20.574767 16011 sgd_solver.cpp:105] Iteration 660, lr = 0.00877449
I0422 00:52:25.758674 16011 solver.cpp:218] Iteration 672 (2.31491 iter/s, 5.18378s/12 iters), loss = 4.81434
I0422 00:52:25.758723 16011 solver.cpp:237]     Train net output #0: loss = 4.81434 (* 1 = 4.81434 loss)
I0422 00:52:25.758733 16011 sgd_solver.cpp:105] Iteration 672, lr = 0.00875366
I0422 00:52:30.988140 16011 solver.cpp:218] Iteration 684 (2.29477 iter/s, 5.22928s/12 iters), loss = 4.92643
I0422 00:52:30.988180 16011 solver.cpp:237]     Train net output #0: loss = 4.92643 (* 1 = 4.92643 loss)
I0422 00:52:30.988189 16011 sgd_solver.cpp:105] Iteration 684, lr = 0.00873287
I0422 00:52:31.855723 16011 blocking_queue.cpp:49] Waiting for data
I0422 00:52:36.535662 16011 solver.cpp:218] Iteration 696 (2.1632 iter/s, 5.54734s/12 iters), loss = 4.80779
I0422 00:52:36.535750 16011 solver.cpp:237]     Train net output #0: loss = 4.80779 (* 1 = 4.80779 loss)
I0422 00:52:36.535761 16011 sgd_solver.cpp:105] Iteration 696, lr = 0.00871214
I0422 00:52:41.401712 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:52:41.820974 16011 solver.cpp:218] Iteration 708 (2.27054 iter/s, 5.28508s/12 iters), loss = 4.95705
I0422 00:52:41.821019 16011 solver.cpp:237]     Train net output #0: loss = 4.95705 (* 1 = 4.95705 loss)
I0422 00:52:41.821028 16011 sgd_solver.cpp:105] Iteration 708, lr = 0.00869145
I0422 00:52:44.089629 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_714.caffemodel
I0422 00:52:48.974542 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_714.solverstate
I0422 00:52:53.305481 16011 solver.cpp:330] Iteration 714, Testing net (#0)
I0422 00:52:53.305505 16011 net.cpp:676] Ignoring source layer train-data
I0422 00:52:57.419112 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:52:57.744275 16011 solver.cpp:397]     Test net output #0: accuracy = 0.0349265
I0422 00:52:57.744305 16011 solver.cpp:397]     Test net output #1: loss = 4.84555 (* 1 = 4.84555 loss)
I0422 00:52:59.795940 16011 solver.cpp:218] Iteration 720 (0.667613 iter/s, 17.9745s/12 iters), loss = 4.77136
I0422 00:52:59.795984 16011 solver.cpp:237]     Train net output #0: loss = 4.77136 (* 1 = 4.77136 loss)
I0422 00:52:59.795992 16011 sgd_solver.cpp:105] Iteration 720, lr = 0.00867082
I0422 00:53:05.069692 16011 solver.cpp:218] Iteration 732 (2.2755 iter/s, 5.27357s/12 iters), loss = 4.91108
I0422 00:53:05.069731 16011 solver.cpp:237]     Train net output #0: loss = 4.91108 (* 1 = 4.91108 loss)
I0422 00:53:05.069739 16011 sgd_solver.cpp:105] Iteration 732, lr = 0.00865023
I0422 00:53:10.305987 16011 solver.cpp:218] Iteration 744 (2.29177 iter/s, 5.23612s/12 iters), loss = 4.77833
I0422 00:53:10.306110 16011 solver.cpp:237]     Train net output #0: loss = 4.77833 (* 1 = 4.77833 loss)
I0422 00:53:10.306123 16011 sgd_solver.cpp:105] Iteration 744, lr = 0.0086297
I0422 00:53:15.454617 16011 solver.cpp:218] Iteration 756 (2.33083 iter/s, 5.14837s/12 iters), loss = 4.83614
I0422 00:53:15.454663 16011 solver.cpp:237]     Train net output #0: loss = 4.83614 (* 1 = 4.83614 loss)
I0422 00:53:15.454674 16011 sgd_solver.cpp:105] Iteration 756, lr = 0.00860921
I0422 00:53:20.675709 16011 solver.cpp:218] Iteration 768 (2.29845 iter/s, 5.22091s/12 iters), loss = 4.79817
I0422 00:53:20.675750 16011 solver.cpp:237]     Train net output #0: loss = 4.79817 (* 1 = 4.79817 loss)
I0422 00:53:20.675760 16011 sgd_solver.cpp:105] Iteration 768, lr = 0.00858877
I0422 00:53:26.201840 16011 solver.cpp:218] Iteration 780 (2.17157 iter/s, 5.52594s/12 iters), loss = 4.66063
I0422 00:53:26.201889 16011 solver.cpp:237]     Train net output #0: loss = 4.66063 (* 1 = 4.66063 loss)
I0422 00:53:26.201900 16011 sgd_solver.cpp:105] Iteration 780, lr = 0.00856838
I0422 00:53:31.543565 16011 solver.cpp:218] Iteration 792 (2.24654 iter/s, 5.34154s/12 iters), loss = 4.86061
I0422 00:53:31.543609 16011 solver.cpp:237]     Train net output #0: loss = 4.86061 (* 1 = 4.86061 loss)
I0422 00:53:31.543618 16011 sgd_solver.cpp:105] Iteration 792, lr = 0.00854803
I0422 00:53:36.919086 16011 solver.cpp:218] Iteration 804 (2.23242 iter/s, 5.37534s/12 iters), loss = 4.80898
I0422 00:53:36.919131 16011 solver.cpp:237]     Train net output #0: loss = 4.80898 (* 1 = 4.80898 loss)
I0422 00:53:36.919142 16011 sgd_solver.cpp:105] Iteration 804, lr = 0.00852774
I0422 00:53:38.688881 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:53:41.574318 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_816.caffemodel
I0422 00:53:50.764010 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_816.solverstate
I0422 00:53:53.318387 16011 solver.cpp:330] Iteration 816, Testing net (#0)
I0422 00:53:53.318415 16011 net.cpp:676] Ignoring source layer train-data
I0422 00:53:57.520889 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:53:57.905818 16011 solver.cpp:397]     Test net output #0: accuracy = 0.0441176
I0422 00:53:57.905848 16011 solver.cpp:397]     Test net output #1: loss = 4.70717 (* 1 = 4.70717 loss)
I0422 00:53:58.001348 16011 solver.cpp:218] Iteration 816 (0.569214 iter/s, 21.0817s/12 iters), loss = 4.52802
I0422 00:53:58.001394 16011 solver.cpp:237]     Train net output #0: loss = 4.52802 (* 1 = 4.52802 loss)
I0422 00:53:58.001402 16011 sgd_solver.cpp:105] Iteration 816, lr = 0.00850749
I0422 00:54:02.496716 16011 solver.cpp:218] Iteration 828 (2.66951 iter/s, 4.4952s/12 iters), loss = 4.82892
I0422 00:54:02.496762 16011 solver.cpp:237]     Train net output #0: loss = 4.82892 (* 1 = 4.82892 loss)
I0422 00:54:02.496771 16011 sgd_solver.cpp:105] Iteration 828, lr = 0.00848729
I0422 00:54:07.580385 16011 solver.cpp:218] Iteration 840 (2.36058 iter/s, 5.08349s/12 iters), loss = 4.7581
I0422 00:54:07.580425 16011 solver.cpp:237]     Train net output #0: loss = 4.7581 (* 1 = 4.7581 loss)
I0422 00:54:07.580433 16011 sgd_solver.cpp:105] Iteration 840, lr = 0.00846714
I0422 00:54:12.917544 16011 solver.cpp:218] Iteration 852 (2.24846 iter/s, 5.33698s/12 iters), loss = 4.6391
I0422 00:54:12.917647 16011 solver.cpp:237]     Train net output #0: loss = 4.6391 (* 1 = 4.6391 loss)
I0422 00:54:12.917657 16011 sgd_solver.cpp:105] Iteration 852, lr = 0.00844704
I0422 00:54:18.162761 16011 solver.cpp:218] Iteration 864 (2.28791 iter/s, 5.24497s/12 iters), loss = 4.63113
I0422 00:54:18.162806 16011 solver.cpp:237]     Train net output #0: loss = 4.63113 (* 1 = 4.63113 loss)
I0422 00:54:18.162815 16011 sgd_solver.cpp:105] Iteration 864, lr = 0.00842698
I0422 00:54:23.466652 16011 solver.cpp:218] Iteration 876 (2.26257 iter/s, 5.30371s/12 iters), loss = 4.49497
I0422 00:54:23.466692 16011 solver.cpp:237]     Train net output #0: loss = 4.49497 (* 1 = 4.49497 loss)
I0422 00:54:23.466701 16011 sgd_solver.cpp:105] Iteration 876, lr = 0.00840698
I0422 00:54:28.970952 16011 solver.cpp:218] Iteration 888 (2.18019 iter/s, 5.50412s/12 iters), loss = 4.50894
I0422 00:54:28.970993 16011 solver.cpp:237]     Train net output #0: loss = 4.50894 (* 1 = 4.50894 loss)
I0422 00:54:28.971002 16011 sgd_solver.cpp:105] Iteration 888, lr = 0.00838702
I0422 00:54:34.158229 16011 solver.cpp:218] Iteration 900 (2.31343 iter/s, 5.1871s/12 iters), loss = 4.491
I0422 00:54:34.158274 16011 solver.cpp:237]     Train net output #0: loss = 4.491 (* 1 = 4.491 loss)
I0422 00:54:34.158283 16011 sgd_solver.cpp:105] Iteration 900, lr = 0.0083671
I0422 00:54:38.248342 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:54:39.401046 16011 solver.cpp:218] Iteration 912 (2.28893 iter/s, 5.24263s/12 iters), loss = 4.63594
I0422 00:54:39.401091 16011 solver.cpp:237]     Train net output #0: loss = 4.63594 (* 1 = 4.63594 loss)
I0422 00:54:39.401100 16011 sgd_solver.cpp:105] Iteration 912, lr = 0.00834724
I0422 00:54:41.488467 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_918.caffemodel
I0422 00:54:52.693783 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_918.solverstate
I0422 00:54:57.712342 16011 solver.cpp:330] Iteration 918, Testing net (#0)
I0422 00:54:57.712368 16011 net.cpp:676] Ignoring source layer train-data
I0422 00:55:01.935431 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:55:02.415717 16011 solver.cpp:397]     Test net output #0: accuracy = 0.0545343
I0422 00:55:02.415758 16011 solver.cpp:397]     Test net output #1: loss = 4.59062 (* 1 = 4.59062 loss)
I0422 00:55:04.340168 16011 solver.cpp:218] Iteration 924 (0.481184 iter/s, 24.9385s/12 iters), loss = 4.56234
I0422 00:55:04.340222 16011 solver.cpp:237]     Train net output #0: loss = 4.56234 (* 1 = 4.56234 loss)
I0422 00:55:04.340234 16011 sgd_solver.cpp:105] Iteration 924, lr = 0.00832742
I0422 00:55:09.420545 16011 solver.cpp:218] Iteration 936 (2.36212 iter/s, 5.08019s/12 iters), loss = 4.54533
I0422 00:55:09.420588 16011 solver.cpp:237]     Train net output #0: loss = 4.54533 (* 1 = 4.54533 loss)
I0422 00:55:09.420596 16011 sgd_solver.cpp:105] Iteration 936, lr = 0.00830765
I0422 00:55:14.471743 16011 solver.cpp:218] Iteration 948 (2.37576 iter/s, 5.05103s/12 iters), loss = 4.75073
I0422 00:55:14.471782 16011 solver.cpp:237]     Train net output #0: loss = 4.75073 (* 1 = 4.75073 loss)
I0422 00:55:14.471791 16011 sgd_solver.cpp:105] Iteration 948, lr = 0.00828793
I0422 00:55:19.576897 16011 solver.cpp:218] Iteration 960 (2.35065 iter/s, 5.10498s/12 iters), loss = 4.58989
I0422 00:55:19.576948 16011 solver.cpp:237]     Train net output #0: loss = 4.58989 (* 1 = 4.58989 loss)
I0422 00:55:19.576969 16011 sgd_solver.cpp:105] Iteration 960, lr = 0.00826825
I0422 00:55:24.814576 16011 solver.cpp:218] Iteration 972 (2.29117 iter/s, 5.23749s/12 iters), loss = 4.39123
I0422 00:55:24.814678 16011 solver.cpp:237]     Train net output #0: loss = 4.39123 (* 1 = 4.39123 loss)
I0422 00:55:24.814689 16011 sgd_solver.cpp:105] Iteration 972, lr = 0.00824862
I0422 00:55:29.925556 16011 solver.cpp:218] Iteration 984 (2.34799 iter/s, 5.11075s/12 iters), loss = 4.46857
I0422 00:55:29.925595 16011 solver.cpp:237]     Train net output #0: loss = 4.46857 (* 1 = 4.46857 loss)
I0422 00:55:29.925603 16011 sgd_solver.cpp:105] Iteration 984, lr = 0.00822903
I0422 00:55:35.003417 16011 solver.cpp:218] Iteration 996 (2.36328 iter/s, 5.07768s/12 iters), loss = 4.50367
I0422 00:55:35.003463 16011 solver.cpp:237]     Train net output #0: loss = 4.50367 (* 1 = 4.50367 loss)
I0422 00:55:35.003473 16011 sgd_solver.cpp:105] Iteration 996, lr = 0.0082095
I0422 00:55:40.143198 16011 solver.cpp:218] Iteration 1008 (2.33481 iter/s, 5.1396s/12 iters), loss = 4.42226
I0422 00:55:40.143229 16011 solver.cpp:237]     Train net output #0: loss = 4.42226 (* 1 = 4.42226 loss)
I0422 00:55:40.143236 16011 sgd_solver.cpp:105] Iteration 1008, lr = 0.00819001
I0422 00:55:41.161906 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:55:44.743571 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_1020.caffemodel
I0422 00:55:54.802667 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1020.solverstate
I0422 00:56:02.496902 16011 solver.cpp:330] Iteration 1020, Testing net (#0)
I0422 00:56:02.497017 16011 net.cpp:676] Ignoring source layer train-data
I0422 00:56:06.612121 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:56:07.090590 16011 solver.cpp:397]     Test net output #0: accuracy = 0.0704657
I0422 00:56:07.090618 16011 solver.cpp:397]     Test net output #1: loss = 4.46033 (* 1 = 4.46033 loss)
I0422 00:56:07.185389 16011 solver.cpp:218] Iteration 1020 (0.443762 iter/s, 27.0415s/12 iters), loss = 4.52195
I0422 00:56:07.185431 16011 solver.cpp:237]     Train net output #0: loss = 4.52195 (* 1 = 4.52195 loss)
I0422 00:56:07.185439 16011 sgd_solver.cpp:105] Iteration 1020, lr = 0.00817056
I0422 00:56:11.453558 16011 solver.cpp:218] Iteration 1032 (2.81162 iter/s, 4.26801s/12 iters), loss = 4.48081
I0422 00:56:11.453603 16011 solver.cpp:237]     Train net output #0: loss = 4.48081 (* 1 = 4.48081 loss)
I0422 00:56:11.453613 16011 sgd_solver.cpp:105] Iteration 1032, lr = 0.00815116
I0422 00:56:16.666322 16011 solver.cpp:218] Iteration 1044 (2.30212 iter/s, 5.21258s/12 iters), loss = 4.53502
I0422 00:56:16.666373 16011 solver.cpp:237]     Train net output #0: loss = 4.53502 (* 1 = 4.53502 loss)
I0422 00:56:16.666384 16011 sgd_solver.cpp:105] Iteration 1044, lr = 0.00813181
I0422 00:56:21.856787 16011 solver.cpp:218] Iteration 1056 (2.31201 iter/s, 5.19028s/12 iters), loss = 4.27808
I0422 00:56:21.856827 16011 solver.cpp:237]     Train net output #0: loss = 4.27808 (* 1 = 4.27808 loss)
I0422 00:56:21.856834 16011 sgd_solver.cpp:105] Iteration 1056, lr = 0.0081125
I0422 00:56:27.142546 16011 solver.cpp:218] Iteration 1068 (2.27033 iter/s, 5.28558s/12 iters), loss = 4.24081
I0422 00:56:27.142591 16011 solver.cpp:237]     Train net output #0: loss = 4.24081 (* 1 = 4.24081 loss)
I0422 00:56:27.142601 16011 sgd_solver.cpp:105] Iteration 1068, lr = 0.00809324
I0422 00:56:32.307411 16011 solver.cpp:218] Iteration 1080 (2.32347 iter/s, 5.16469s/12 iters), loss = 4.33164
I0422 00:56:32.307449 16011 solver.cpp:237]     Train net output #0: loss = 4.33164 (* 1 = 4.33164 loss)
I0422 00:56:32.307459 16011 sgd_solver.cpp:105] Iteration 1080, lr = 0.00807403
I0422 00:56:37.527832 16011 solver.cpp:218] Iteration 1092 (2.29874 iter/s, 5.22025s/12 iters), loss = 4.41718
I0422 00:56:37.527933 16011 solver.cpp:237]     Train net output #0: loss = 4.41718 (* 1 = 4.41718 loss)
I0422 00:56:37.527942 16011 sgd_solver.cpp:105] Iteration 1092, lr = 0.00805486
I0422 00:56:42.757294 16011 solver.cpp:218] Iteration 1104 (2.29479 iter/s, 5.22923s/12 iters), loss = 4.22961
I0422 00:56:42.757339 16011 solver.cpp:237]     Train net output #0: loss = 4.22961 (* 1 = 4.22961 loss)
I0422 00:56:42.757347 16011 sgd_solver.cpp:105] Iteration 1104, lr = 0.00803573
I0422 00:56:46.016402 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:56:47.924942 16011 solver.cpp:218] Iteration 1116 (2.32223 iter/s, 5.16745s/12 iters), loss = 4.3988
I0422 00:56:47.925014 16011 solver.cpp:237]     Train net output #0: loss = 4.3988 (* 1 = 4.3988 loss)
I0422 00:56:47.925026 16011 sgd_solver.cpp:105] Iteration 1116, lr = 0.00801666
I0422 00:56:49.990167 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_1122.caffemodel
I0422 00:56:56.740694 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1122.solverstate
I0422 00:57:04.533805 16011 solver.cpp:330] Iteration 1122, Testing net (#0)
I0422 00:57:04.533824 16011 net.cpp:676] Ignoring source layer train-data
I0422 00:57:08.591380 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:57:09.077899 16011 solver.cpp:397]     Test net output #0: accuracy = 0.0821078
I0422 00:57:09.077932 16011 solver.cpp:397]     Test net output #1: loss = 4.28371 (* 1 = 4.28371 loss)
I0422 00:57:11.038954 16011 solver.cpp:218] Iteration 1128 (0.51918 iter/s, 23.1134s/12 iters), loss = 4.05624
I0422 00:57:11.038995 16011 solver.cpp:237]     Train net output #0: loss = 4.05624 (* 1 = 4.05624 loss)
I0422 00:57:11.039005 16011 sgd_solver.cpp:105] Iteration 1128, lr = 0.00799762
I0422 00:57:16.214138 16011 solver.cpp:218] Iteration 1140 (2.31884 iter/s, 5.175s/12 iters), loss = 4.14583
I0422 00:57:16.214185 16011 solver.cpp:237]     Train net output #0: loss = 4.14583 (* 1 = 4.14583 loss)
I0422 00:57:16.214195 16011 sgd_solver.cpp:105] Iteration 1140, lr = 0.00797863
I0422 00:57:21.303884 16011 solver.cpp:218] Iteration 1152 (2.35776 iter/s, 5.08957s/12 iters), loss = 4.33842
I0422 00:57:21.303923 16011 solver.cpp:237]     Train net output #0: loss = 4.33842 (* 1 = 4.33842 loss)
I0422 00:57:21.303932 16011 sgd_solver.cpp:105] Iteration 1152, lr = 0.00795969
I0422 00:57:26.408195 16011 solver.cpp:218] Iteration 1164 (2.35103 iter/s, 5.10414s/12 iters), loss = 4.17552
I0422 00:57:26.408239 16011 solver.cpp:237]     Train net output #0: loss = 4.17552 (* 1 = 4.17552 loss)
I0422 00:57:26.408249 16011 sgd_solver.cpp:105] Iteration 1164, lr = 0.00794079
I0422 00:57:31.492528 16011 solver.cpp:218] Iteration 1176 (2.36029 iter/s, 5.08413s/12 iters), loss = 4.20511
I0422 00:57:31.492571 16011 solver.cpp:237]     Train net output #0: loss = 4.20511 (* 1 = 4.20511 loss)
I0422 00:57:31.492579 16011 sgd_solver.cpp:105] Iteration 1176, lr = 0.00792194
I0422 00:57:36.667444 16011 solver.cpp:218] Iteration 1188 (2.31896 iter/s, 5.17474s/12 iters), loss = 4.23092
I0422 00:57:36.667482 16011 solver.cpp:237]     Train net output #0: loss = 4.23092 (* 1 = 4.23092 loss)
I0422 00:57:36.667491 16011 sgd_solver.cpp:105] Iteration 1188, lr = 0.00790313
I0422 00:57:41.855505 16011 solver.cpp:218] Iteration 1200 (2.31308 iter/s, 5.18789s/12 iters), loss = 4.31939
I0422 00:57:41.856038 16011 solver.cpp:237]     Train net output #0: loss = 4.31939 (* 1 = 4.31939 loss)
I0422 00:57:41.856048 16011 sgd_solver.cpp:105] Iteration 1200, lr = 0.00788437
I0422 00:57:47.276840 16011 solver.cpp:218] Iteration 1212 (2.21375 iter/s, 5.42066s/12 iters), loss = 4.12656
I0422 00:57:47.276878 16011 solver.cpp:237]     Train net output #0: loss = 4.12656 (* 1 = 4.12656 loss)
I0422 00:57:47.276886 16011 sgd_solver.cpp:105] Iteration 1212, lr = 0.00786565
I0422 00:57:47.560586 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:57:52.109864 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_1224.caffemodel
I0422 00:57:59.774216 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1224.solverstate
I0422 00:58:09.099701 16011 solver.cpp:330] Iteration 1224, Testing net (#0)
I0422 00:58:09.099721 16011 net.cpp:676] Ignoring source layer train-data
I0422 00:58:13.133134 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:58:13.652676 16011 solver.cpp:397]     Test net output #0: accuracy = 0.0992647
I0422 00:58:13.652710 16011 solver.cpp:397]     Test net output #1: loss = 4.16168 (* 1 = 4.16168 loss)
I0422 00:58:13.747872 16011 solver.cpp:218] Iteration 1224 (0.453337 iter/s, 26.4704s/12 iters), loss = 3.96353
I0422 00:58:13.747915 16011 solver.cpp:237]     Train net output #0: loss = 3.96353 (* 1 = 3.96353 loss)
I0422 00:58:13.747925 16011 sgd_solver.cpp:105] Iteration 1224, lr = 0.00784697
I0422 00:58:17.961328 16011 solver.cpp:218] Iteration 1236 (2.84812 iter/s, 4.2133s/12 iters), loss = 4.07428
I0422 00:58:17.961369 16011 solver.cpp:237]     Train net output #0: loss = 4.07428 (* 1 = 4.07428 loss)
I0422 00:58:17.961377 16011 sgd_solver.cpp:105] Iteration 1236, lr = 0.00782834
I0422 00:58:23.150144 16011 solver.cpp:218] Iteration 1248 (2.31274 iter/s, 5.18864s/12 iters), loss = 4.36328
I0422 00:58:23.150182 16011 solver.cpp:237]     Train net output #0: loss = 4.36328 (* 1 = 4.36328 loss)
I0422 00:58:23.150190 16011 sgd_solver.cpp:105] Iteration 1248, lr = 0.00780976
I0422 00:58:28.384419 16011 solver.cpp:218] Iteration 1260 (2.29266 iter/s, 5.2341s/12 iters), loss = 4.40511
I0422 00:58:28.384460 16011 solver.cpp:237]     Train net output #0: loss = 4.40511 (* 1 = 4.40511 loss)
I0422 00:58:28.384469 16011 sgd_solver.cpp:105] Iteration 1260, lr = 0.00779122
I0422 00:58:33.492924 16011 solver.cpp:218] Iteration 1272 (2.34911 iter/s, 5.10832s/12 iters), loss = 4.12045
I0422 00:58:33.492975 16011 solver.cpp:237]     Train net output #0: loss = 4.12045 (* 1 = 4.12045 loss)
I0422 00:58:33.492986 16011 sgd_solver.cpp:105] Iteration 1272, lr = 0.00777272
I0422 00:58:38.595791 16011 solver.cpp:218] Iteration 1284 (2.35171 iter/s, 5.10268s/12 iters), loss = 4.08802
I0422 00:58:38.595834 16011 solver.cpp:237]     Train net output #0: loss = 4.08802 (* 1 = 4.08802 loss)
I0422 00:58:38.595841 16011 sgd_solver.cpp:105] Iteration 1284, lr = 0.00775426
I0422 00:58:43.751181 16011 solver.cpp:218] Iteration 1296 (2.32774 iter/s, 5.15521s/12 iters), loss = 4.04632
I0422 00:58:43.751341 16011 solver.cpp:237]     Train net output #0: loss = 4.04632 (* 1 = 4.04632 loss)
I0422 00:58:43.751354 16011 sgd_solver.cpp:105] Iteration 1296, lr = 0.00773585
I0422 00:58:48.925139 16011 solver.cpp:218] Iteration 1308 (2.31944 iter/s, 5.17367s/12 iters), loss = 4.20114
I0422 00:58:48.925177 16011 solver.cpp:237]     Train net output #0: loss = 4.20114 (* 1 = 4.20114 loss)
I0422 00:58:48.925186 16011 sgd_solver.cpp:105] Iteration 1308, lr = 0.00771749
I0422 00:58:51.574062 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:58:54.181169 16011 solver.cpp:218] Iteration 1320 (2.28317 iter/s, 5.25585s/12 iters), loss = 4.14322
I0422 00:58:54.181210 16011 solver.cpp:237]     Train net output #0: loss = 4.14322 (* 1 = 4.14322 loss)
I0422 00:58:54.181221 16011 sgd_solver.cpp:105] Iteration 1320, lr = 0.00769916
I0422 00:58:56.227605 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_1326.caffemodel
I0422 00:59:08.122771 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1326.solverstate
I0422 00:59:16.354662 16011 solver.cpp:330] Iteration 1326, Testing net (#0)
I0422 00:59:16.354758 16011 net.cpp:676] Ignoring source layer train-data
I0422 00:59:20.278657 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:59:20.845293 16011 solver.cpp:397]     Test net output #0: accuracy = 0.103554
I0422 00:59:20.845325 16011 solver.cpp:397]     Test net output #1: loss = 4.14645 (* 1 = 4.14645 loss)
I0422 00:59:22.704437 16011 solver.cpp:218] Iteration 1332 (0.42072 iter/s, 28.5225s/12 iters), loss = 4.39096
I0422 00:59:22.704528 16011 solver.cpp:237]     Train net output #0: loss = 4.39096 (* 1 = 4.39096 loss)
I0422 00:59:22.704545 16011 sgd_solver.cpp:105] Iteration 1332, lr = 0.00768088
I0422 00:59:27.821516 16011 solver.cpp:218] Iteration 1344 (2.34519 iter/s, 5.11685s/12 iters), loss = 4.13578
I0422 00:59:27.821573 16011 solver.cpp:237]     Train net output #0: loss = 4.13578 (* 1 = 4.13578 loss)
I0422 00:59:27.821585 16011 sgd_solver.cpp:105] Iteration 1344, lr = 0.00766265
I0422 00:59:32.951992 16011 solver.cpp:218] Iteration 1356 (2.33905 iter/s, 5.13028s/12 iters), loss = 4.21149
I0422 00:59:32.952040 16011 solver.cpp:237]     Train net output #0: loss = 4.21149 (* 1 = 4.21149 loss)
I0422 00:59:32.952049 16011 sgd_solver.cpp:105] Iteration 1356, lr = 0.00764446
I0422 00:59:38.132002 16011 solver.cpp:218] Iteration 1368 (2.31668 iter/s, 5.17983s/12 iters), loss = 3.6929
I0422 00:59:38.132042 16011 solver.cpp:237]     Train net output #0: loss = 3.6929 (* 1 = 3.6929 loss)
I0422 00:59:38.132052 16011 sgd_solver.cpp:105] Iteration 1368, lr = 0.00762631
I0422 00:59:39.421780 16011 blocking_queue.cpp:49] Waiting for data
I0422 00:59:43.340188 16011 solver.cpp:218] Iteration 1380 (2.30415 iter/s, 5.208s/12 iters), loss = 3.73396
I0422 00:59:43.340235 16011 solver.cpp:237]     Train net output #0: loss = 3.73396 (* 1 = 3.73396 loss)
I0422 00:59:43.340247 16011 sgd_solver.cpp:105] Iteration 1380, lr = 0.0076082
I0422 00:59:48.560267 16011 solver.cpp:218] Iteration 1392 (2.2989 iter/s, 5.2199s/12 iters), loss = 3.90233
I0422 00:59:48.561408 16011 solver.cpp:237]     Train net output #0: loss = 3.90233 (* 1 = 3.90233 loss)
I0422 00:59:48.561419 16011 sgd_solver.cpp:105] Iteration 1392, lr = 0.00759014
I0422 00:59:53.861343 16011 solver.cpp:218] Iteration 1404 (2.26424 iter/s, 5.2998s/12 iters), loss = 3.85325
I0422 00:59:53.861390 16011 solver.cpp:237]     Train net output #0: loss = 3.85325 (* 1 = 3.85325 loss)
I0422 00:59:53.861402 16011 sgd_solver.cpp:105] Iteration 1404, lr = 0.00757212
I0422 00:59:58.583451 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 00:59:58.943497 16011 solver.cpp:218] Iteration 1416 (2.36129 iter/s, 5.08197s/12 iters), loss = 3.69808
I0422 00:59:58.943545 16011 solver.cpp:237]     Train net output #0: loss = 3.69808 (* 1 = 3.69808 loss)
I0422 00:59:58.943558 16011 sgd_solver.cpp:105] Iteration 1416, lr = 0.00755414
I0422 01:00:03.641180 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_1428.caffemodel
I0422 01:00:11.929112 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1428.solverstate
I0422 01:00:18.105293 16011 solver.cpp:330] Iteration 1428, Testing net (#0)
I0422 01:00:18.105317 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:00:22.126314 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:00:22.735705 16011 solver.cpp:397]     Test net output #0: accuracy = 0.11826
I0422 01:00:22.735743 16011 solver.cpp:397]     Test net output #1: loss = 4.0299 (* 1 = 4.0299 loss)
I0422 01:00:22.830941 16011 solver.cpp:218] Iteration 1428 (0.502369 iter/s, 23.8868s/12 iters), loss = 3.75846
I0422 01:00:22.830991 16011 solver.cpp:237]     Train net output #0: loss = 3.75846 (* 1 = 3.75846 loss)
I0422 01:00:22.831001 16011 sgd_solver.cpp:105] Iteration 1428, lr = 0.0075362
I0422 01:00:27.223804 16011 solver.cpp:218] Iteration 1440 (2.73181 iter/s, 4.3927s/12 iters), loss = 3.80461
I0422 01:00:27.223845 16011 solver.cpp:237]     Train net output #0: loss = 3.80461 (* 1 = 3.80461 loss)
I0422 01:00:27.223852 16011 sgd_solver.cpp:105] Iteration 1440, lr = 0.00751831
I0422 01:00:32.475950 16011 solver.cpp:218] Iteration 1452 (2.28486 iter/s, 5.25197s/12 iters), loss = 3.74791
I0422 01:00:32.475996 16011 solver.cpp:237]     Train net output #0: loss = 3.74791 (* 1 = 3.74791 loss)
I0422 01:00:32.476007 16011 sgd_solver.cpp:105] Iteration 1452, lr = 0.00750046
I0422 01:00:37.605129 16011 solver.cpp:218] Iteration 1464 (2.33963 iter/s, 5.12901s/12 iters), loss = 3.72528
I0422 01:00:37.605166 16011 solver.cpp:237]     Train net output #0: loss = 3.72528 (* 1 = 3.72528 loss)
I0422 01:00:37.605175 16011 sgd_solver.cpp:105] Iteration 1464, lr = 0.00748265
I0422 01:00:42.822194 16011 solver.cpp:218] Iteration 1476 (2.30022 iter/s, 5.21689s/12 iters), loss = 3.65759
I0422 01:00:42.822239 16011 solver.cpp:237]     Train net output #0: loss = 3.65759 (* 1 = 3.65759 loss)
I0422 01:00:42.822249 16011 sgd_solver.cpp:105] Iteration 1476, lr = 0.00746489
I0422 01:00:48.063143 16011 solver.cpp:218] Iteration 1488 (2.28974 iter/s, 5.24076s/12 iters), loss = 3.42777
I0422 01:00:48.063187 16011 solver.cpp:237]     Train net output #0: loss = 3.42777 (* 1 = 3.42777 loss)
I0422 01:00:48.063197 16011 sgd_solver.cpp:105] Iteration 1488, lr = 0.00744716
I0422 01:00:53.299973 16011 solver.cpp:218] Iteration 1500 (2.29154 iter/s, 5.23664s/12 iters), loss = 3.87982
I0422 01:00:53.300069 16011 solver.cpp:237]     Train net output #0: loss = 3.87982 (* 1 = 3.87982 loss)
I0422 01:00:53.300079 16011 sgd_solver.cpp:105] Iteration 1500, lr = 0.00742948
I0422 01:00:58.470068 16011 solver.cpp:218] Iteration 1512 (2.32114 iter/s, 5.16987s/12 iters), loss = 3.76593
I0422 01:00:58.470106 16011 solver.cpp:237]     Train net output #0: loss = 3.76593 (* 1 = 3.76593 loss)
I0422 01:00:58.470118 16011 sgd_solver.cpp:105] Iteration 1512, lr = 0.00741184
I0422 01:01:00.258311 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:01:03.508965 16011 solver.cpp:218] Iteration 1524 (2.38155 iter/s, 5.03873s/12 iters), loss = 3.4036
I0422 01:01:03.509011 16011 solver.cpp:237]     Train net output #0: loss = 3.4036 (* 1 = 3.4036 loss)
I0422 01:01:03.509019 16011 sgd_solver.cpp:105] Iteration 1524, lr = 0.00739425
I0422 01:01:05.629623 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_1530.caffemodel
I0422 01:01:08.556591 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1530.solverstate
I0422 01:01:12.236949 16011 solver.cpp:330] Iteration 1530, Testing net (#0)
I0422 01:01:12.236966 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:01:16.320654 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:01:17.018293 16011 solver.cpp:397]     Test net output #0: accuracy = 0.130515
I0422 01:01:17.018328 16011 solver.cpp:397]     Test net output #1: loss = 3.95334 (* 1 = 3.95334 loss)
I0422 01:01:18.812661 16011 solver.cpp:218] Iteration 1536 (0.784146 iter/s, 15.3033s/12 iters), loss = 3.4229
I0422 01:01:18.812705 16011 solver.cpp:237]     Train net output #0: loss = 3.4229 (* 1 = 3.4229 loss)
I0422 01:01:18.812716 16011 sgd_solver.cpp:105] Iteration 1536, lr = 0.00737669
I0422 01:01:24.200129 16011 solver.cpp:218] Iteration 1548 (2.22747 iter/s, 5.38728s/12 iters), loss = 3.72438
I0422 01:01:24.200263 16011 solver.cpp:237]     Train net output #0: loss = 3.72438 (* 1 = 3.72438 loss)
I0422 01:01:24.200273 16011 sgd_solver.cpp:105] Iteration 1548, lr = 0.00735918
I0422 01:01:29.469159 16011 solver.cpp:218] Iteration 1560 (2.27757 iter/s, 5.26876s/12 iters), loss = 3.28434
I0422 01:01:29.469197 16011 solver.cpp:237]     Train net output #0: loss = 3.28434 (* 1 = 3.28434 loss)
I0422 01:01:29.469205 16011 sgd_solver.cpp:105] Iteration 1560, lr = 0.00734171
I0422 01:01:34.612793 16011 solver.cpp:218] Iteration 1572 (2.33306 iter/s, 5.14347s/12 iters), loss = 3.40364
I0422 01:01:34.612828 16011 solver.cpp:237]     Train net output #0: loss = 3.40364 (* 1 = 3.40364 loss)
I0422 01:01:34.612836 16011 sgd_solver.cpp:105] Iteration 1572, lr = 0.00732427
I0422 01:01:39.779886 16011 solver.cpp:218] Iteration 1584 (2.32246 iter/s, 5.16693s/12 iters), loss = 3.25739
I0422 01:01:39.779927 16011 solver.cpp:237]     Train net output #0: loss = 3.25739 (* 1 = 3.25739 loss)
I0422 01:01:39.779935 16011 sgd_solver.cpp:105] Iteration 1584, lr = 0.00730688
I0422 01:01:44.989125 16011 solver.cpp:218] Iteration 1596 (2.30368 iter/s, 5.20906s/12 iters), loss = 3.33559
I0422 01:01:44.989176 16011 solver.cpp:237]     Train net output #0: loss = 3.33559 (* 1 = 3.33559 loss)
I0422 01:01:44.989187 16011 sgd_solver.cpp:105] Iteration 1596, lr = 0.00728954
I0422 01:01:50.212533 16011 solver.cpp:218] Iteration 1608 (2.29744 iter/s, 5.22321s/12 iters), loss = 3.58856
I0422 01:01:50.212580 16011 solver.cpp:237]     Train net output #0: loss = 3.58856 (* 1 = 3.58856 loss)
I0422 01:01:50.212589 16011 sgd_solver.cpp:105] Iteration 1608, lr = 0.00727223
I0422 01:01:54.259112 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:01:55.376824 16011 solver.cpp:218] Iteration 1620 (2.32373 iter/s, 5.16411s/12 iters), loss = 3.43424
I0422 01:01:55.376863 16011 solver.cpp:237]     Train net output #0: loss = 3.43424 (* 1 = 3.43424 loss)
I0422 01:01:55.376873 16011 sgd_solver.cpp:105] Iteration 1620, lr = 0.00725496
I0422 01:02:00.073935 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_1632.caffemodel
I0422 01:02:05.205051 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1632.solverstate
I0422 01:02:07.483418 16011 solver.cpp:330] Iteration 1632, Testing net (#0)
I0422 01:02:07.483438 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:02:11.194211 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:02:11.874610 16011 solver.cpp:397]     Test net output #0: accuracy = 0.164828
I0422 01:02:11.874644 16011 solver.cpp:397]     Test net output #1: loss = 3.69266 (* 1 = 3.69266 loss)
I0422 01:02:11.969803 16011 solver.cpp:218] Iteration 1632 (0.723217 iter/s, 16.5925s/12 iters), loss = 3.44397
I0422 01:02:11.969847 16011 solver.cpp:237]     Train net output #0: loss = 3.44397 (* 1 = 3.44397 loss)
I0422 01:02:11.969857 16011 sgd_solver.cpp:105] Iteration 1632, lr = 0.00723774
I0422 01:02:16.679451 16011 solver.cpp:218] Iteration 1644 (2.54805 iter/s, 4.70948s/12 iters), loss = 3.29855
I0422 01:02:16.679498 16011 solver.cpp:237]     Train net output #0: loss = 3.29855 (* 1 = 3.29855 loss)
I0422 01:02:16.679508 16011 sgd_solver.cpp:105] Iteration 1644, lr = 0.00722056
I0422 01:02:21.908370 16011 solver.cpp:218] Iteration 1656 (2.29501 iter/s, 5.22874s/12 iters), loss = 3.40156
I0422 01:02:21.908411 16011 solver.cpp:237]     Train net output #0: loss = 3.40156 (* 1 = 3.40156 loss)
I0422 01:02:21.908418 16011 sgd_solver.cpp:105] Iteration 1656, lr = 0.00720341
I0422 01:02:27.175504 16011 solver.cpp:218] Iteration 1668 (2.27836 iter/s, 5.26696s/12 iters), loss = 3.5064
I0422 01:02:27.175628 16011 solver.cpp:237]     Train net output #0: loss = 3.5064 (* 1 = 3.5064 loss)
I0422 01:02:27.175638 16011 sgd_solver.cpp:105] Iteration 1668, lr = 0.00718631
I0422 01:02:32.403657 16011 solver.cpp:218] Iteration 1680 (2.29538 iter/s, 5.22789s/12 iters), loss = 3.26246
I0422 01:02:32.403697 16011 solver.cpp:237]     Train net output #0: loss = 3.26246 (* 1 = 3.26246 loss)
I0422 01:02:32.403705 16011 sgd_solver.cpp:105] Iteration 1680, lr = 0.00716925
I0422 01:02:37.873728 16011 solver.cpp:218] Iteration 1692 (2.19383 iter/s, 5.46988s/12 iters), loss = 3.22948
I0422 01:02:37.873780 16011 solver.cpp:237]     Train net output #0: loss = 3.22948 (* 1 = 3.22948 loss)
I0422 01:02:37.873791 16011 sgd_solver.cpp:105] Iteration 1692, lr = 0.00715223
I0422 01:02:43.109681 16011 solver.cpp:218] Iteration 1704 (2.29193 iter/s, 5.23576s/12 iters), loss = 3.34711
I0422 01:02:43.109740 16011 solver.cpp:237]     Train net output #0: loss = 3.34711 (* 1 = 3.34711 loss)
I0422 01:02:43.109751 16011 sgd_solver.cpp:105] Iteration 1704, lr = 0.00713525
I0422 01:02:48.223304 16011 solver.cpp:218] Iteration 1716 (2.34676 iter/s, 5.11343s/12 iters), loss = 3.33407
I0422 01:02:48.223351 16011 solver.cpp:237]     Train net output #0: loss = 3.33407 (* 1 = 3.33407 loss)
I0422 01:02:48.223362 16011 sgd_solver.cpp:105] Iteration 1716, lr = 0.00711831
I0422 01:02:49.301111 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:02:53.290271 16011 solver.cpp:218] Iteration 1728 (2.36837 iter/s, 5.06679s/12 iters), loss = 3.39426
I0422 01:02:53.290313 16011 solver.cpp:237]     Train net output #0: loss = 3.39426 (* 1 = 3.39426 loss)
I0422 01:02:53.290321 16011 sgd_solver.cpp:105] Iteration 1728, lr = 0.00710141
I0422 01:02:55.390766 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_1734.caffemodel
I0422 01:02:58.346160 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1734.solverstate
I0422 01:03:00.660378 16011 solver.cpp:330] Iteration 1734, Testing net (#0)
I0422 01:03:00.660396 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:03:04.714470 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:03:05.445133 16011 solver.cpp:397]     Test net output #0: accuracy = 0.178922
I0422 01:03:05.445178 16011 solver.cpp:397]     Test net output #1: loss = 3.53857 (* 1 = 3.53857 loss)
I0422 01:03:07.199752 16011 solver.cpp:218] Iteration 1740 (0.862744 iter/s, 13.9091s/12 iters), loss = 3.36985
I0422 01:03:07.199795 16011 solver.cpp:237]     Train net output #0: loss = 3.36985 (* 1 = 3.36985 loss)
I0422 01:03:07.199803 16011 sgd_solver.cpp:105] Iteration 1740, lr = 0.00708455
I0422 01:03:12.348973 16011 solver.cpp:218] Iteration 1752 (2.33053 iter/s, 5.14904s/12 iters), loss = 3.17292
I0422 01:03:12.349015 16011 solver.cpp:237]     Train net output #0: loss = 3.17292 (* 1 = 3.17292 loss)
I0422 01:03:12.349023 16011 sgd_solver.cpp:105] Iteration 1752, lr = 0.00706773
I0422 01:03:17.721181 16011 solver.cpp:218] Iteration 1764 (2.23379 iter/s, 5.37203s/12 iters), loss = 3.12809
I0422 01:03:17.721223 16011 solver.cpp:237]     Train net output #0: loss = 3.12809 (* 1 = 3.12809 loss)
I0422 01:03:17.721231 16011 sgd_solver.cpp:105] Iteration 1764, lr = 0.00705094
I0422 01:03:23.153980 16011 solver.cpp:218] Iteration 1776 (2.20888 iter/s, 5.43261s/12 iters), loss = 3.42717
I0422 01:03:23.154029 16011 solver.cpp:237]     Train net output #0: loss = 3.42717 (* 1 = 3.42717 loss)
I0422 01:03:23.154040 16011 sgd_solver.cpp:105] Iteration 1776, lr = 0.0070342
I0422 01:03:28.317987 16011 solver.cpp:218] Iteration 1788 (2.32386 iter/s, 5.16383s/12 iters), loss = 3.23645
I0422 01:03:28.318027 16011 solver.cpp:237]     Train net output #0: loss = 3.23645 (* 1 = 3.23645 loss)
I0422 01:03:28.318035 16011 sgd_solver.cpp:105] Iteration 1788, lr = 0.0070175
I0422 01:03:33.417440 16011 solver.cpp:218] Iteration 1800 (2.35327 iter/s, 5.09928s/12 iters), loss = 3.33372
I0422 01:03:33.429085 16011 solver.cpp:237]     Train net output #0: loss = 3.33372 (* 1 = 3.33372 loss)
I0422 01:03:33.429096 16011 sgd_solver.cpp:105] Iteration 1800, lr = 0.00700084
I0422 01:03:38.635365 16011 solver.cpp:218] Iteration 1812 (2.30496 iter/s, 5.20615s/12 iters), loss = 3.06521
I0422 01:03:38.635414 16011 solver.cpp:237]     Train net output #0: loss = 3.06521 (* 1 = 3.06521 loss)
I0422 01:03:38.635426 16011 sgd_solver.cpp:105] Iteration 1812, lr = 0.00698422
I0422 01:03:41.927381 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:03:43.846251 16011 solver.cpp:218] Iteration 1824 (2.30295 iter/s, 5.2107s/12 iters), loss = 3.10347
I0422 01:03:43.846295 16011 solver.cpp:237]     Train net output #0: loss = 3.10347 (* 1 = 3.10347 loss)
I0422 01:03:43.846307 16011 sgd_solver.cpp:105] Iteration 1824, lr = 0.00696764
I0422 01:03:48.744026 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_1836.caffemodel
I0422 01:03:51.660128 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1836.solverstate
I0422 01:03:53.936931 16011 solver.cpp:330] Iteration 1836, Testing net (#0)
I0422 01:03:53.936952 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:03:57.794759 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:03:58.562487 16011 solver.cpp:397]     Test net output #0: accuracy = 0.188113
I0422 01:03:58.562526 16011 solver.cpp:397]     Test net output #1: loss = 3.57527 (* 1 = 3.57527 loss)
I0422 01:03:58.658046 16011 solver.cpp:218] Iteration 1836 (0.810187 iter/s, 14.8114s/12 iters), loss = 3.10781
I0422 01:03:58.658089 16011 solver.cpp:237]     Train net output #0: loss = 3.10781 (* 1 = 3.10781 loss)
I0422 01:03:58.658097 16011 sgd_solver.cpp:105] Iteration 1836, lr = 0.0069511
I0422 01:04:03.012949 16011 solver.cpp:218] Iteration 1848 (2.75562 iter/s, 4.35474s/12 iters), loss = 3.03082
I0422 01:04:03.013000 16011 solver.cpp:237]     Train net output #0: loss = 3.03082 (* 1 = 3.03082 loss)
I0422 01:04:03.013010 16011 sgd_solver.cpp:105] Iteration 1848, lr = 0.00693459
I0422 01:04:08.412317 16011 solver.cpp:218] Iteration 1860 (2.22256 iter/s, 5.39918s/12 iters), loss = 3.20417
I0422 01:04:08.434792 16011 solver.cpp:237]     Train net output #0: loss = 3.20417 (* 1 = 3.20417 loss)
I0422 01:04:08.434804 16011 sgd_solver.cpp:105] Iteration 1860, lr = 0.00691813
I0422 01:04:13.630249 16011 solver.cpp:218] Iteration 1872 (2.30977 iter/s, 5.19533s/12 iters), loss = 3.09388
I0422 01:04:13.630293 16011 solver.cpp:237]     Train net output #0: loss = 3.09388 (* 1 = 3.09388 loss)
I0422 01:04:13.630303 16011 sgd_solver.cpp:105] Iteration 1872, lr = 0.0069017
I0422 01:04:18.804522 16011 solver.cpp:218] Iteration 1884 (2.31925 iter/s, 5.17409s/12 iters), loss = 3.24495
I0422 01:04:18.804567 16011 solver.cpp:237]     Train net output #0: loss = 3.24495 (* 1 = 3.24495 loss)
I0422 01:04:18.804577 16011 sgd_solver.cpp:105] Iteration 1884, lr = 0.00688532
I0422 01:04:24.189558 16011 solver.cpp:218] Iteration 1896 (2.22847 iter/s, 5.38485s/12 iters), loss = 2.98668
I0422 01:04:24.189599 16011 solver.cpp:237]     Train net output #0: loss = 2.98668 (* 1 = 2.98668 loss)
I0422 01:04:24.189606 16011 sgd_solver.cpp:105] Iteration 1896, lr = 0.00686897
I0422 01:04:29.381691 16011 solver.cpp:218] Iteration 1908 (2.31127 iter/s, 5.19196s/12 iters), loss = 3.05835
I0422 01:04:29.381737 16011 solver.cpp:237]     Train net output #0: loss = 3.05835 (* 1 = 3.05835 loss)
I0422 01:04:29.381748 16011 sgd_solver.cpp:105] Iteration 1908, lr = 0.00685266
I0422 01:04:34.798341 16011 solver.cpp:218] Iteration 1920 (2.21547 iter/s, 5.41647s/12 iters), loss = 2.94003
I0422 01:04:34.798385 16011 solver.cpp:237]     Train net output #0: loss = 2.94003 (* 1 = 2.94003 loss)
I0422 01:04:34.798396 16011 sgd_solver.cpp:105] Iteration 1920, lr = 0.00683639
I0422 01:04:35.180948 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:04:40.236923 16011 solver.cpp:218] Iteration 1932 (2.20653 iter/s, 5.4384s/12 iters), loss = 3.0891
I0422 01:04:40.237051 16011 solver.cpp:237]     Train net output #0: loss = 3.0891 (* 1 = 3.0891 loss)
I0422 01:04:40.237061 16011 sgd_solver.cpp:105] Iteration 1932, lr = 0.00682016
I0422 01:04:42.472918 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_1938.caffemodel
I0422 01:04:45.422194 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_1938.solverstate
I0422 01:04:47.730592 16011 solver.cpp:330] Iteration 1938, Testing net (#0)
I0422 01:04:47.730616 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:04:51.509879 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:04:52.326921 16011 solver.cpp:397]     Test net output #0: accuracy = 0.20098
I0422 01:04:52.326951 16011 solver.cpp:397]     Test net output #1: loss = 3.47898 (* 1 = 3.47898 loss)
I0422 01:04:54.248701 16011 solver.cpp:218] Iteration 1944 (0.856451 iter/s, 14.0113s/12 iters), loss = 2.97341
I0422 01:04:54.248744 16011 solver.cpp:237]     Train net output #0: loss = 2.97341 (* 1 = 2.97341 loss)
I0422 01:04:54.248752 16011 sgd_solver.cpp:105] Iteration 1944, lr = 0.00680397
I0422 01:04:59.433568 16011 solver.cpp:218] Iteration 1956 (2.31451 iter/s, 5.18469s/12 iters), loss = 3.15906
I0422 01:04:59.433609 16011 solver.cpp:237]     Train net output #0: loss = 3.15906 (* 1 = 3.15906 loss)
I0422 01:04:59.433619 16011 sgd_solver.cpp:105] Iteration 1956, lr = 0.00678782
I0422 01:05:04.563338 16011 solver.cpp:218] Iteration 1968 (2.33936 iter/s, 5.1296s/12 iters), loss = 3.39176
I0422 01:05:04.563377 16011 solver.cpp:237]     Train net output #0: loss = 3.39176 (* 1 = 3.39176 loss)
I0422 01:05:04.563386 16011 sgd_solver.cpp:105] Iteration 1968, lr = 0.0067717
I0422 01:05:09.892550 16011 solver.cpp:218] Iteration 1980 (2.25183 iter/s, 5.32901s/12 iters), loss = 3.02723
I0422 01:05:09.892597 16011 solver.cpp:237]     Train net output #0: loss = 3.02723 (* 1 = 3.02723 loss)
I0422 01:05:09.892606 16011 sgd_solver.cpp:105] Iteration 1980, lr = 0.00675562
I0422 01:05:14.957494 16011 solver.cpp:218] Iteration 1992 (2.36931 iter/s, 5.06477s/12 iters), loss = 3.01286
I0422 01:05:14.957602 16011 solver.cpp:237]     Train net output #0: loss = 3.01286 (* 1 = 3.01286 loss)
I0422 01:05:14.957612 16011 sgd_solver.cpp:105] Iteration 1992, lr = 0.00673958
I0422 01:05:20.118027 16011 solver.cpp:218] Iteration 2004 (2.32545 iter/s, 5.16029s/12 iters), loss = 2.96624
I0422 01:05:20.118077 16011 solver.cpp:237]     Train net output #0: loss = 2.96624 (* 1 = 2.96624 loss)
I0422 01:05:20.118089 16011 sgd_solver.cpp:105] Iteration 2004, lr = 0.00672358
I0422 01:05:25.299923 16011 solver.cpp:218] Iteration 2016 (2.31584 iter/s, 5.18171s/12 iters), loss = 3.24151
I0422 01:05:25.299973 16011 solver.cpp:237]     Train net output #0: loss = 3.24151 (* 1 = 3.24151 loss)
I0422 01:05:25.299984 16011 sgd_solver.cpp:105] Iteration 2016, lr = 0.00670762
I0422 01:05:27.913338 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:05:30.615195 16011 solver.cpp:218] Iteration 2028 (2.25773 iter/s, 5.31508s/12 iters), loss = 2.89681
I0422 01:05:30.615242 16011 solver.cpp:237]     Train net output #0: loss = 2.89681 (* 1 = 2.89681 loss)
I0422 01:05:30.615252 16011 sgd_solver.cpp:105] Iteration 2028, lr = 0.00669169
I0422 01:05:35.494864 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_2040.caffemodel
I0422 01:05:47.087208 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2040.solverstate
I0422 01:05:49.372745 16011 solver.cpp:330] Iteration 2040, Testing net (#0)
I0422 01:05:49.372766 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:05:52.995398 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:05:53.844482 16011 solver.cpp:397]     Test net output #0: accuracy = 0.213235
I0422 01:05:53.844542 16011 solver.cpp:397]     Test net output #1: loss = 3.38505 (* 1 = 3.38505 loss)
I0422 01:05:53.939675 16011 solver.cpp:218] Iteration 2040 (0.514494 iter/s, 23.3239s/12 iters), loss = 2.92831
I0422 01:05:53.939724 16011 solver.cpp:237]     Train net output #0: loss = 2.92831 (* 1 = 2.92831 loss)
I0422 01:05:53.939736 16011 sgd_solver.cpp:105] Iteration 2040, lr = 0.00667581
I0422 01:05:58.242386 16011 solver.cpp:218] Iteration 2052 (2.78904 iter/s, 4.30255s/12 iters), loss = 2.86935
I0422 01:05:58.242426 16011 solver.cpp:237]     Train net output #0: loss = 2.86935 (* 1 = 2.86935 loss)
I0422 01:05:58.242434 16011 sgd_solver.cpp:105] Iteration 2052, lr = 0.00665996
I0422 01:05:59.890813 16011 blocking_queue.cpp:49] Waiting for data
I0422 01:06:03.366921 16011 solver.cpp:218] Iteration 2064 (2.34176 iter/s, 5.12436s/12 iters), loss = 2.61871
I0422 01:06:03.366968 16011 solver.cpp:237]     Train net output #0: loss = 2.61871 (* 1 = 2.61871 loss)
I0422 01:06:03.366978 16011 sgd_solver.cpp:105] Iteration 2064, lr = 0.00664414
I0422 01:06:08.558982 16011 solver.cpp:218] Iteration 2076 (2.3113 iter/s, 5.19188s/12 iters), loss = 2.81256
I0422 01:06:08.559024 16011 solver.cpp:237]     Train net output #0: loss = 2.81256 (* 1 = 2.81256 loss)
I0422 01:06:08.559033 16011 sgd_solver.cpp:105] Iteration 2076, lr = 0.00662837
I0422 01:06:13.825352 16011 solver.cpp:218] Iteration 2088 (2.27869 iter/s, 5.26619s/12 iters), loss = 2.78298
I0422 01:06:13.825397 16011 solver.cpp:237]     Train net output #0: loss = 2.78298 (* 1 = 2.78298 loss)
I0422 01:06:13.825409 16011 sgd_solver.cpp:105] Iteration 2088, lr = 0.00661263
I0422 01:06:18.920543 16011 solver.cpp:218] Iteration 2100 (2.35524 iter/s, 5.09501s/12 iters), loss = 2.95619
I0422 01:06:18.920662 16011 solver.cpp:237]     Train net output #0: loss = 2.95619 (* 1 = 2.95619 loss)
I0422 01:06:18.920671 16011 sgd_solver.cpp:105] Iteration 2100, lr = 0.00659693
I0422 01:06:24.468950 16011 solver.cpp:218] Iteration 2112 (2.16289 iter/s, 5.54814s/12 iters), loss = 3.07339
I0422 01:06:24.468992 16011 solver.cpp:237]     Train net output #0: loss = 3.07339 (* 1 = 3.07339 loss)
I0422 01:06:24.469002 16011 sgd_solver.cpp:105] Iteration 2112, lr = 0.00658127
I0422 01:06:29.439082 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:06:29.796290 16011 solver.cpp:218] Iteration 2124 (2.2526 iter/s, 5.32717s/12 iters), loss = 2.60325
I0422 01:06:29.796324 16011 solver.cpp:237]     Train net output #0: loss = 2.60325 (* 1 = 2.60325 loss)
I0422 01:06:29.796331 16011 sgd_solver.cpp:105] Iteration 2124, lr = 0.00656564
I0422 01:06:34.996791 16011 solver.cpp:218] Iteration 2136 (2.30755 iter/s, 5.20033s/12 iters), loss = 2.78416
I0422 01:06:34.996840 16011 solver.cpp:237]     Train net output #0: loss = 2.78416 (* 1 = 2.78416 loss)
I0422 01:06:34.996851 16011 sgd_solver.cpp:105] Iteration 2136, lr = 0.00655006
I0422 01:06:37.190043 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_2142.caffemodel
I0422 01:06:48.765163 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2142.solverstate
I0422 01:06:57.908015 16011 solver.cpp:330] Iteration 2142, Testing net (#0)
I0422 01:06:57.908089 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:07:01.455569 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:07:02.331533 16011 solver.cpp:397]     Test net output #0: accuracy = 0.231618
I0422 01:07:02.331568 16011 solver.cpp:397]     Test net output #1: loss = 3.36651 (* 1 = 3.36651 loss)
I0422 01:07:04.244257 16011 solver.cpp:218] Iteration 2148 (0.410302 iter/s, 29.2467s/12 iters), loss = 2.64145
I0422 01:07:04.244303 16011 solver.cpp:237]     Train net output #0: loss = 2.64145 (* 1 = 2.64145 loss)
I0422 01:07:04.244313 16011 sgd_solver.cpp:105] Iteration 2148, lr = 0.00653451
I0422 01:07:09.394704 16011 solver.cpp:218] Iteration 2160 (2.32997 iter/s, 5.15027s/12 iters), loss = 2.56591
I0422 01:07:09.394742 16011 solver.cpp:237]     Train net output #0: loss = 2.56591 (* 1 = 2.56591 loss)
I0422 01:07:09.394752 16011 sgd_solver.cpp:105] Iteration 2160, lr = 0.00651899
I0422 01:07:14.683001 16011 solver.cpp:218] Iteration 2172 (2.26924 iter/s, 5.28811s/12 iters), loss = 2.73003
I0422 01:07:14.683053 16011 solver.cpp:237]     Train net output #0: loss = 2.73003 (* 1 = 2.73003 loss)
I0422 01:07:14.683063 16011 sgd_solver.cpp:105] Iteration 2172, lr = 0.00650351
I0422 01:07:19.801384 16011 solver.cpp:218] Iteration 2184 (2.34458 iter/s, 5.1182s/12 iters), loss = 2.76942
I0422 01:07:19.801437 16011 solver.cpp:237]     Train net output #0: loss = 2.76942 (* 1 = 2.76942 loss)
I0422 01:07:19.801450 16011 sgd_solver.cpp:105] Iteration 2184, lr = 0.00648807
I0422 01:07:25.078732 16011 solver.cpp:218] Iteration 2196 (2.27395 iter/s, 5.27715s/12 iters), loss = 2.32854
I0422 01:07:25.078775 16011 solver.cpp:237]     Train net output #0: loss = 2.32854 (* 1 = 2.32854 loss)
I0422 01:07:25.078788 16011 sgd_solver.cpp:105] Iteration 2196, lr = 0.00647267
I0422 01:07:30.317426 16011 solver.cpp:218] Iteration 2208 (2.29073 iter/s, 5.23851s/12 iters), loss = 2.5011
I0422 01:07:30.323519 16011 solver.cpp:237]     Train net output #0: loss = 2.5011 (* 1 = 2.5011 loss)
I0422 01:07:30.323529 16011 sgd_solver.cpp:105] Iteration 2208, lr = 0.0064573
I0422 01:07:35.644057 16011 solver.cpp:218] Iteration 2220 (2.25547 iter/s, 5.3204s/12 iters), loss = 2.6868
I0422 01:07:35.644099 16011 solver.cpp:237]     Train net output #0: loss = 2.6868 (* 1 = 2.6868 loss)
I0422 01:07:35.644109 16011 sgd_solver.cpp:105] Iteration 2220, lr = 0.00644197
I0422 01:07:37.550380 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:07:40.918438 16011 solver.cpp:218] Iteration 2232 (2.27523 iter/s, 5.2742s/12 iters), loss = 2.47938
I0422 01:07:40.918478 16011 solver.cpp:237]     Train net output #0: loss = 2.47938 (* 1 = 2.47938 loss)
I0422 01:07:40.918486 16011 sgd_solver.cpp:105] Iteration 2232, lr = 0.00642668
I0422 01:07:45.541487 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_2244.caffemodel
I0422 01:08:05.886385 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2244.solverstate
I0422 01:08:09.666889 16011 solver.cpp:330] Iteration 2244, Testing net (#0)
I0422 01:08:09.666910 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:08:13.465210 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:08:14.389328 16011 solver.cpp:397]     Test net output #0: accuracy = 0.234069
I0422 01:08:14.389369 16011 solver.cpp:397]     Test net output #1: loss = 3.33931 (* 1 = 3.33931 loss)
I0422 01:08:14.484706 16011 solver.cpp:218] Iteration 2244 (0.357511 iter/s, 33.5654s/12 iters), loss = 2.76757
I0422 01:08:14.484751 16011 solver.cpp:237]     Train net output #0: loss = 2.76757 (* 1 = 2.76757 loss)
I0422 01:08:14.484760 16011 sgd_solver.cpp:105] Iteration 2244, lr = 0.00641142
I0422 01:08:18.658185 16011 solver.cpp:218] Iteration 2256 (2.87541 iter/s, 4.17332s/12 iters), loss = 2.79171
I0422 01:08:18.658236 16011 solver.cpp:237]     Train net output #0: loss = 2.79171 (* 1 = 2.79171 loss)
I0422 01:08:18.658247 16011 sgd_solver.cpp:105] Iteration 2256, lr = 0.0063962
I0422 01:08:23.989439 16011 solver.cpp:218] Iteration 2268 (2.25096 iter/s, 5.33107s/12 iters), loss = 2.52696
I0422 01:08:23.989480 16011 solver.cpp:237]     Train net output #0: loss = 2.52696 (* 1 = 2.52696 loss)
I0422 01:08:23.989488 16011 sgd_solver.cpp:105] Iteration 2268, lr = 0.00638101
I0422 01:08:29.149272 16011 solver.cpp:218] Iteration 2280 (2.32574 iter/s, 5.15966s/12 iters), loss = 2.62861
I0422 01:08:29.149315 16011 solver.cpp:237]     Train net output #0: loss = 2.62861 (* 1 = 2.62861 loss)
I0422 01:08:29.149325 16011 sgd_solver.cpp:105] Iteration 2280, lr = 0.00636586
I0422 01:08:34.445093 16011 solver.cpp:218] Iteration 2292 (2.26602 iter/s, 5.29564s/12 iters), loss = 2.18655
I0422 01:08:34.445132 16011 solver.cpp:237]     Train net output #0: loss = 2.18655 (* 1 = 2.18655 loss)
I0422 01:08:34.445140 16011 sgd_solver.cpp:105] Iteration 2292, lr = 0.00635075
I0422 01:08:39.534039 16011 solver.cpp:218] Iteration 2304 (2.35814 iter/s, 5.08876s/12 iters), loss = 2.52493
I0422 01:08:39.534386 16011 solver.cpp:237]     Train net output #0: loss = 2.52493 (* 1 = 2.52493 loss)
I0422 01:08:39.534402 16011 sgd_solver.cpp:105] Iteration 2304, lr = 0.00633567
I0422 01:08:44.663399 16011 solver.cpp:218] Iteration 2316 (2.33969 iter/s, 5.12888s/12 iters), loss = 2.37474
I0422 01:08:44.663458 16011 solver.cpp:237]     Train net output #0: loss = 2.37474 (* 1 = 2.37474 loss)
I0422 01:08:44.663470 16011 sgd_solver.cpp:105] Iteration 2316, lr = 0.00632063
I0422 01:08:48.669778 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:08:49.742494 16011 solver.cpp:218] Iteration 2328 (2.36272 iter/s, 5.0789s/12 iters), loss = 2.42765
I0422 01:08:49.742548 16011 solver.cpp:237]     Train net output #0: loss = 2.42765 (* 1 = 2.42765 loss)
I0422 01:08:49.742560 16011 sgd_solver.cpp:105] Iteration 2328, lr = 0.00630562
I0422 01:08:54.872954 16011 solver.cpp:218] Iteration 2340 (2.33906 iter/s, 5.13027s/12 iters), loss = 2.29716
I0422 01:08:54.872998 16011 solver.cpp:237]     Train net output #0: loss = 2.29716 (* 1 = 2.29716 loss)
I0422 01:08:54.873008 16011 sgd_solver.cpp:105] Iteration 2340, lr = 0.00629065
I0422 01:08:56.997853 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_2346.caffemodel
I0422 01:09:02.860177 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2346.solverstate
I0422 01:09:07.070472 16011 solver.cpp:330] Iteration 2346, Testing net (#0)
I0422 01:09:07.070504 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:09:10.650372 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:09:11.607941 16011 solver.cpp:397]     Test net output #0: accuracy = 0.260417
I0422 01:09:11.607966 16011 solver.cpp:397]     Test net output #1: loss = 3.20642 (* 1 = 3.20642 loss)
I0422 01:09:13.490994 16011 solver.cpp:218] Iteration 2352 (0.644553 iter/s, 18.6175s/12 iters), loss = 2.29817
I0422 01:09:13.491039 16011 solver.cpp:237]     Train net output #0: loss = 2.29817 (* 1 = 2.29817 loss)
I0422 01:09:13.491050 16011 sgd_solver.cpp:105] Iteration 2352, lr = 0.00627571
I0422 01:09:18.697872 16011 solver.cpp:218] Iteration 2364 (2.30472 iter/s, 5.2067s/12 iters), loss = 2.5006
I0422 01:09:18.697911 16011 solver.cpp:237]     Train net output #0: loss = 2.5006 (* 1 = 2.5006 loss)
I0422 01:09:18.697921 16011 sgd_solver.cpp:105] Iteration 2364, lr = 0.00626081
I0422 01:09:24.160063 16011 solver.cpp:218] Iteration 2376 (2.19699 iter/s, 5.46201s/12 iters), loss = 2.37064
I0422 01:09:24.160107 16011 solver.cpp:237]     Train net output #0: loss = 2.37064 (* 1 = 2.37064 loss)
I0422 01:09:24.160116 16011 sgd_solver.cpp:105] Iteration 2376, lr = 0.00624595
I0422 01:09:29.244333 16011 solver.cpp:218] Iteration 2388 (2.36031 iter/s, 5.08409s/12 iters), loss = 2.62066
I0422 01:09:29.244377 16011 solver.cpp:237]     Train net output #0: loss = 2.62066 (* 1 = 2.62066 loss)
I0422 01:09:29.244387 16011 sgd_solver.cpp:105] Iteration 2388, lr = 0.00623112
I0422 01:09:34.452739 16011 solver.cpp:218] Iteration 2400 (2.30405 iter/s, 5.20823s/12 iters), loss = 2.04971
I0422 01:09:34.452780 16011 solver.cpp:237]     Train net output #0: loss = 2.04971 (* 1 = 2.04971 loss)
I0422 01:09:34.452790 16011 sgd_solver.cpp:105] Iteration 2400, lr = 0.00621633
I0422 01:09:39.651876 16011 solver.cpp:218] Iteration 2412 (2.30815 iter/s, 5.19896s/12 iters), loss = 2.58788
I0422 01:09:39.651921 16011 solver.cpp:237]     Train net output #0: loss = 2.58788 (* 1 = 2.58788 loss)
I0422 01:09:39.651930 16011 sgd_solver.cpp:105] Iteration 2412, lr = 0.00620157
I0422 01:09:45.024619 16011 solver.cpp:218] Iteration 2424 (2.23357 iter/s, 5.37256s/12 iters), loss = 2.13672
I0422 01:09:45.047247 16011 solver.cpp:237]     Train net output #0: loss = 2.13672 (* 1 = 2.13672 loss)
I0422 01:09:45.047260 16011 sgd_solver.cpp:105] Iteration 2424, lr = 0.00618684
I0422 01:09:46.127908 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:09:50.166200 16011 solver.cpp:218] Iteration 2436 (2.34429 iter/s, 5.11883s/12 iters), loss = 2.5216
I0422 01:09:50.166239 16011 solver.cpp:237]     Train net output #0: loss = 2.5216 (* 1 = 2.5216 loss)
I0422 01:09:50.166247 16011 sgd_solver.cpp:105] Iteration 2436, lr = 0.00617215
I0422 01:09:54.784709 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_2448.caffemodel
I0422 01:09:58.960971 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2448.solverstate
I0422 01:10:04.237625 16011 solver.cpp:330] Iteration 2448, Testing net (#0)
I0422 01:10:04.237650 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:10:07.816692 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:10:08.827220 16011 solver.cpp:397]     Test net output #0: accuracy = 0.278799
I0422 01:10:08.827257 16011 solver.cpp:397]     Test net output #1: loss = 3.08933 (* 1 = 3.08933 loss)
I0422 01:10:08.922399 16011 solver.cpp:218] Iteration 2448 (0.639805 iter/s, 18.7557s/12 iters), loss = 2.22379
I0422 01:10:08.922448 16011 solver.cpp:237]     Train net output #0: loss = 2.22379 (* 1 = 2.22379 loss)
I0422 01:10:08.922461 16011 sgd_solver.cpp:105] Iteration 2448, lr = 0.0061575
I0422 01:10:13.262334 16011 solver.cpp:218] Iteration 2460 (2.76513 iter/s, 4.33977s/12 iters), loss = 2.10569
I0422 01:10:13.262392 16011 solver.cpp:237]     Train net output #0: loss = 2.10569 (* 1 = 2.10569 loss)
I0422 01:10:13.262403 16011 sgd_solver.cpp:105] Iteration 2460, lr = 0.00614288
I0422 01:10:18.518985 16011 solver.cpp:218] Iteration 2472 (2.28291 iter/s, 5.25645s/12 iters), loss = 2.27831
I0422 01:10:18.519127 16011 solver.cpp:237]     Train net output #0: loss = 2.27831 (* 1 = 2.27831 loss)
I0422 01:10:18.519137 16011 sgd_solver.cpp:105] Iteration 2472, lr = 0.0061283
I0422 01:10:23.697476 16011 solver.cpp:218] Iteration 2484 (2.3174 iter/s, 5.17821s/12 iters), loss = 2.08098
I0422 01:10:23.697527 16011 solver.cpp:237]     Train net output #0: loss = 2.08098 (* 1 = 2.08098 loss)
I0422 01:10:23.697537 16011 sgd_solver.cpp:105] Iteration 2484, lr = 0.00611375
I0422 01:10:28.768162 16011 solver.cpp:218] Iteration 2496 (2.36663 iter/s, 5.07051s/12 iters), loss = 2.19406
I0422 01:10:28.768203 16011 solver.cpp:237]     Train net output #0: loss = 2.19406 (* 1 = 2.19406 loss)
I0422 01:10:28.768211 16011 sgd_solver.cpp:105] Iteration 2496, lr = 0.00609923
I0422 01:10:33.894459 16011 solver.cpp:218] Iteration 2508 (2.34095 iter/s, 5.12612s/12 iters), loss = 2.13181
I0422 01:10:33.894510 16011 solver.cpp:237]     Train net output #0: loss = 2.13181 (* 1 = 2.13181 loss)
I0422 01:10:33.894521 16011 sgd_solver.cpp:105] Iteration 2508, lr = 0.00608475
I0422 01:10:39.064196 16011 solver.cpp:218] Iteration 2520 (2.32128 iter/s, 5.16955s/12 iters), loss = 1.97432
I0422 01:10:39.064241 16011 solver.cpp:237]     Train net output #0: loss = 1.97432 (* 1 = 1.97432 loss)
I0422 01:10:39.064254 16011 sgd_solver.cpp:105] Iteration 2520, lr = 0.0060703
I0422 01:10:42.372972 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:10:44.210633 16011 solver.cpp:218] Iteration 2532 (2.33179 iter/s, 5.14626s/12 iters), loss = 2.22295
I0422 01:10:44.210672 16011 solver.cpp:237]     Train net output #0: loss = 2.22295 (* 1 = 2.22295 loss)
I0422 01:10:44.210682 16011 sgd_solver.cpp:105] Iteration 2532, lr = 0.00605589
I0422 01:10:49.371377 16011 solver.cpp:218] Iteration 2544 (2.32532 iter/s, 5.16057s/12 iters), loss = 2.07034
I0422 01:10:49.379184 16011 solver.cpp:237]     Train net output #0: loss = 2.07034 (* 1 = 2.07034 loss)
I0422 01:10:49.379199 16011 sgd_solver.cpp:105] Iteration 2544, lr = 0.00604151
I0422 01:10:51.499637 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_2550.caffemodel
I0422 01:11:01.316030 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2550.solverstate
I0422 01:11:10.850502 16011 solver.cpp:330] Iteration 2550, Testing net (#0)
I0422 01:11:10.850529 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:11:14.421576 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:11:15.533030 16011 solver.cpp:397]     Test net output #0: accuracy = 0.280024
I0422 01:11:15.533079 16011 solver.cpp:397]     Test net output #1: loss = 3.1073 (* 1 = 3.1073 loss)
I0422 01:11:17.450645 16011 solver.cpp:218] Iteration 2556 (0.42749 iter/s, 28.0708s/12 iters), loss = 2.18965
I0422 01:11:17.450701 16011 solver.cpp:237]     Train net output #0: loss = 2.18965 (* 1 = 2.18965 loss)
I0422 01:11:17.450714 16011 sgd_solver.cpp:105] Iteration 2556, lr = 0.00602717
I0422 01:11:22.608456 16011 solver.cpp:218] Iteration 2568 (2.32665 iter/s, 5.15762s/12 iters), loss = 1.67684
I0422 01:11:22.608613 16011 solver.cpp:237]     Train net output #0: loss = 1.67684 (* 1 = 1.67684 loss)
I0422 01:11:22.608623 16011 sgd_solver.cpp:105] Iteration 2568, lr = 0.00601286
I0422 01:11:27.755623 16011 solver.cpp:218] Iteration 2580 (2.33151 iter/s, 5.14688s/12 iters), loss = 2.17156
I0422 01:11:27.755664 16011 solver.cpp:237]     Train net output #0: loss = 2.17156 (* 1 = 2.17156 loss)
I0422 01:11:27.755673 16011 sgd_solver.cpp:105] Iteration 2580, lr = 0.00599858
I0422 01:11:32.991561 16011 solver.cpp:218] Iteration 2592 (2.29193 iter/s, 5.23576s/12 iters), loss = 2.18704
I0422 01:11:32.991607 16011 solver.cpp:237]     Train net output #0: loss = 2.18704 (* 1 = 2.18704 loss)
I0422 01:11:32.991618 16011 sgd_solver.cpp:105] Iteration 2592, lr = 0.00598434
I0422 01:11:38.329092 16011 solver.cpp:218] Iteration 2604 (2.24831 iter/s, 5.33734s/12 iters), loss = 1.7944
I0422 01:11:38.329138 16011 solver.cpp:237]     Train net output #0: loss = 1.7944 (* 1 = 1.7944 loss)
I0422 01:11:38.329146 16011 sgd_solver.cpp:105] Iteration 2604, lr = 0.00597013
I0422 01:11:43.481371 16011 solver.cpp:218] Iteration 2616 (2.32915 iter/s, 5.15209s/12 iters), loss = 2.00548
I0422 01:11:43.481421 16011 solver.cpp:237]     Train net output #0: loss = 2.00548 (* 1 = 2.00548 loss)
I0422 01:11:43.481432 16011 sgd_solver.cpp:105] Iteration 2616, lr = 0.00595596
I0422 01:11:48.631381 16011 solver.cpp:218] Iteration 2628 (2.33017 iter/s, 5.14983s/12 iters), loss = 2.07665
I0422 01:11:48.631423 16011 solver.cpp:237]     Train net output #0: loss = 2.07665 (* 1 = 2.07665 loss)
I0422 01:11:48.631433 16011 sgd_solver.cpp:105] Iteration 2628, lr = 0.00594182
I0422 01:11:49.104689 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:11:53.888522 16011 solver.cpp:218] Iteration 2640 (2.28269 iter/s, 5.25696s/12 iters), loss = 2.03638
I0422 01:11:53.888624 16011 solver.cpp:237]     Train net output #0: loss = 2.03638 (* 1 = 2.03638 loss)
I0422 01:11:53.888634 16011 sgd_solver.cpp:105] Iteration 2640, lr = 0.00592771
I0422 01:11:58.771889 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_2652.caffemodel
I0422 01:12:04.956794 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2652.solverstate
I0422 01:12:09.070431 16011 solver.cpp:330] Iteration 2652, Testing net (#0)
I0422 01:12:09.070456 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:12:12.516130 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:12:13.588666 16011 solver.cpp:397]     Test net output #0: accuracy = 0.282476
I0422 01:12:13.588704 16011 solver.cpp:397]     Test net output #1: loss = 3.10718 (* 1 = 3.10718 loss)
I0422 01:12:13.684198 16011 solver.cpp:218] Iteration 2652 (0.606211 iter/s, 19.7951s/12 iters), loss = 1.80225
I0422 01:12:13.684242 16011 solver.cpp:237]     Train net output #0: loss = 1.80225 (* 1 = 1.80225 loss)
I0422 01:12:13.684250 16011 sgd_solver.cpp:105] Iteration 2652, lr = 0.00591364
I0422 01:12:18.125166 16011 solver.cpp:218] Iteration 2664 (2.70221 iter/s, 4.4408s/12 iters), loss = 2.19311
I0422 01:12:18.125211 16011 solver.cpp:237]     Train net output #0: loss = 2.19311 (* 1 = 2.19311 loss)
I0422 01:12:18.125221 16011 sgd_solver.cpp:105] Iteration 2664, lr = 0.0058996
I0422 01:12:23.219676 16011 solver.cpp:218] Iteration 2676 (2.35556 iter/s, 5.09433s/12 iters), loss = 2.1828
I0422 01:12:23.219730 16011 solver.cpp:237]     Train net output #0: loss = 2.1828 (* 1 = 2.1828 loss)
I0422 01:12:23.219743 16011 sgd_solver.cpp:105] Iteration 2676, lr = 0.00588559
I0422 01:12:28.377760 16011 solver.cpp:218] Iteration 2688 (2.32653 iter/s, 5.15789s/12 iters), loss = 1.89309
I0422 01:12:28.377936 16011 solver.cpp:237]     Train net output #0: loss = 1.89309 (* 1 = 1.89309 loss)
I0422 01:12:28.377950 16011 sgd_solver.cpp:105] Iteration 2688, lr = 0.00587162
I0422 01:12:33.605794 16011 solver.cpp:218] Iteration 2700 (2.29545 iter/s, 5.22773s/12 iters), loss = 1.55657
I0422 01:12:33.605832 16011 solver.cpp:237]     Train net output #0: loss = 1.55657 (* 1 = 1.55657 loss)
I0422 01:12:33.605840 16011 sgd_solver.cpp:105] Iteration 2700, lr = 0.00585768
I0422 01:12:38.887389 16011 solver.cpp:218] Iteration 2712 (2.27212 iter/s, 5.28142s/12 iters), loss = 1.71492
I0422 01:12:38.887430 16011 solver.cpp:237]     Train net output #0: loss = 1.71492 (* 1 = 1.71492 loss)
I0422 01:12:38.887439 16011 sgd_solver.cpp:105] Iteration 2712, lr = 0.00584377
I0422 01:12:44.226518 16011 solver.cpp:218] Iteration 2724 (2.24764 iter/s, 5.33894s/12 iters), loss = 2.35571
I0422 01:12:44.226575 16011 solver.cpp:237]     Train net output #0: loss = 2.35571 (* 1 = 2.35571 loss)
I0422 01:12:44.226588 16011 sgd_solver.cpp:105] Iteration 2724, lr = 0.0058299
I0422 01:12:46.943646 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:12:49.439831 16011 solver.cpp:218] Iteration 2736 (2.30188 iter/s, 5.21312s/12 iters), loss = 2.10024
I0422 01:12:49.439877 16011 solver.cpp:237]     Train net output #0: loss = 2.10024 (* 1 = 2.10024 loss)
I0422 01:12:49.439888 16011 sgd_solver.cpp:105] Iteration 2736, lr = 0.00581605
I0422 01:12:54.941848 16011 solver.cpp:218] Iteration 2748 (2.18109 iter/s, 5.50183s/12 iters), loss = 2.11028
I0422 01:12:54.941890 16011 solver.cpp:237]     Train net output #0: loss = 2.11028 (* 1 = 2.11028 loss)
I0422 01:12:54.941900 16011 sgd_solver.cpp:105] Iteration 2748, lr = 0.00580225
I0422 01:12:57.038998 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_2754.caffemodel
I0422 01:12:59.953469 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2754.solverstate
I0422 01:13:02.829922 16011 solver.cpp:330] Iteration 2754, Testing net (#0)
I0422 01:13:02.829946 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:13:06.103165 16011 blocking_queue.cpp:49] Waiting for data
I0422 01:13:06.350271 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:13:07.481899 16011 solver.cpp:397]     Test net output #0: accuracy = 0.264706
I0422 01:13:07.481941 16011 solver.cpp:397]     Test net output #1: loss = 3.1517 (* 1 = 3.1517 loss)
I0422 01:13:09.251134 16011 solver.cpp:218] Iteration 2760 (0.838639 iter/s, 14.3089s/12 iters), loss = 1.73027
I0422 01:13:09.251183 16011 solver.cpp:237]     Train net output #0: loss = 1.73027 (* 1 = 1.73027 loss)
I0422 01:13:09.251194 16011 sgd_solver.cpp:105] Iteration 2760, lr = 0.00578847
I0422 01:13:14.386181 16011 solver.cpp:218] Iteration 2772 (2.33696 iter/s, 5.13487s/12 iters), loss = 1.975
I0422 01:13:14.386212 16011 solver.cpp:237]     Train net output #0: loss = 1.975 (* 1 = 1.975 loss)
I0422 01:13:14.386220 16011 sgd_solver.cpp:105] Iteration 2772, lr = 0.00577473
I0422 01:13:19.790505 16011 solver.cpp:218] Iteration 2784 (2.22052 iter/s, 5.40414s/12 iters), loss = 1.73734
I0422 01:13:19.790563 16011 solver.cpp:237]     Train net output #0: loss = 1.73734 (* 1 = 1.73734 loss)
I0422 01:13:19.790578 16011 sgd_solver.cpp:105] Iteration 2784, lr = 0.00576102
I0422 01:13:24.984032 16011 solver.cpp:218] Iteration 2796 (2.31065 iter/s, 5.19334s/12 iters), loss = 1.68857
I0422 01:13:24.984072 16011 solver.cpp:237]     Train net output #0: loss = 1.68857 (* 1 = 1.68857 loss)
I0422 01:13:24.984082 16011 sgd_solver.cpp:105] Iteration 2796, lr = 0.00574734
I0422 01:13:30.228821 16011 solver.cpp:218] Iteration 2808 (2.28806 iter/s, 5.24462s/12 iters), loss = 1.96012
I0422 01:13:30.228933 16011 solver.cpp:237]     Train net output #0: loss = 1.96012 (* 1 = 1.96012 loss)
I0422 01:13:30.228943 16011 sgd_solver.cpp:105] Iteration 2808, lr = 0.00573369
I0422 01:13:35.678629 16011 solver.cpp:218] Iteration 2820 (2.20201 iter/s, 5.44956s/12 iters), loss = 1.70589
I0422 01:13:35.678671 16011 solver.cpp:237]     Train net output #0: loss = 1.70589 (* 1 = 1.70589 loss)
I0422 01:13:35.678680 16011 sgd_solver.cpp:105] Iteration 2820, lr = 0.00572008
I0422 01:13:40.601677 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:13:40.913331 16011 solver.cpp:218] Iteration 2832 (2.29247 iter/s, 5.23453s/12 iters), loss = 1.63095
I0422 01:13:40.913379 16011 solver.cpp:237]     Train net output #0: loss = 1.63095 (* 1 = 1.63095 loss)
I0422 01:13:40.913388 16011 sgd_solver.cpp:105] Iteration 2832, lr = 0.0057065
I0422 01:13:45.962247 16011 solver.cpp:218] Iteration 2844 (2.37683 iter/s, 5.04873s/12 iters), loss = 2.0412
I0422 01:13:45.962294 16011 solver.cpp:237]     Train net output #0: loss = 2.0412 (* 1 = 2.0412 loss)
I0422 01:13:45.962303 16011 sgd_solver.cpp:105] Iteration 2844, lr = 0.00569295
I0422 01:13:50.681376 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_2856.caffemodel
I0422 01:13:55.115469 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2856.solverstate
I0422 01:13:59.044773 16011 solver.cpp:330] Iteration 2856, Testing net (#0)
I0422 01:13:59.044798 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:14:02.333997 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:14:03.488528 16011 solver.cpp:397]     Test net output #0: accuracy = 0.291054
I0422 01:14:03.488557 16011 solver.cpp:397]     Test net output #1: loss = 3.08465 (* 1 = 3.08465 loss)
I0422 01:14:03.584141 16011 solver.cpp:218] Iteration 2856 (0.680989 iter/s, 17.6214s/12 iters), loss = 1.54554
I0422 01:14:03.584197 16011 solver.cpp:237]     Train net output #0: loss = 1.54554 (* 1 = 1.54554 loss)
I0422 01:14:03.584210 16011 sgd_solver.cpp:105] Iteration 2856, lr = 0.00567944
I0422 01:14:07.840970 16011 solver.cpp:218] Iteration 2868 (2.81911 iter/s, 4.25666s/12 iters), loss = 1.89803
I0422 01:14:07.841017 16011 solver.cpp:237]     Train net output #0: loss = 1.89803 (* 1 = 1.89803 loss)
I0422 01:14:07.841027 16011 sgd_solver.cpp:105] Iteration 2868, lr = 0.00566595
I0422 01:14:13.000085 16011 solver.cpp:218] Iteration 2880 (2.32606 iter/s, 5.15893s/12 iters), loss = 1.9917
I0422 01:14:13.000138 16011 solver.cpp:237]     Train net output #0: loss = 1.9917 (* 1 = 1.9917 loss)
I0422 01:14:13.000149 16011 sgd_solver.cpp:105] Iteration 2880, lr = 0.0056525
I0422 01:14:18.263027 16011 solver.cpp:218] Iteration 2892 (2.28017 iter/s, 5.26275s/12 iters), loss = 1.71931
I0422 01:14:18.263064 16011 solver.cpp:237]     Train net output #0: loss = 1.71931 (* 1 = 1.71931 loss)
I0422 01:14:18.263073 16011 sgd_solver.cpp:105] Iteration 2892, lr = 0.00563908
I0422 01:14:23.534072 16011 solver.cpp:218] Iteration 2904 (2.27666 iter/s, 5.27087s/12 iters), loss = 1.59404
I0422 01:14:23.534114 16011 solver.cpp:237]     Train net output #0: loss = 1.59404 (* 1 = 1.59404 loss)
I0422 01:14:23.534124 16011 sgd_solver.cpp:105] Iteration 2904, lr = 0.00562569
I0422 01:14:28.798875 16011 solver.cpp:218] Iteration 2916 (2.27937 iter/s, 5.26462s/12 iters), loss = 1.73867
I0422 01:14:28.798918 16011 solver.cpp:237]     Train net output #0: loss = 1.73867 (* 1 = 1.73867 loss)
I0422 01:14:28.798928 16011 sgd_solver.cpp:105] Iteration 2916, lr = 0.00561233
I0422 01:14:34.129688 16011 solver.cpp:218] Iteration 2928 (2.25114 iter/s, 5.33063s/12 iters), loss = 1.87689
I0422 01:14:34.129832 16011 solver.cpp:237]     Train net output #0: loss = 1.87689 (* 1 = 1.87689 loss)
I0422 01:14:34.129842 16011 sgd_solver.cpp:105] Iteration 2928, lr = 0.00559901
I0422 01:14:36.081773 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:14:39.451635 16011 solver.cpp:218] Iteration 2940 (2.25493 iter/s, 5.32167s/12 iters), loss = 1.73869
I0422 01:14:39.451680 16011 solver.cpp:237]     Train net output #0: loss = 1.73869 (* 1 = 1.73869 loss)
I0422 01:14:39.451689 16011 sgd_solver.cpp:105] Iteration 2940, lr = 0.00558572
I0422 01:14:44.575384 16011 solver.cpp:218] Iteration 2952 (2.34212 iter/s, 5.12357s/12 iters), loss = 1.59589
I0422 01:14:44.575423 16011 solver.cpp:237]     Train net output #0: loss = 1.59589 (* 1 = 1.59589 loss)
I0422 01:14:44.575431 16011 sgd_solver.cpp:105] Iteration 2952, lr = 0.00557245
I0422 01:14:46.665138 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_2958.caffemodel
I0422 01:14:49.777261 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_2958.solverstate
I0422 01:14:52.092449 16011 solver.cpp:330] Iteration 2958, Testing net (#0)
I0422 01:14:52.092475 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:14:55.301815 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:14:56.502085 16011 solver.cpp:397]     Test net output #0: accuracy = 0.3125
I0422 01:14:56.502132 16011 solver.cpp:397]     Test net output #1: loss = 3.06357 (* 1 = 3.06357 loss)
I0422 01:14:58.294602 16011 solver.cpp:218] Iteration 2964 (0.874709 iter/s, 13.7188s/12 iters), loss = 1.85597
I0422 01:14:58.294651 16011 solver.cpp:237]     Train net output #0: loss = 1.85597 (* 1 = 1.85597 loss)
I0422 01:14:58.294661 16011 sgd_solver.cpp:105] Iteration 2964, lr = 0.00555922
I0422 01:15:03.745231 16011 solver.cpp:218] Iteration 2976 (2.20166 iter/s, 5.45044s/12 iters), loss = 1.49465
I0422 01:15:03.745276 16011 solver.cpp:237]     Train net output #0: loss = 1.49465 (* 1 = 1.49465 loss)
I0422 01:15:03.745288 16011 sgd_solver.cpp:105] Iteration 2976, lr = 0.00554603
I0422 01:15:08.884479 16011 solver.cpp:218] Iteration 2988 (2.33505 iter/s, 5.13907s/12 iters), loss = 2.03298
I0422 01:15:08.888067 16011 solver.cpp:237]     Train net output #0: loss = 2.03298 (* 1 = 2.03298 loss)
I0422 01:15:08.888077 16011 sgd_solver.cpp:105] Iteration 2988, lr = 0.00553286
I0422 01:15:14.115279 16011 solver.cpp:218] Iteration 3000 (2.29574 iter/s, 5.22708s/12 iters), loss = 1.53034
I0422 01:15:14.115327 16011 solver.cpp:237]     Train net output #0: loss = 1.53034 (* 1 = 1.53034 loss)
I0422 01:15:14.115339 16011 sgd_solver.cpp:105] Iteration 3000, lr = 0.00551972
I0422 01:15:19.340972 16011 solver.cpp:218] Iteration 3012 (2.29643 iter/s, 5.22551s/12 iters), loss = 1.50467
I0422 01:15:19.341013 16011 solver.cpp:237]     Train net output #0: loss = 1.50467 (* 1 = 1.50467 loss)
I0422 01:15:19.341023 16011 sgd_solver.cpp:105] Iteration 3012, lr = 0.00550662
I0422 01:15:24.495119 16011 solver.cpp:218] Iteration 3024 (2.3283 iter/s, 5.15397s/12 iters), loss = 1.85887
I0422 01:15:24.495157 16011 solver.cpp:237]     Train net output #0: loss = 1.85887 (* 1 = 1.85887 loss)
I0422 01:15:24.495164 16011 sgd_solver.cpp:105] Iteration 3024, lr = 0.00549354
I0422 01:15:28.698668 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:15:29.746109 16011 solver.cpp:218] Iteration 3036 (2.28536 iter/s, 5.25082s/12 iters), loss = 1.3461
I0422 01:15:29.746155 16011 solver.cpp:237]     Train net output #0: loss = 1.3461 (* 1 = 1.3461 loss)
I0422 01:15:29.746163 16011 sgd_solver.cpp:105] Iteration 3036, lr = 0.0054805
I0422 01:15:34.945276 16011 solver.cpp:218] Iteration 3048 (2.30814 iter/s, 5.19899s/12 iters), loss = 1.30816
I0422 01:15:34.945318 16011 solver.cpp:237]     Train net output #0: loss = 1.30816 (* 1 = 1.30816 loss)
I0422 01:15:34.945327 16011 sgd_solver.cpp:105] Iteration 3048, lr = 0.00546749
I0422 01:15:39.746342 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_3060.caffemodel
I0422 01:15:42.746436 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3060.solverstate
I0422 01:15:45.054195 16011 solver.cpp:330] Iteration 3060, Testing net (#0)
I0422 01:15:45.054221 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:15:48.263501 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:15:49.548414 16011 solver.cpp:397]     Test net output #0: accuracy = 0.308824
I0422 01:15:49.548452 16011 solver.cpp:397]     Test net output #1: loss = 3.06429 (* 1 = 3.06429 loss)
I0422 01:15:49.644867 16011 solver.cpp:218] Iteration 3060 (0.816371 iter/s, 14.6992s/12 iters), loss = 1.69832
I0422 01:15:49.644909 16011 solver.cpp:237]     Train net output #0: loss = 1.69832 (* 1 = 1.69832 loss)
I0422 01:15:49.644918 16011 sgd_solver.cpp:105] Iteration 3060, lr = 0.00545451
I0422 01:15:53.873930 16011 solver.cpp:218] Iteration 3072 (2.83761 iter/s, 4.22891s/12 iters), loss = 1.40839
I0422 01:15:53.873967 16011 solver.cpp:237]     Train net output #0: loss = 1.40839 (* 1 = 1.40839 loss)
I0422 01:15:53.873977 16011 sgd_solver.cpp:105] Iteration 3072, lr = 0.00544156
I0422 01:15:59.260119 16011 solver.cpp:218] Iteration 3084 (2.22799 iter/s, 5.38601s/12 iters), loss = 1.56093
I0422 01:15:59.260174 16011 solver.cpp:237]     Train net output #0: loss = 1.56093 (* 1 = 1.56093 loss)
I0422 01:15:59.260185 16011 sgd_solver.cpp:105] Iteration 3084, lr = 0.00542864
I0422 01:16:04.552287 16011 solver.cpp:218] Iteration 3096 (2.26758 iter/s, 5.29197s/12 iters), loss = 1.73607
I0422 01:16:04.552341 16011 solver.cpp:237]     Train net output #0: loss = 1.73607 (* 1 = 1.73607 loss)
I0422 01:16:04.552352 16011 sgd_solver.cpp:105] Iteration 3096, lr = 0.00541575
I0422 01:16:10.004772 16011 solver.cpp:218] Iteration 3108 (2.20091 iter/s, 5.45229s/12 iters), loss = 1.65188
I0422 01:16:10.005017 16011 solver.cpp:237]     Train net output #0: loss = 1.65188 (* 1 = 1.65188 loss)
I0422 01:16:10.005028 16011 sgd_solver.cpp:105] Iteration 3108, lr = 0.00540289
I0422 01:16:15.223906 16011 solver.cpp:218] Iteration 3120 (2.2994 iter/s, 5.21876s/12 iters), loss = 1.30189
I0422 01:16:15.223948 16011 solver.cpp:237]     Train net output #0: loss = 1.30189 (* 1 = 1.30189 loss)
I0422 01:16:15.223958 16011 sgd_solver.cpp:105] Iteration 3120, lr = 0.00539006
I0422 01:16:20.572068 16011 solver.cpp:218] Iteration 3132 (2.24384 iter/s, 5.34798s/12 iters), loss = 1.87039
I0422 01:16:20.572106 16011 solver.cpp:237]     Train net output #0: loss = 1.87039 (* 1 = 1.87039 loss)
I0422 01:16:20.572116 16011 sgd_solver.cpp:105] Iteration 3132, lr = 0.00537727
I0422 01:16:21.774571 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:16:25.849099 16011 solver.cpp:218] Iteration 3144 (2.27408 iter/s, 5.27686s/12 iters), loss = 1.63306
I0422 01:16:25.849135 16011 solver.cpp:237]     Train net output #0: loss = 1.63306 (* 1 = 1.63306 loss)
I0422 01:16:25.849143 16011 sgd_solver.cpp:105] Iteration 3144, lr = 0.0053645
I0422 01:16:30.978763 16011 solver.cpp:218] Iteration 3156 (2.33941 iter/s, 5.12949s/12 iters), loss = 1.45358
I0422 01:16:30.978808 16011 solver.cpp:237]     Train net output #0: loss = 1.45358 (* 1 = 1.45358 loss)
I0422 01:16:30.978816 16011 sgd_solver.cpp:105] Iteration 3156, lr = 0.00535176
I0422 01:16:33.058254 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_3162.caffemodel
I0422 01:16:36.049911 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3162.solverstate
I0422 01:16:39.606109 16011 solver.cpp:330] Iteration 3162, Testing net (#0)
I0422 01:16:39.606135 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:16:42.715270 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:16:43.995040 16011 solver.cpp:397]     Test net output #0: accuracy = 0.313726
I0422 01:16:43.995072 16011 solver.cpp:397]     Test net output #1: loss = 3.07148 (* 1 = 3.07148 loss)
I0422 01:16:45.930963 16011 solver.cpp:218] Iteration 3168 (0.802579 iter/s, 14.9518s/12 iters), loss = 1.465
I0422 01:16:45.931006 16011 solver.cpp:237]     Train net output #0: loss = 1.465 (* 1 = 1.465 loss)
I0422 01:16:45.931015 16011 sgd_solver.cpp:105] Iteration 3168, lr = 0.00533906
I0422 01:16:51.114667 16011 solver.cpp:218] Iteration 3180 (2.31503 iter/s, 5.18353s/12 iters), loss = 1.11215
I0422 01:16:51.114710 16011 solver.cpp:237]     Train net output #0: loss = 1.11215 (* 1 = 1.11215 loss)
I0422 01:16:51.114719 16011 sgd_solver.cpp:105] Iteration 3180, lr = 0.00532638
I0422 01:16:56.350965 16011 solver.cpp:218] Iteration 3192 (2.29178 iter/s, 5.23611s/12 iters), loss = 1.24541
I0422 01:16:56.351007 16011 solver.cpp:237]     Train net output #0: loss = 1.24541 (* 1 = 1.24541 loss)
I0422 01:16:56.351016 16011 sgd_solver.cpp:105] Iteration 3192, lr = 0.00531374
I0422 01:17:01.640548 16011 solver.cpp:218] Iteration 3204 (2.26869 iter/s, 5.28941s/12 iters), loss = 1.5493
I0422 01:17:01.640589 16011 solver.cpp:237]     Train net output #0: loss = 1.5493 (* 1 = 1.5493 loss)
I0422 01:17:01.640599 16011 sgd_solver.cpp:105] Iteration 3204, lr = 0.00530112
I0422 01:17:06.869457 16011 solver.cpp:218] Iteration 3216 (2.29501 iter/s, 5.22873s/12 iters), loss = 1.2843
I0422 01:17:06.869498 16011 solver.cpp:237]     Train net output #0: loss = 1.2843 (* 1 = 1.2843 loss)
I0422 01:17:06.869508 16011 sgd_solver.cpp:105] Iteration 3216, lr = 0.00528853
I0422 01:17:12.094416 16011 solver.cpp:218] Iteration 3228 (2.29675 iter/s, 5.22478s/12 iters), loss = 1.60204
I0422 01:17:12.094465 16011 solver.cpp:237]     Train net output #0: loss = 1.60204 (* 1 = 1.60204 loss)
I0422 01:17:12.094475 16011 sgd_solver.cpp:105] Iteration 3228, lr = 0.00527598
I0422 01:17:15.606986 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:17:17.420315 16011 solver.cpp:218] Iteration 3240 (2.25322 iter/s, 5.32572s/12 iters), loss = 1.72776
I0422 01:17:17.420358 16011 solver.cpp:237]     Train net output #0: loss = 1.72776 (* 1 = 1.72776 loss)
I0422 01:17:17.420368 16011 sgd_solver.cpp:105] Iteration 3240, lr = 0.00526345
I0422 01:17:22.719951 16011 solver.cpp:218] Iteration 3252 (2.26438 iter/s, 5.29946s/12 iters), loss = 1.2111
I0422 01:17:22.719990 16011 solver.cpp:237]     Train net output #0: loss = 1.2111 (* 1 = 1.2111 loss)
I0422 01:17:22.720000 16011 sgd_solver.cpp:105] Iteration 3252, lr = 0.00525095
I0422 01:17:27.282002 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_3264.caffemodel
I0422 01:17:31.431655 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3264.solverstate
I0422 01:17:34.287993 16011 solver.cpp:330] Iteration 3264, Testing net (#0)
I0422 01:17:34.288017 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:17:37.366559 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:17:38.683612 16011 solver.cpp:397]     Test net output #0: accuracy = 0.342524
I0422 01:17:38.683647 16011 solver.cpp:397]     Test net output #1: loss = 2.91338 (* 1 = 2.91338 loss)
I0422 01:17:38.779501 16011 solver.cpp:218] Iteration 3264 (0.747239 iter/s, 16.0591s/12 iters), loss = 1.10269
I0422 01:17:38.779541 16011 solver.cpp:237]     Train net output #0: loss = 1.10269 (* 1 = 1.10269 loss)
I0422 01:17:38.779551 16011 sgd_solver.cpp:105] Iteration 3264, lr = 0.00523849
I0422 01:17:42.872040 16011 solver.cpp:218] Iteration 3276 (2.93227 iter/s, 4.09239s/12 iters), loss = 1.25978
I0422 01:17:42.872081 16011 solver.cpp:237]     Train net output #0: loss = 1.25978 (* 1 = 1.25978 loss)
I0422 01:17:42.872089 16011 sgd_solver.cpp:105] Iteration 3276, lr = 0.00522605
I0422 01:17:48.258997 16011 solver.cpp:218] Iteration 3288 (2.22768 iter/s, 5.38678s/12 iters), loss = 1.33592
I0422 01:17:48.259090 16011 solver.cpp:237]     Train net output #0: loss = 1.33592 (* 1 = 1.33592 loss)
I0422 01:17:48.259101 16011 sgd_solver.cpp:105] Iteration 3288, lr = 0.00521364
I0422 01:17:53.388034 16011 solver.cpp:218] Iteration 3300 (2.33972 iter/s, 5.12881s/12 iters), loss = 1.52713
I0422 01:17:53.388083 16011 solver.cpp:237]     Train net output #0: loss = 1.52713 (* 1 = 1.52713 loss)
I0422 01:17:53.388094 16011 sgd_solver.cpp:105] Iteration 3300, lr = 0.00520126
I0422 01:17:58.508255 16011 solver.cpp:218] Iteration 3312 (2.34373 iter/s, 5.12004s/12 iters), loss = 1.29476
I0422 01:17:58.508301 16011 solver.cpp:237]     Train net output #0: loss = 1.29476 (* 1 = 1.29476 loss)
I0422 01:17:58.508311 16011 sgd_solver.cpp:105] Iteration 3312, lr = 0.00518892
I0422 01:18:03.644981 16011 solver.cpp:218] Iteration 3324 (2.3362 iter/s, 5.13654s/12 iters), loss = 1.18884
I0422 01:18:03.645035 16011 solver.cpp:237]     Train net output #0: loss = 1.18884 (* 1 = 1.18884 loss)
I0422 01:18:03.645051 16011 sgd_solver.cpp:105] Iteration 3324, lr = 0.0051766
I0422 01:18:08.945912 16011 solver.cpp:218] Iteration 3336 (2.26383 iter/s, 5.30075s/12 iters), loss = 1.20231
I0422 01:18:08.945951 16011 solver.cpp:237]     Train net output #0: loss = 1.20231 (* 1 = 1.20231 loss)
I0422 01:18:08.945962 16011 sgd_solver.cpp:105] Iteration 3336, lr = 0.00516431
I0422 01:18:09.438784 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:18:13.985525 16011 solver.cpp:218] Iteration 3348 (2.38122 iter/s, 5.03944s/12 iters), loss = 1.35758
I0422 01:18:13.985572 16011 solver.cpp:237]     Train net output #0: loss = 1.35758 (* 1 = 1.35758 loss)
I0422 01:18:13.985584 16011 sgd_solver.cpp:105] Iteration 3348, lr = 0.00515204
I0422 01:18:19.104254 16011 solver.cpp:218] Iteration 3360 (2.34442 iter/s, 5.11853s/12 iters), loss = 1.39213
I0422 01:18:19.106400 16011 solver.cpp:237]     Train net output #0: loss = 1.39213 (* 1 = 1.39213 loss)
I0422 01:18:19.106410 16011 sgd_solver.cpp:105] Iteration 3360, lr = 0.00513981
I0422 01:18:21.200636 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_3366.caffemodel
I0422 01:18:24.212683 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3366.solverstate
I0422 01:18:26.499325 16011 solver.cpp:330] Iteration 3366, Testing net (#0)
I0422 01:18:26.499346 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:18:29.857421 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:18:31.243649 16011 solver.cpp:397]     Test net output #0: accuracy = 0.321691
I0422 01:18:31.243695 16011 solver.cpp:397]     Test net output #1: loss = 2.98661 (* 1 = 2.98661 loss)
I0422 01:18:33.192549 16011 solver.cpp:218] Iteration 3372 (0.851921 iter/s, 14.0858s/12 iters), loss = 1.24197
I0422 01:18:33.192592 16011 solver.cpp:237]     Train net output #0: loss = 1.24197 (* 1 = 1.24197 loss)
I0422 01:18:33.192600 16011 sgd_solver.cpp:105] Iteration 3372, lr = 0.00512761
I0422 01:18:38.597651 16011 solver.cpp:218] Iteration 3384 (2.2202 iter/s, 5.40492s/12 iters), loss = 1.58914
I0422 01:18:38.597692 16011 solver.cpp:237]     Train net output #0: loss = 1.58914 (* 1 = 1.58914 loss)
I0422 01:18:38.597702 16011 sgd_solver.cpp:105] Iteration 3384, lr = 0.00511544
I0422 01:18:43.907788 16011 solver.cpp:218] Iteration 3396 (2.25991 iter/s, 5.30996s/12 iters), loss = 1.35128
I0422 01:18:43.907836 16011 solver.cpp:237]     Train net output #0: loss = 1.35128 (* 1 = 1.35128 loss)
I0422 01:18:43.907846 16011 sgd_solver.cpp:105] Iteration 3396, lr = 0.00510329
I0422 01:18:49.089332 16011 solver.cpp:218] Iteration 3408 (2.316 iter/s, 5.18136s/12 iters), loss = 1.5573
I0422 01:18:49.089372 16011 solver.cpp:237]     Train net output #0: loss = 1.5573 (* 1 = 1.5573 loss)
I0422 01:18:49.089381 16011 sgd_solver.cpp:105] Iteration 3408, lr = 0.00509117
I0422 01:18:54.431691 16011 solver.cpp:218] Iteration 3420 (2.24627 iter/s, 5.34218s/12 iters), loss = 1.01567
I0422 01:18:54.431802 16011 solver.cpp:237]     Train net output #0: loss = 1.01567 (* 1 = 1.01567 loss)
I0422 01:18:54.431816 16011 sgd_solver.cpp:105] Iteration 3420, lr = 0.00507909
I0422 01:18:59.611949 16011 solver.cpp:218] Iteration 3432 (2.3166 iter/s, 5.18001s/12 iters), loss = 0.906431
I0422 01:18:59.611992 16011 solver.cpp:237]     Train net output #0: loss = 0.906431 (* 1 = 0.906431 loss)
I0422 01:18:59.612004 16011 sgd_solver.cpp:105] Iteration 3432, lr = 0.00506703
I0422 01:19:02.344960 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:19:04.819900 16011 solver.cpp:218] Iteration 3444 (2.30425 iter/s, 5.20778s/12 iters), loss = 1.3242
I0422 01:19:04.819941 16011 solver.cpp:237]     Train net output #0: loss = 1.3242 (* 1 = 1.3242 loss)
I0422 01:19:04.819950 16011 sgd_solver.cpp:105] Iteration 3444, lr = 0.005055
I0422 01:19:09.925879 16011 solver.cpp:218] Iteration 3456 (2.35027 iter/s, 5.1058s/12 iters), loss = 1.19173
I0422 01:19:09.925922 16011 solver.cpp:237]     Train net output #0: loss = 1.19173 (* 1 = 1.19173 loss)
I0422 01:19:09.925932 16011 sgd_solver.cpp:105] Iteration 3456, lr = 0.005043
I0422 01:19:14.598803 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_3468.caffemodel
I0422 01:19:20.486263 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3468.solverstate
I0422 01:19:27.637766 16011 solver.cpp:330] Iteration 3468, Testing net (#0)
I0422 01:19:27.637881 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:19:28.043947 16011 blocking_queue.cpp:49] Waiting for data
I0422 01:19:30.652673 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:19:32.045202 16011 solver.cpp:397]     Test net output #0: accuracy = 0.318015
I0422 01:19:32.045231 16011 solver.cpp:397]     Test net output #1: loss = 2.98236 (* 1 = 2.98236 loss)
I0422 01:19:32.140115 16011 solver.cpp:218] Iteration 3468 (0.540208 iter/s, 22.2137s/12 iters), loss = 1.18301
I0422 01:19:32.140154 16011 solver.cpp:237]     Train net output #0: loss = 1.18301 (* 1 = 1.18301 loss)
I0422 01:19:32.140163 16011 sgd_solver.cpp:105] Iteration 3468, lr = 0.00503102
I0422 01:19:36.415771 16011 solver.cpp:218] Iteration 3480 (2.80669 iter/s, 4.2755s/12 iters), loss = 1.55496
I0422 01:19:36.415812 16011 solver.cpp:237]     Train net output #0: loss = 1.55496 (* 1 = 1.55496 loss)
I0422 01:19:36.415820 16011 sgd_solver.cpp:105] Iteration 3480, lr = 0.00501908
I0422 01:19:41.640975 16011 solver.cpp:218] Iteration 3492 (2.29664 iter/s, 5.22502s/12 iters), loss = 1.03019
I0422 01:19:41.641016 16011 solver.cpp:237]     Train net output #0: loss = 1.03019 (* 1 = 1.03019 loss)
I0422 01:19:41.641026 16011 sgd_solver.cpp:105] Iteration 3492, lr = 0.00500716
I0422 01:19:47.023705 16011 solver.cpp:218] Iteration 3504 (2.22943 iter/s, 5.38255s/12 iters), loss = 1.17795
I0422 01:19:47.023749 16011 solver.cpp:237]     Train net output #0: loss = 1.17795 (* 1 = 1.17795 loss)
I0422 01:19:47.023759 16011 sgd_solver.cpp:105] Iteration 3504, lr = 0.00499527
I0422 01:19:52.296444 16011 solver.cpp:218] Iteration 3516 (2.27593 iter/s, 5.27256s/12 iters), loss = 1.50005
I0422 01:19:52.296483 16011 solver.cpp:237]     Train net output #0: loss = 1.50005 (* 1 = 1.50005 loss)
I0422 01:19:52.296525 16011 sgd_solver.cpp:105] Iteration 3516, lr = 0.00498341
I0422 01:19:57.525817 16011 solver.cpp:218] Iteration 3528 (2.29481 iter/s, 5.22919s/12 iters), loss = 1.05379
I0422 01:19:57.525866 16011 solver.cpp:237]     Train net output #0: loss = 1.05379 (* 1 = 1.05379 loss)
I0422 01:19:57.525874 16011 sgd_solver.cpp:105] Iteration 3528, lr = 0.00497158
I0422 01:20:02.613051 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:20:02.904947 16011 solver.cpp:218] Iteration 3540 (2.23092 iter/s, 5.37894s/12 iters), loss = 1.13422
I0422 01:20:02.904986 16011 solver.cpp:237]     Train net output #0: loss = 1.13422 (* 1 = 1.13422 loss)
I0422 01:20:02.904995 16011 sgd_solver.cpp:105] Iteration 3540, lr = 0.00495978
I0422 01:20:08.113346 16011 solver.cpp:218] Iteration 3552 (2.30405 iter/s, 5.20822s/12 iters), loss = 1.24985
I0422 01:20:08.113389 16011 solver.cpp:237]     Train net output #0: loss = 1.24985 (* 1 = 1.24985 loss)
I0422 01:20:08.113399 16011 sgd_solver.cpp:105] Iteration 3552, lr = 0.004948
I0422 01:20:13.388913 16011 solver.cpp:218] Iteration 3564 (2.27471 iter/s, 5.27539s/12 iters), loss = 1.27975
I0422 01:20:13.388952 16011 solver.cpp:237]     Train net output #0: loss = 1.27975 (* 1 = 1.27975 loss)
I0422 01:20:13.388960 16011 sgd_solver.cpp:105] Iteration 3564, lr = 0.00493626
I0422 01:20:15.496737 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_3570.caffemodel
I0422 01:20:18.512840 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3570.solverstate
I0422 01:20:20.835822 16011 solver.cpp:330] Iteration 3570, Testing net (#0)
I0422 01:20:20.835845 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:20:24.030527 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:20:25.463276 16011 solver.cpp:397]     Test net output #0: accuracy = 0.340074
I0422 01:20:25.463325 16011 solver.cpp:397]     Test net output #1: loss = 2.95958 (* 1 = 2.95958 loss)
I0422 01:20:27.388634 16011 solver.cpp:218] Iteration 3576 (0.857183 iter/s, 13.9993s/12 iters), loss = 1.36351
I0422 01:20:27.388677 16011 solver.cpp:237]     Train net output #0: loss = 1.36351 (* 1 = 1.36351 loss)
I0422 01:20:27.388687 16011 sgd_solver.cpp:105] Iteration 3576, lr = 0.00492454
I0422 01:20:32.737792 16011 solver.cpp:218] Iteration 3588 (2.24342 iter/s, 5.34897s/12 iters), loss = 1.01566
I0422 01:20:32.737948 16011 solver.cpp:237]     Train net output #0: loss = 1.01566 (* 1 = 1.01566 loss)
I0422 01:20:32.737959 16011 sgd_solver.cpp:105] Iteration 3588, lr = 0.00491284
I0422 01:20:38.067423 16011 solver.cpp:218] Iteration 3600 (2.25169 iter/s, 5.32934s/12 iters), loss = 1.21986
I0422 01:20:38.067471 16011 solver.cpp:237]     Train net output #0: loss = 1.21986 (* 1 = 1.21986 loss)
I0422 01:20:38.067481 16011 sgd_solver.cpp:105] Iteration 3600, lr = 0.00490118
I0422 01:20:43.163550 16011 solver.cpp:218] Iteration 3612 (2.35481 iter/s, 5.09594s/12 iters), loss = 0.893039
I0422 01:20:43.163594 16011 solver.cpp:237]     Train net output #0: loss = 0.893039 (* 1 = 0.893039 loss)
I0422 01:20:43.163604 16011 sgd_solver.cpp:105] Iteration 3612, lr = 0.00488954
I0422 01:20:48.357357 16011 solver.cpp:218] Iteration 3624 (2.31053 iter/s, 5.19362s/12 iters), loss = 0.841379
I0422 01:20:48.357411 16011 solver.cpp:237]     Train net output #0: loss = 0.841379 (* 1 = 0.841379 loss)
I0422 01:20:48.357422 16011 sgd_solver.cpp:105] Iteration 3624, lr = 0.00487793
I0422 01:20:53.777875 16011 solver.cpp:218] Iteration 3636 (2.21389 iter/s, 5.42033s/12 iters), loss = 1.07648
I0422 01:20:53.777915 16011 solver.cpp:237]     Train net output #0: loss = 1.07648 (* 1 = 1.07648 loss)
I0422 01:20:53.777925 16011 sgd_solver.cpp:105] Iteration 3636, lr = 0.00486635
I0422 01:20:55.771121 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:20:59.078477 16011 solver.cpp:218] Iteration 3648 (2.26397 iter/s, 5.30043s/12 iters), loss = 1.05586
I0422 01:20:59.078512 16011 solver.cpp:237]     Train net output #0: loss = 1.05586 (* 1 = 1.05586 loss)
I0422 01:20:59.078521 16011 sgd_solver.cpp:105] Iteration 3648, lr = 0.0048548
I0422 01:21:04.172308 16011 solver.cpp:218] Iteration 3660 (2.35587 iter/s, 5.09366s/12 iters), loss = 0.941375
I0422 01:21:04.172436 16011 solver.cpp:237]     Train net output #0: loss = 0.941375 (* 1 = 0.941375 loss)
I0422 01:21:04.172446 16011 sgd_solver.cpp:105] Iteration 3660, lr = 0.00484327
I0422 01:21:08.955055 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_3672.caffemodel
I0422 01:21:12.469094 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3672.solverstate
I0422 01:21:15.335681 16011 solver.cpp:330] Iteration 3672, Testing net (#0)
I0422 01:21:15.335705 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:21:18.390148 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:21:19.869678 16011 solver.cpp:397]     Test net output #0: accuracy = 0.335784
I0422 01:21:19.869709 16011 solver.cpp:397]     Test net output #1: loss = 3.07512 (* 1 = 3.07512 loss)
I0422 01:21:19.965227 16011 solver.cpp:218] Iteration 3672 (0.759859 iter/s, 15.7924s/12 iters), loss = 0.869218
I0422 01:21:19.965271 16011 solver.cpp:237]     Train net output #0: loss = 0.869218 (* 1 = 0.869218 loss)
I0422 01:21:19.965281 16011 sgd_solver.cpp:105] Iteration 3672, lr = 0.00483177
I0422 01:21:24.293793 16011 solver.cpp:218] Iteration 3684 (2.77239 iter/s, 4.3284s/12 iters), loss = 1.00083
I0422 01:21:24.293848 16011 solver.cpp:237]     Train net output #0: loss = 1.00083 (* 1 = 1.00083 loss)
I0422 01:21:24.293859 16011 sgd_solver.cpp:105] Iteration 3684, lr = 0.0048203
I0422 01:21:29.599524 16011 solver.cpp:218] Iteration 3696 (2.26179 iter/s, 5.30554s/12 iters), loss = 0.824658
I0422 01:21:29.599568 16011 solver.cpp:237]     Train net output #0: loss = 0.824658 (* 1 = 0.824658 loss)
I0422 01:21:29.599576 16011 sgd_solver.cpp:105] Iteration 3696, lr = 0.00480886
I0422 01:21:34.768234 16011 solver.cpp:218] Iteration 3708 (2.32175 iter/s, 5.16852s/12 iters), loss = 1.36255
I0422 01:21:34.768393 16011 solver.cpp:237]     Train net output #0: loss = 1.36255 (* 1 = 1.36255 loss)
I0422 01:21:34.768407 16011 sgd_solver.cpp:105] Iteration 3708, lr = 0.00479744
I0422 01:21:40.024065 16011 solver.cpp:218] Iteration 3720 (2.28331 iter/s, 5.25553s/12 iters), loss = 1.07655
I0422 01:21:40.024112 16011 solver.cpp:237]     Train net output #0: loss = 1.07655 (* 1 = 1.07655 loss)
I0422 01:21:40.024121 16011 sgd_solver.cpp:105] Iteration 3720, lr = 0.00478605
I0422 01:21:45.168143 16011 solver.cpp:218] Iteration 3732 (2.33286 iter/s, 5.1439s/12 iters), loss = 0.852276
I0422 01:21:45.168184 16011 solver.cpp:237]     Train net output #0: loss = 0.852276 (* 1 = 0.852276 loss)
I0422 01:21:45.168193 16011 sgd_solver.cpp:105] Iteration 3732, lr = 0.00477469
I0422 01:21:49.302937 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:21:50.320252 16011 solver.cpp:218] Iteration 3744 (2.32922 iter/s, 5.15194s/12 iters), loss = 0.858054
I0422 01:21:50.320291 16011 solver.cpp:237]     Train net output #0: loss = 0.858054 (* 1 = 0.858054 loss)
I0422 01:21:50.320298 16011 sgd_solver.cpp:105] Iteration 3744, lr = 0.00476335
I0422 01:21:55.638850 16011 solver.cpp:218] Iteration 3756 (2.25631 iter/s, 5.31842s/12 iters), loss = 0.694049
I0422 01:21:55.638895 16011 solver.cpp:237]     Train net output #0: loss = 0.694049 (* 1 = 0.694049 loss)
I0422 01:21:55.638903 16011 sgd_solver.cpp:105] Iteration 3756, lr = 0.00475204
I0422 01:22:00.850610 16011 solver.cpp:218] Iteration 3768 (2.30256 iter/s, 5.21158s/12 iters), loss = 0.842245
I0422 01:22:00.850647 16011 solver.cpp:237]     Train net output #0: loss = 0.842245 (* 1 = 0.842245 loss)
I0422 01:22:00.850656 16011 sgd_solver.cpp:105] Iteration 3768, lr = 0.00474076
I0422 01:22:02.925715 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_3774.caffemodel
I0422 01:22:06.471944 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3774.solverstate
I0422 01:22:10.291396 16011 solver.cpp:330] Iteration 3774, Testing net (#0)
I0422 01:22:10.291419 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:22:13.165598 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:22:14.732645 16011 solver.cpp:397]     Test net output #0: accuracy = 0.330882
I0422 01:22:14.732682 16011 solver.cpp:397]     Test net output #1: loss = 3.24064 (* 1 = 3.24064 loss)
I0422 01:22:16.563303 16011 solver.cpp:218] Iteration 3780 (0.763734 iter/s, 15.7123s/12 iters), loss = 1.02097
I0422 01:22:16.563341 16011 solver.cpp:237]     Train net output #0: loss = 1.02097 (* 1 = 1.02097 loss)
I0422 01:22:16.563350 16011 sgd_solver.cpp:105] Iteration 3780, lr = 0.00472951
I0422 01:22:21.774878 16011 solver.cpp:218] Iteration 3792 (2.30265 iter/s, 5.21139s/12 iters), loss = 0.983482
I0422 01:22:21.774930 16011 solver.cpp:237]     Train net output #0: loss = 0.983482 (* 1 = 0.983482 loss)
I0422 01:22:21.774940 16011 sgd_solver.cpp:105] Iteration 3792, lr = 0.00471828
I0422 01:22:27.039935 16011 solver.cpp:218] Iteration 3804 (2.27926 iter/s, 5.26487s/12 iters), loss = 1.09263
I0422 01:22:27.039976 16011 solver.cpp:237]     Train net output #0: loss = 1.09263 (* 1 = 1.09263 loss)
I0422 01:22:27.039986 16011 sgd_solver.cpp:105] Iteration 3804, lr = 0.00470707
I0422 01:22:32.262252 16011 solver.cpp:218] Iteration 3816 (2.29791 iter/s, 5.22215s/12 iters), loss = 1.00128
I0422 01:22:32.262288 16011 solver.cpp:237]     Train net output #0: loss = 1.00128 (* 1 = 1.00128 loss)
I0422 01:22:32.262296 16011 sgd_solver.cpp:105] Iteration 3816, lr = 0.0046959
I0422 01:22:37.576747 16011 solver.cpp:218] Iteration 3828 (2.25805 iter/s, 5.31431s/12 iters), loss = 1.21943
I0422 01:22:37.576920 16011 solver.cpp:237]     Train net output #0: loss = 1.21943 (* 1 = 1.21943 loss)
I0422 01:22:37.576933 16011 sgd_solver.cpp:105] Iteration 3828, lr = 0.00468475
I0422 01:22:42.872148 16011 solver.cpp:218] Iteration 3840 (2.26625 iter/s, 5.2951s/12 iters), loss = 0.95886
I0422 01:22:42.872189 16011 solver.cpp:237]     Train net output #0: loss = 0.95886 (* 1 = 0.95886 loss)
I0422 01:22:42.872197 16011 sgd_solver.cpp:105] Iteration 3840, lr = 0.00467363
I0422 01:22:44.044593 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:22:48.238926 16011 solver.cpp:218] Iteration 3852 (2.23605 iter/s, 5.3666s/12 iters), loss = 0.910184
I0422 01:22:48.238968 16011 solver.cpp:237]     Train net output #0: loss = 0.910184 (* 1 = 0.910184 loss)
I0422 01:22:48.238976 16011 sgd_solver.cpp:105] Iteration 3852, lr = 0.00466253
I0422 01:22:53.634672 16011 solver.cpp:218] Iteration 3864 (2.22405 iter/s, 5.39557s/12 iters), loss = 0.842651
I0422 01:22:53.634713 16011 solver.cpp:237]     Train net output #0: loss = 0.842651 (* 1 = 0.842651 loss)
I0422 01:22:53.634722 16011 sgd_solver.cpp:105] Iteration 3864, lr = 0.00465146
I0422 01:22:58.452122 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_3876.caffemodel
I0422 01:23:06.358018 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3876.solverstate
I0422 01:23:09.248677 16011 solver.cpp:330] Iteration 3876, Testing net (#0)
I0422 01:23:09.248812 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:23:12.126262 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:23:13.792150 16011 solver.cpp:397]     Test net output #0: accuracy = 0.33027
I0422 01:23:13.792193 16011 solver.cpp:397]     Test net output #1: loss = 3.2097 (* 1 = 3.2097 loss)
I0422 01:23:13.887420 16011 solver.cpp:218] Iteration 3876 (0.592528 iter/s, 20.2522s/12 iters), loss = 0.855714
I0422 01:23:13.887460 16011 solver.cpp:237]     Train net output #0: loss = 0.855714 (* 1 = 0.855714 loss)
I0422 01:23:13.887471 16011 sgd_solver.cpp:105] Iteration 3876, lr = 0.00464042
I0422 01:23:18.226047 16011 solver.cpp:218] Iteration 3888 (2.76595 iter/s, 4.33847s/12 iters), loss = 0.904856
I0422 01:23:18.226089 16011 solver.cpp:237]     Train net output #0: loss = 0.904856 (* 1 = 0.904856 loss)
I0422 01:23:18.226099 16011 sgd_solver.cpp:105] Iteration 3888, lr = 0.0046294
I0422 01:23:23.406431 16011 solver.cpp:218] Iteration 3900 (2.31651 iter/s, 5.1802s/12 iters), loss = 1.17787
I0422 01:23:23.406482 16011 solver.cpp:237]     Train net output #0: loss = 1.17787 (* 1 = 1.17787 loss)
I0422 01:23:23.406492 16011 sgd_solver.cpp:105] Iteration 3900, lr = 0.00461841
I0422 01:23:28.584012 16011 solver.cpp:218] Iteration 3912 (2.31777 iter/s, 5.17739s/12 iters), loss = 0.911082
I0422 01:23:28.584053 16011 solver.cpp:237]     Train net output #0: loss = 0.911082 (* 1 = 0.911082 loss)
I0422 01:23:28.584062 16011 sgd_solver.cpp:105] Iteration 3912, lr = 0.00460744
I0422 01:23:33.875520 16011 solver.cpp:218] Iteration 3924 (2.26786 iter/s, 5.29133s/12 iters), loss = 0.722544
I0422 01:23:33.875567 16011 solver.cpp:237]     Train net output #0: loss = 0.722544 (* 1 = 0.722544 loss)
I0422 01:23:33.875577 16011 sgd_solver.cpp:105] Iteration 3924, lr = 0.0045965
I0422 01:23:39.061944 16011 solver.cpp:218] Iteration 3936 (2.31382 iter/s, 5.18624s/12 iters), loss = 1.00573
I0422 01:23:39.061986 16011 solver.cpp:237]     Train net output #0: loss = 1.00573 (* 1 = 1.00573 loss)
I0422 01:23:39.061995 16011 sgd_solver.cpp:105] Iteration 3936, lr = 0.00458559
I0422 01:23:42.669492 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:23:44.315809 16011 solver.cpp:218] Iteration 3948 (2.28411 iter/s, 5.25369s/12 iters), loss = 0.587181
I0422 01:23:44.315855 16011 solver.cpp:237]     Train net output #0: loss = 0.587181 (* 1 = 0.587181 loss)
I0422 01:23:44.315865 16011 sgd_solver.cpp:105] Iteration 3948, lr = 0.0045747
I0422 01:23:49.455430 16011 solver.cpp:218] Iteration 3960 (2.33488 iter/s, 5.13944s/12 iters), loss = 0.983089
I0422 01:23:49.455474 16011 solver.cpp:237]     Train net output #0: loss = 0.983089 (* 1 = 0.983089 loss)
I0422 01:23:49.455483 16011 sgd_solver.cpp:105] Iteration 3960, lr = 0.00456384
I0422 01:23:54.589579 16011 solver.cpp:218] Iteration 3972 (2.33737 iter/s, 5.13397s/12 iters), loss = 1.06977
I0422 01:23:54.589622 16011 solver.cpp:237]     Train net output #0: loss = 1.06977 (* 1 = 1.06977 loss)
I0422 01:23:54.589632 16011 sgd_solver.cpp:105] Iteration 3972, lr = 0.00455301
I0422 01:23:56.627615 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_3978.caffemodel
I0422 01:24:01.986862 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_3978.solverstate
I0422 01:24:08.447257 16011 solver.cpp:330] Iteration 3978, Testing net (#0)
I0422 01:24:08.447283 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:24:11.346724 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:24:13.017403 16011 solver.cpp:397]     Test net output #0: accuracy = 0.338235
I0422 01:24:13.017508 16011 solver.cpp:397]     Test net output #1: loss = 3.22417 (* 1 = 3.22417 loss)
I0422 01:24:14.984956 16011 solver.cpp:218] Iteration 3984 (0.588384 iter/s, 20.3948s/12 iters), loss = 1.02448
I0422 01:24:14.985000 16011 solver.cpp:237]     Train net output #0: loss = 1.02448 (* 1 = 1.02448 loss)
I0422 01:24:14.985014 16011 sgd_solver.cpp:105] Iteration 3984, lr = 0.0045422
I0422 01:24:20.059347 16011 solver.cpp:218] Iteration 3996 (2.3649 iter/s, 5.07421s/12 iters), loss = 0.87843
I0422 01:24:20.059394 16011 solver.cpp:237]     Train net output #0: loss = 0.87843 (* 1 = 0.87843 loss)
I0422 01:24:20.059404 16011 sgd_solver.cpp:105] Iteration 3996, lr = 0.00453141
I0422 01:24:25.129202 16011 solver.cpp:218] Iteration 4008 (2.36702 iter/s, 5.06967s/12 iters), loss = 0.865175
I0422 01:24:25.129259 16011 solver.cpp:237]     Train net output #0: loss = 0.865175 (* 1 = 0.865175 loss)
I0422 01:24:25.129271 16011 sgd_solver.cpp:105] Iteration 4008, lr = 0.00452066
I0422 01:24:30.465616 16011 solver.cpp:218] Iteration 4020 (2.24879 iter/s, 5.33621s/12 iters), loss = 0.763587
I0422 01:24:30.465668 16011 solver.cpp:237]     Train net output #0: loss = 0.763587 (* 1 = 0.763587 loss)
I0422 01:24:30.465678 16011 sgd_solver.cpp:105] Iteration 4020, lr = 0.00450992
I0422 01:24:35.583225 16011 solver.cpp:218] Iteration 4032 (2.34493 iter/s, 5.11742s/12 iters), loss = 0.556507
I0422 01:24:35.583277 16011 solver.cpp:237]     Train net output #0: loss = 0.556507 (* 1 = 0.556507 loss)
I0422 01:24:35.583289 16011 sgd_solver.cpp:105] Iteration 4032, lr = 0.00449921
I0422 01:24:40.977566 16011 solver.cpp:218] Iteration 4044 (2.22463 iter/s, 5.39415s/12 iters), loss = 0.846032
I0422 01:24:40.977618 16011 solver.cpp:237]     Train net output #0: loss = 0.846032 (* 1 = 0.846032 loss)
I0422 01:24:40.977629 16011 sgd_solver.cpp:105] Iteration 4044, lr = 0.00448853
I0422 01:24:41.494606 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:24:46.225155 16011 solver.cpp:218] Iteration 4056 (2.28685 iter/s, 5.2474s/12 iters), loss = 0.809165
I0422 01:24:46.225275 16011 solver.cpp:237]     Train net output #0: loss = 0.809165 (* 1 = 0.809165 loss)
I0422 01:24:46.225287 16011 sgd_solver.cpp:105] Iteration 4056, lr = 0.00447788
I0422 01:24:51.530580 16011 solver.cpp:218] Iteration 4068 (2.26195 iter/s, 5.30517s/12 iters), loss = 0.575931
I0422 01:24:51.530622 16011 solver.cpp:237]     Train net output #0: loss = 0.575931 (* 1 = 0.575931 loss)
I0422 01:24:51.530632 16011 sgd_solver.cpp:105] Iteration 4068, lr = 0.00446724
I0422 01:24:56.181155 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_4080.caffemodel
I0422 01:25:03.885375 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4080.solverstate
I0422 01:25:11.907013 16011 solver.cpp:330] Iteration 4080, Testing net (#0)
I0422 01:25:11.907035 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:25:14.667307 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:25:16.299860 16011 solver.cpp:397]     Test net output #0: accuracy = 0.363358
I0422 01:25:16.299968 16011 solver.cpp:397]     Test net output #1: loss = 3.04147 (* 1 = 3.04147 loss)
I0422 01:25:16.395390 16011 solver.cpp:218] Iteration 4080 (0.482622 iter/s, 24.8642s/12 iters), loss = 0.821522
I0422 01:25:16.395431 16011 solver.cpp:237]     Train net output #0: loss = 0.821522 (* 1 = 0.821522 loss)
I0422 01:25:16.395440 16011 sgd_solver.cpp:105] Iteration 4080, lr = 0.00445664
I0422 01:25:20.835711 16011 solver.cpp:218] Iteration 4092 (2.70261 iter/s, 4.44016s/12 iters), loss = 0.712853
I0422 01:25:20.835752 16011 solver.cpp:237]     Train net output #0: loss = 0.712853 (* 1 = 0.712853 loss)
I0422 01:25:20.835762 16011 sgd_solver.cpp:105] Iteration 4092, lr = 0.00444606
I0422 01:25:26.052981 16011 solver.cpp:218] Iteration 4104 (2.30013 iter/s, 5.21709s/12 iters), loss = 0.737641
I0422 01:25:26.053025 16011 solver.cpp:237]     Train net output #0: loss = 0.737641 (* 1 = 0.737641 loss)
I0422 01:25:26.053035 16011 sgd_solver.cpp:105] Iteration 4104, lr = 0.0044355
I0422 01:25:31.180732 16011 solver.cpp:218] Iteration 4116 (2.34029 iter/s, 5.12756s/12 iters), loss = 0.819839
I0422 01:25:31.180776 16011 solver.cpp:237]     Train net output #0: loss = 0.819839 (* 1 = 0.819839 loss)
I0422 01:25:31.180788 16011 sgd_solver.cpp:105] Iteration 4116, lr = 0.00442497
I0422 01:25:36.496641 16011 solver.cpp:218] Iteration 4128 (2.25745 iter/s, 5.31572s/12 iters), loss = 0.838911
I0422 01:25:36.496685 16011 solver.cpp:237]     Train net output #0: loss = 0.838911 (* 1 = 0.838911 loss)
I0422 01:25:36.496695 16011 sgd_solver.cpp:105] Iteration 4128, lr = 0.00441447
I0422 01:25:41.818934 16011 solver.cpp:218] Iteration 4140 (2.25474 iter/s, 5.32211s/12 iters), loss = 0.747038
I0422 01:25:41.818974 16011 solver.cpp:237]     Train net output #0: loss = 0.747038 (* 1 = 0.747038 loss)
I0422 01:25:41.818984 16011 sgd_solver.cpp:105] Iteration 4140, lr = 0.00440398
I0422 01:25:44.671979 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:25:47.175911 16011 solver.cpp:218] Iteration 4152 (2.24014 iter/s, 5.3568s/12 iters), loss = 0.552329
I0422 01:25:47.176028 16011 solver.cpp:237]     Train net output #0: loss = 0.552329 (* 1 = 0.552329 loss)
I0422 01:25:47.176040 16011 sgd_solver.cpp:105] Iteration 4152, lr = 0.00439353
I0422 01:25:48.839529 16011 blocking_queue.cpp:49] Waiting for data
I0422 01:25:52.481856 16011 solver.cpp:218] Iteration 4164 (2.26172 iter/s, 5.30569s/12 iters), loss = 0.839423
I0422 01:25:52.481914 16011 solver.cpp:237]     Train net output #0: loss = 0.839423 (* 1 = 0.839423 loss)
I0422 01:25:52.481926 16011 sgd_solver.cpp:105] Iteration 4164, lr = 0.0043831
I0422 01:25:57.619963 16011 solver.cpp:218] Iteration 4176 (2.33557 iter/s, 5.13792s/12 iters), loss = 0.983584
I0422 01:25:57.620000 16011 solver.cpp:237]     Train net output #0: loss = 0.983584 (* 1 = 0.983584 loss)
I0422 01:25:57.620009 16011 sgd_solver.cpp:105] Iteration 4176, lr = 0.00437269
I0422 01:25:59.821458 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_4182.caffemodel
I0422 01:26:08.349968 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4182.solverstate
I0422 01:26:14.527405 16011 solver.cpp:330] Iteration 4182, Testing net (#0)
I0422 01:26:14.527431 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:26:17.361626 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:26:19.040719 16011 solver.cpp:397]     Test net output #0: accuracy = 0.348039
I0422 01:26:19.040750 16011 solver.cpp:397]     Test net output #1: loss = 3.18008 (* 1 = 3.18008 loss)
I0422 01:26:20.976341 16011 solver.cpp:218] Iteration 4188 (0.513791 iter/s, 23.3558s/12 iters), loss = 0.602018
I0422 01:26:20.976380 16011 solver.cpp:237]     Train net output #0: loss = 0.602018 (* 1 = 0.602018 loss)
I0422 01:26:20.976389 16011 sgd_solver.cpp:105] Iteration 4188, lr = 0.00436231
I0422 01:26:26.244544 16011 solver.cpp:218] Iteration 4200 (2.27789 iter/s, 5.26802s/12 iters), loss = 0.798173
I0422 01:26:26.244590 16011 solver.cpp:237]     Train net output #0: loss = 0.798173 (* 1 = 0.798173 loss)
I0422 01:26:26.244601 16011 sgd_solver.cpp:105] Iteration 4200, lr = 0.00435195
I0422 01:26:31.476794 16011 solver.cpp:218] Iteration 4212 (2.29355 iter/s, 5.23207s/12 iters), loss = 0.800529
I0422 01:26:31.476833 16011 solver.cpp:237]     Train net output #0: loss = 0.800529 (* 1 = 0.800529 loss)
I0422 01:26:31.476841 16011 sgd_solver.cpp:105] Iteration 4212, lr = 0.00434162
I0422 01:26:36.711483 16011 solver.cpp:218] Iteration 4224 (2.29248 iter/s, 5.23451s/12 iters), loss = 0.85698
I0422 01:26:36.711524 16011 solver.cpp:237]     Train net output #0: loss = 0.85698 (* 1 = 0.85698 loss)
I0422 01:26:36.711532 16011 sgd_solver.cpp:105] Iteration 4224, lr = 0.00433131
I0422 01:26:41.861546 16011 solver.cpp:218] Iteration 4236 (2.33015 iter/s, 5.14989s/12 iters), loss = 0.586536
I0422 01:26:41.861583 16011 solver.cpp:237]     Train net output #0: loss = 0.586536 (* 1 = 0.586536 loss)
I0422 01:26:41.861591 16011 sgd_solver.cpp:105] Iteration 4236, lr = 0.00432103
I0422 01:26:46.844808 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:26:47.101871 16011 solver.cpp:218] Iteration 4248 (2.29001 iter/s, 5.24015s/12 iters), loss = 0.596527
I0422 01:26:47.101918 16011 solver.cpp:237]     Train net output #0: loss = 0.596527 (* 1 = 0.596527 loss)
I0422 01:26:47.101928 16011 sgd_solver.cpp:105] Iteration 4248, lr = 0.00431077
I0422 01:26:52.239395 16011 solver.cpp:218] Iteration 4260 (2.33584 iter/s, 5.13734s/12 iters), loss = 0.602165
I0422 01:26:52.239533 16011 solver.cpp:237]     Train net output #0: loss = 0.602165 (* 1 = 0.602165 loss)
I0422 01:26:52.239543 16011 sgd_solver.cpp:105] Iteration 4260, lr = 0.00430053
I0422 01:26:57.439158 16011 solver.cpp:218] Iteration 4272 (2.30792 iter/s, 5.19949s/12 iters), loss = 0.776535
I0422 01:26:57.439205 16011 solver.cpp:237]     Train net output #0: loss = 0.776535 (* 1 = 0.776535 loss)
I0422 01:26:57.439218 16011 sgd_solver.cpp:105] Iteration 4272, lr = 0.00429032
I0422 01:27:02.121912 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_4284.caffemodel
I0422 01:27:07.513677 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4284.solverstate
I0422 01:27:11.234403 16011 solver.cpp:330] Iteration 4284, Testing net (#0)
I0422 01:27:11.234424 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:27:14.044627 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:27:15.757050 16011 solver.cpp:397]     Test net output #0: accuracy = 0.369485
I0422 01:27:15.757094 16011 solver.cpp:397]     Test net output #1: loss = 2.98598 (* 1 = 2.98598 loss)
I0422 01:27:15.852283 16011 solver.cpp:218] Iteration 4284 (0.651726 iter/s, 18.4126s/12 iters), loss = 0.526759
I0422 01:27:15.852331 16011 solver.cpp:237]     Train net output #0: loss = 0.526759 (* 1 = 0.526759 loss)
I0422 01:27:15.852344 16011 sgd_solver.cpp:105] Iteration 4284, lr = 0.00428014
I0422 01:27:20.318087 16011 solver.cpp:218] Iteration 4296 (2.68719 iter/s, 4.46564s/12 iters), loss = 0.812493
I0422 01:27:20.318126 16011 solver.cpp:237]     Train net output #0: loss = 0.812493 (* 1 = 0.812493 loss)
I0422 01:27:20.318135 16011 sgd_solver.cpp:105] Iteration 4296, lr = 0.00426998
I0422 01:27:25.510663 16011 solver.cpp:218] Iteration 4308 (2.31107 iter/s, 5.1924s/12 iters), loss = 0.496137
I0422 01:27:25.510763 16011 solver.cpp:237]     Train net output #0: loss = 0.496137 (* 1 = 0.496137 loss)
I0422 01:27:25.510773 16011 sgd_solver.cpp:105] Iteration 4308, lr = 0.00425984
I0422 01:27:30.659170 16011 solver.cpp:218] Iteration 4320 (2.33088 iter/s, 5.14827s/12 iters), loss = 0.633079
I0422 01:27:30.659217 16011 solver.cpp:237]     Train net output #0: loss = 0.633079 (* 1 = 0.633079 loss)
I0422 01:27:30.659225 16011 sgd_solver.cpp:105] Iteration 4320, lr = 0.00424972
I0422 01:27:35.797823 16011 solver.cpp:218] Iteration 4332 (2.33533 iter/s, 5.13847s/12 iters), loss = 0.675359
I0422 01:27:35.797865 16011 solver.cpp:237]     Train net output #0: loss = 0.675359 (* 1 = 0.675359 loss)
I0422 01:27:35.797874 16011 sgd_solver.cpp:105] Iteration 4332, lr = 0.00423964
I0422 01:27:41.138006 16011 solver.cpp:218] Iteration 4344 (2.24719 iter/s, 5.34s/12 iters), loss = 0.667129
I0422 01:27:41.138049 16011 solver.cpp:237]     Train net output #0: loss = 0.667129 (* 1 = 0.667129 loss)
I0422 01:27:41.138058 16011 sgd_solver.cpp:105] Iteration 4344, lr = 0.00422957
I0422 01:27:43.233139 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:27:46.390688 16011 solver.cpp:218] Iteration 4356 (2.28463 iter/s, 5.2525s/12 iters), loss = 0.522094
I0422 01:27:46.390727 16011 solver.cpp:237]     Train net output #0: loss = 0.522094 (* 1 = 0.522094 loss)
I0422 01:27:46.390736 16011 sgd_solver.cpp:105] Iteration 4356, lr = 0.00421953
I0422 01:27:51.494398 16011 solver.cpp:218] Iteration 4368 (2.35131 iter/s, 5.10354s/12 iters), loss = 0.644826
I0422 01:27:51.494437 16011 solver.cpp:237]     Train net output #0: loss = 0.644826 (* 1 = 0.644826 loss)
I0422 01:27:51.494446 16011 sgd_solver.cpp:105] Iteration 4368, lr = 0.00420951
I0422 01:27:56.624680 16011 solver.cpp:218] Iteration 4380 (2.33913 iter/s, 5.13011s/12 iters), loss = 0.903377
I0422 01:27:56.624816 16011 solver.cpp:237]     Train net output #0: loss = 0.903377 (* 1 = 0.903377 loss)
I0422 01:27:56.624826 16011 sgd_solver.cpp:105] Iteration 4380, lr = 0.00419952
I0422 01:27:58.756762 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_4386.caffemodel
I0422 01:28:02.637908 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4386.solverstate
I0422 01:28:09.366196 16011 solver.cpp:330] Iteration 4386, Testing net (#0)
I0422 01:28:09.366220 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:28:12.121117 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:28:13.909847 16011 solver.cpp:397]     Test net output #0: accuracy = 0.369485
I0422 01:28:13.909888 16011 solver.cpp:397]     Test net output #1: loss = 3.04016 (* 1 = 3.04016 loss)
I0422 01:28:15.671387 16011 solver.cpp:218] Iteration 4392 (0.63005 iter/s, 19.0461s/12 iters), loss = 0.648724
I0422 01:28:15.671428 16011 solver.cpp:237]     Train net output #0: loss = 0.648724 (* 1 = 0.648724 loss)
I0422 01:28:15.671437 16011 sgd_solver.cpp:105] Iteration 4392, lr = 0.00418954
I0422 01:28:21.154340 16011 solver.cpp:218] Iteration 4404 (2.18868 iter/s, 5.48276s/12 iters), loss = 0.660785
I0422 01:28:21.154393 16011 solver.cpp:237]     Train net output #0: loss = 0.660785 (* 1 = 0.660785 loss)
I0422 01:28:21.154407 16011 sgd_solver.cpp:105] Iteration 4404, lr = 0.0041796
I0422 01:28:26.511445 16011 solver.cpp:218] Iteration 4416 (2.2401 iter/s, 5.35691s/12 iters), loss = 0.608422
I0422 01:28:26.511497 16011 solver.cpp:237]     Train net output #0: loss = 0.608422 (* 1 = 0.608422 loss)
I0422 01:28:26.511507 16011 sgd_solver.cpp:105] Iteration 4416, lr = 0.00416967
I0422 01:28:31.856009 16011 solver.cpp:218] Iteration 4428 (2.24535 iter/s, 5.34437s/12 iters), loss = 0.664069
I0422 01:28:31.856117 16011 solver.cpp:237]     Train net output #0: loss = 0.664069 (* 1 = 0.664069 loss)
I0422 01:28:31.856127 16011 sgd_solver.cpp:105] Iteration 4428, lr = 0.00415977
I0422 01:28:37.079802 16011 solver.cpp:218] Iteration 4440 (2.29729 iter/s, 5.22355s/12 iters), loss = 0.708636
I0422 01:28:37.079847 16011 solver.cpp:237]     Train net output #0: loss = 0.708636 (* 1 = 0.708636 loss)
I0422 01:28:37.079856 16011 sgd_solver.cpp:105] Iteration 4440, lr = 0.0041499
I0422 01:28:41.248400 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:28:42.251924 16011 solver.cpp:218] Iteration 4452 (2.32021 iter/s, 5.17194s/12 iters), loss = 0.627201
I0422 01:28:42.251966 16011 solver.cpp:237]     Train net output #0: loss = 0.627201 (* 1 = 0.627201 loss)
I0422 01:28:42.251976 16011 sgd_solver.cpp:105] Iteration 4452, lr = 0.00414005
I0422 01:28:47.690696 16011 solver.cpp:218] Iteration 4464 (2.20645 iter/s, 5.43859s/12 iters), loss = 0.571794
I0422 01:28:47.690742 16011 solver.cpp:237]     Train net output #0: loss = 0.571794 (* 1 = 0.571794 loss)
I0422 01:28:47.690752 16011 sgd_solver.cpp:105] Iteration 4464, lr = 0.00413022
I0422 01:28:53.283705 16011 solver.cpp:218] Iteration 4476 (2.14561 iter/s, 5.59283s/12 iters), loss = 0.477844
I0422 01:28:53.283736 16011 solver.cpp:237]     Train net output #0: loss = 0.477844 (* 1 = 0.477844 loss)
I0422 01:28:53.283744 16011 sgd_solver.cpp:105] Iteration 4476, lr = 0.00412041
I0422 01:28:57.994593 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_4488.caffemodel
I0422 01:29:01.123028 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4488.solverstate
I0422 01:29:05.431442 16011 solver.cpp:330] Iteration 4488, Testing net (#0)
I0422 01:29:05.431545 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:29:08.085129 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:29:09.868942 16011 solver.cpp:397]     Test net output #0: accuracy = 0.403186
I0422 01:29:09.868976 16011 solver.cpp:397]     Test net output #1: loss = 2.96979 (* 1 = 2.96979 loss)
I0422 01:29:09.963634 16011 solver.cpp:218] Iteration 4488 (0.719446 iter/s, 16.6795s/12 iters), loss = 0.614857
I0422 01:29:09.963673 16011 solver.cpp:237]     Train net output #0: loss = 0.614857 (* 1 = 0.614857 loss)
I0422 01:29:09.963682 16011 sgd_solver.cpp:105] Iteration 4488, lr = 0.00411063
I0422 01:29:14.251260 16011 solver.cpp:218] Iteration 4500 (2.79885 iter/s, 4.28747s/12 iters), loss = 0.615486
I0422 01:29:14.251302 16011 solver.cpp:237]     Train net output #0: loss = 0.615486 (* 1 = 0.615486 loss)
I0422 01:29:14.251309 16011 sgd_solver.cpp:105] Iteration 4500, lr = 0.00410087
I0422 01:29:19.377822 16011 solver.cpp:218] Iteration 4512 (2.34083 iter/s, 5.12639s/12 iters), loss = 0.423845
I0422 01:29:19.377866 16011 solver.cpp:237]     Train net output #0: loss = 0.423845 (* 1 = 0.423845 loss)
I0422 01:29:19.377876 16011 sgd_solver.cpp:105] Iteration 4512, lr = 0.00409113
I0422 01:29:24.472899 16011 solver.cpp:218] Iteration 4524 (2.3553 iter/s, 5.0949s/12 iters), loss = 0.591439
I0422 01:29:24.472939 16011 solver.cpp:237]     Train net output #0: loss = 0.591439 (* 1 = 0.591439 loss)
I0422 01:29:24.472946 16011 sgd_solver.cpp:105] Iteration 4524, lr = 0.00408142
I0422 01:29:29.699443 16011 solver.cpp:218] Iteration 4536 (2.29605 iter/s, 5.22637s/12 iters), loss = 0.56153
I0422 01:29:29.699484 16011 solver.cpp:237]     Train net output #0: loss = 0.56153 (* 1 = 0.56153 loss)
I0422 01:29:29.699492 16011 sgd_solver.cpp:105] Iteration 4536, lr = 0.00407173
I0422 01:29:34.854919 16011 solver.cpp:218] Iteration 4548 (2.3277 iter/s, 5.15529s/12 iters), loss = 0.448604
I0422 01:29:34.854974 16011 solver.cpp:237]     Train net output #0: loss = 0.448604 (* 1 = 0.448604 loss)
I0422 01:29:34.854987 16011 sgd_solver.cpp:105] Iteration 4548, lr = 0.00406206
I0422 01:29:36.261078 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:29:40.126238 16011 solver.cpp:218] Iteration 4560 (2.27655 iter/s, 5.27114s/12 iters), loss = 0.745171
I0422 01:29:40.126274 16011 solver.cpp:237]     Train net output #0: loss = 0.745171 (* 1 = 0.745171 loss)
I0422 01:29:40.126282 16011 sgd_solver.cpp:105] Iteration 4560, lr = 0.00405242
I0422 01:29:45.555685 16011 solver.cpp:218] Iteration 4572 (2.21024 iter/s, 5.42927s/12 iters), loss = 0.687842
I0422 01:29:45.555732 16011 solver.cpp:237]     Train net output #0: loss = 0.687842 (* 1 = 0.687842 loss)
I0422 01:29:45.555742 16011 sgd_solver.cpp:105] Iteration 4572, lr = 0.0040428
I0422 01:29:50.711184 16011 solver.cpp:218] Iteration 4584 (2.3277 iter/s, 5.15531s/12 iters), loss = 0.640155
I0422 01:29:50.711236 16011 solver.cpp:237]     Train net output #0: loss = 0.640155 (* 1 = 0.640155 loss)
I0422 01:29:50.711246 16011 sgd_solver.cpp:105] Iteration 4584, lr = 0.0040332
I0422 01:29:52.970818 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_4590.caffemodel
I0422 01:29:58.135768 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4590.solverstate
I0422 01:30:02.517365 16011 solver.cpp:330] Iteration 4590, Testing net (#0)
I0422 01:30:02.517385 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:30:05.319717 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:30:07.193229 16011 solver.cpp:397]     Test net output #0: accuracy = 0.38848
I0422 01:30:07.193356 16011 solver.cpp:397]     Test net output #1: loss = 3.09412 (* 1 = 3.09412 loss)
I0422 01:30:09.232708 16011 solver.cpp:218] Iteration 4596 (0.647912 iter/s, 18.521s/12 iters), loss = 0.545751
I0422 01:30:09.232750 16011 solver.cpp:237]     Train net output #0: loss = 0.545751 (* 1 = 0.545751 loss)
I0422 01:30:09.232759 16011 sgd_solver.cpp:105] Iteration 4596, lr = 0.00402362
I0422 01:30:14.658200 16011 solver.cpp:218] Iteration 4608 (2.21186 iter/s, 5.4253s/12 iters), loss = 0.40095
I0422 01:30:14.658244 16011 solver.cpp:237]     Train net output #0: loss = 0.40095 (* 1 = 0.40095 loss)
I0422 01:30:14.658253 16011 sgd_solver.cpp:105] Iteration 4608, lr = 0.00401407
I0422 01:30:20.100659 16011 solver.cpp:218] Iteration 4620 (2.20496 iter/s, 5.44227s/12 iters), loss = 0.509236
I0422 01:30:20.100711 16011 solver.cpp:237]     Train net output #0: loss = 0.509236 (* 1 = 0.509236 loss)
I0422 01:30:20.100721 16011 sgd_solver.cpp:105] Iteration 4620, lr = 0.00400454
I0422 01:30:25.255784 16011 solver.cpp:218] Iteration 4632 (2.32787 iter/s, 5.15493s/12 iters), loss = 0.511507
I0422 01:30:25.255833 16011 solver.cpp:237]     Train net output #0: loss = 0.511507 (* 1 = 0.511507 loss)
I0422 01:30:25.255844 16011 sgd_solver.cpp:105] Iteration 4632, lr = 0.00399503
I0422 01:30:30.344080 16011 solver.cpp:218] Iteration 4644 (2.35844 iter/s, 5.08811s/12 iters), loss = 0.318795
I0422 01:30:30.344146 16011 solver.cpp:237]     Train net output #0: loss = 0.318795 (* 1 = 0.318795 loss)
I0422 01:30:30.344161 16011 sgd_solver.cpp:105] Iteration 4644, lr = 0.00398555
I0422 01:30:33.852607 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:30:35.516911 16011 solver.cpp:218] Iteration 4656 (2.3199 iter/s, 5.17263s/12 iters), loss = 0.563798
I0422 01:30:35.516970 16011 solver.cpp:237]     Train net output #0: loss = 0.563798 (* 1 = 0.563798 loss)
I0422 01:30:35.516983 16011 sgd_solver.cpp:105] Iteration 4656, lr = 0.00397608
I0422 01:30:40.786151 16011 solver.cpp:218] Iteration 4668 (2.27745 iter/s, 5.26904s/12 iters), loss = 0.493455
I0422 01:30:40.786280 16011 solver.cpp:237]     Train net output #0: loss = 0.493455 (* 1 = 0.493455 loss)
I0422 01:30:40.786294 16011 sgd_solver.cpp:105] Iteration 4668, lr = 0.00396664
I0422 01:30:45.865897 16011 solver.cpp:218] Iteration 4680 (2.36244 iter/s, 5.07949s/12 iters), loss = 0.414796
I0422 01:30:45.865933 16011 solver.cpp:237]     Train net output #0: loss = 0.414796 (* 1 = 0.414796 loss)
I0422 01:30:45.865942 16011 sgd_solver.cpp:105] Iteration 4680, lr = 0.00395723
I0422 01:30:50.626006 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_4692.caffemodel
I0422 01:30:55.668798 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4692.solverstate
I0422 01:30:57.983917 16011 solver.cpp:330] Iteration 4692, Testing net (#0)
I0422 01:30:57.983935 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:31:00.542922 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:31:02.437464 16011 solver.cpp:397]     Test net output #0: accuracy = 0.38174
I0422 01:31:02.437494 16011 solver.cpp:397]     Test net output #1: loss = 3.12929 (* 1 = 3.12929 loss)
I0422 01:31:02.533891 16011 solver.cpp:218] Iteration 4692 (0.719962 iter/s, 16.6676s/12 iters), loss = 0.693065
I0422 01:31:02.533937 16011 solver.cpp:237]     Train net output #0: loss = 0.693065 (* 1 = 0.693065 loss)
I0422 01:31:02.533946 16011 sgd_solver.cpp:105] Iteration 4692, lr = 0.00394783
I0422 01:31:06.846987 16011 solver.cpp:218] Iteration 4704 (2.78233 iter/s, 4.31293s/12 iters), loss = 0.466756
I0422 01:31:06.847030 16011 solver.cpp:237]     Train net output #0: loss = 0.466756 (* 1 = 0.466756 loss)
I0422 01:31:06.847039 16011 sgd_solver.cpp:105] Iteration 4704, lr = 0.00393846
I0422 01:31:12.210808 16011 solver.cpp:218] Iteration 4716 (2.23729 iter/s, 5.36363s/12 iters), loss = 0.620788
I0422 01:31:12.210968 16011 solver.cpp:237]     Train net output #0: loss = 0.620788 (* 1 = 0.620788 loss)
I0422 01:31:12.210980 16011 sgd_solver.cpp:105] Iteration 4716, lr = 0.00392911
I0422 01:31:17.276409 16011 solver.cpp:218] Iteration 4728 (2.36905 iter/s, 5.06531s/12 iters), loss = 0.462105
I0422 01:31:17.276456 16011 solver.cpp:237]     Train net output #0: loss = 0.462105 (* 1 = 0.462105 loss)
I0422 01:31:17.276466 16011 sgd_solver.cpp:105] Iteration 4728, lr = 0.00391978
I0422 01:31:22.297286 16011 solver.cpp:218] Iteration 4740 (2.39011 iter/s, 5.02069s/12 iters), loss = 0.407104
I0422 01:31:22.297343 16011 solver.cpp:237]     Train net output #0: loss = 0.407104 (* 1 = 0.407104 loss)
I0422 01:31:22.297353 16011 sgd_solver.cpp:105] Iteration 4740, lr = 0.00391047
I0422 01:31:27.416190 16011 solver.cpp:218] Iteration 4752 (2.34434 iter/s, 5.11872s/12 iters), loss = 0.387122
I0422 01:31:27.416229 16011 solver.cpp:237]     Train net output #0: loss = 0.387122 (* 1 = 0.387122 loss)
I0422 01:31:27.416239 16011 sgd_solver.cpp:105] Iteration 4752, lr = 0.00390119
I0422 01:31:27.962119 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:31:32.759894 16011 solver.cpp:218] Iteration 4764 (2.24571 iter/s, 5.34353s/12 iters), loss = 0.444072
I0422 01:31:32.759933 16011 solver.cpp:237]     Train net output #0: loss = 0.444072 (* 1 = 0.444072 loss)
I0422 01:31:32.759944 16011 sgd_solver.cpp:105] Iteration 4764, lr = 0.00389193
I0422 01:31:37.881283 16011 solver.cpp:218] Iteration 4776 (2.34319 iter/s, 5.12121s/12 iters), loss = 0.544367
I0422 01:31:37.881325 16011 solver.cpp:237]     Train net output #0: loss = 0.544367 (* 1 = 0.544367 loss)
I0422 01:31:37.881333 16011 sgd_solver.cpp:105] Iteration 4776, lr = 0.00388269
I0422 01:31:43.001847 16011 solver.cpp:218] Iteration 4788 (2.34357 iter/s, 5.12039s/12 iters), loss = 0.420492
I0422 01:31:43.028120 16011 solver.cpp:237]     Train net output #0: loss = 0.420492 (* 1 = 0.420492 loss)
I0422 01:31:43.028134 16011 sgd_solver.cpp:105] Iteration 4788, lr = 0.00387347
I0422 01:31:45.073889 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_4794.caffemodel
I0422 01:31:50.590030 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4794.solverstate
I0422 01:31:52.889173 16011 solver.cpp:330] Iteration 4794, Testing net (#0)
I0422 01:31:52.889200 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:31:55.365535 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:31:57.356855 16011 solver.cpp:397]     Test net output #0: accuracy = 0.394608
I0422 01:31:57.356885 16011 solver.cpp:397]     Test net output #1: loss = 3.15797 (* 1 = 3.15797 loss)
I0422 01:31:59.250021 16011 solver.cpp:218] Iteration 4800 (0.739758 iter/s, 16.2215s/12 iters), loss = 0.382273
I0422 01:31:59.250080 16011 solver.cpp:237]     Train net output #0: loss = 0.382273 (* 1 = 0.382273 loss)
I0422 01:31:59.250092 16011 sgd_solver.cpp:105] Iteration 4800, lr = 0.00386427
I0422 01:32:04.474316 16011 solver.cpp:218] Iteration 4812 (2.29705 iter/s, 5.2241s/12 iters), loss = 0.398215
I0422 01:32:04.474371 16011 solver.cpp:237]     Train net output #0: loss = 0.398215 (* 1 = 0.398215 loss)
I0422 01:32:04.474383 16011 sgd_solver.cpp:105] Iteration 4812, lr = 0.0038551
I0422 01:32:09.810868 16011 solver.cpp:218] Iteration 4824 (2.24873 iter/s, 5.33636s/12 iters), loss = 0.336567
I0422 01:32:09.810911 16011 solver.cpp:237]     Train net output #0: loss = 0.336567 (* 1 = 0.336567 loss)
I0422 01:32:09.810921 16011 sgd_solver.cpp:105] Iteration 4824, lr = 0.00384594
I0422 01:32:15.074834 16011 solver.cpp:218] Iteration 4836 (2.27973 iter/s, 5.26378s/12 iters), loss = 0.54032
I0422 01:32:15.074990 16011 solver.cpp:237]     Train net output #0: loss = 0.54032 (* 1 = 0.54032 loss)
I0422 01:32:15.075003 16011 sgd_solver.cpp:105] Iteration 4836, lr = 0.00383681
I0422 01:32:17.178210 16011 blocking_queue.cpp:49] Waiting for data
I0422 01:32:20.475647 16011 solver.cpp:218] Iteration 4848 (2.22201 iter/s, 5.40052s/12 iters), loss = 0.482178
I0422 01:32:20.475688 16011 solver.cpp:237]     Train net output #0: loss = 0.482178 (* 1 = 0.482178 loss)
I0422 01:32:20.475697 16011 sgd_solver.cpp:105] Iteration 4848, lr = 0.0038277
I0422 01:32:23.461575 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:32:25.919188 16011 solver.cpp:218] Iteration 4860 (2.20452 iter/s, 5.44336s/12 iters), loss = 0.391077
I0422 01:32:25.919237 16011 solver.cpp:237]     Train net output #0: loss = 0.391077 (* 1 = 0.391077 loss)
I0422 01:32:25.919247 16011 sgd_solver.cpp:105] Iteration 4860, lr = 0.00381862
I0422 01:32:31.048796 16011 solver.cpp:218] Iteration 4872 (2.33944 iter/s, 5.12943s/12 iters), loss = 0.348607
I0422 01:32:31.048838 16011 solver.cpp:237]     Train net output #0: loss = 0.348607 (* 1 = 0.348607 loss)
I0422 01:32:31.048846 16011 sgd_solver.cpp:105] Iteration 4872, lr = 0.00380955
I0422 01:32:36.256290 16011 solver.cpp:218] Iteration 4884 (2.30445 iter/s, 5.20732s/12 iters), loss = 0.559466
I0422 01:32:36.256330 16011 solver.cpp:237]     Train net output #0: loss = 0.559466 (* 1 = 0.559466 loss)
I0422 01:32:36.256340 16011 sgd_solver.cpp:105] Iteration 4884, lr = 0.0038005
I0422 01:32:41.228677 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_4896.caffemodel
I0422 01:33:01.016157 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4896.solverstate
I0422 01:33:05.353665 16011 solver.cpp:330] Iteration 4896, Testing net (#0)
I0422 01:33:05.353688 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:33:08.073423 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:33:10.030644 16011 solver.cpp:397]     Test net output #0: accuracy = 0.389706
I0422 01:33:10.030681 16011 solver.cpp:397]     Test net output #1: loss = 3.14183 (* 1 = 3.14183 loss)
I0422 01:33:10.125890 16011 solver.cpp:218] Iteration 4896 (0.354309 iter/s, 33.8688s/12 iters), loss = 0.340141
I0422 01:33:10.125936 16011 solver.cpp:237]     Train net output #0: loss = 0.340141 (* 1 = 0.340141 loss)
I0422 01:33:10.125944 16011 sgd_solver.cpp:105] Iteration 4896, lr = 0.00379148
I0422 01:33:14.350239 16011 solver.cpp:218] Iteration 4908 (2.84078 iter/s, 4.22419s/12 iters), loss = 0.508034
I0422 01:33:14.350291 16011 solver.cpp:237]     Train net output #0: loss = 0.508034 (* 1 = 0.508034 loss)
I0422 01:33:14.350302 16011 sgd_solver.cpp:105] Iteration 4908, lr = 0.00378248
I0422 01:33:19.521955 16011 solver.cpp:218] Iteration 4920 (2.3204 iter/s, 5.17153s/12 iters), loss = 0.401351
I0422 01:33:19.521994 16011 solver.cpp:237]     Train net output #0: loss = 0.401351 (* 1 = 0.401351 loss)
I0422 01:33:19.522003 16011 sgd_solver.cpp:105] Iteration 4920, lr = 0.0037735
I0422 01:33:24.608593 16011 solver.cpp:218] Iteration 4932 (2.3592 iter/s, 5.08647s/12 iters), loss = 0.284363
I0422 01:33:24.608635 16011 solver.cpp:237]     Train net output #0: loss = 0.284363 (* 1 = 0.284363 loss)
I0422 01:33:24.608644 16011 sgd_solver.cpp:105] Iteration 4932, lr = 0.00376454
I0422 01:33:29.965808 16011 solver.cpp:218] Iteration 4944 (2.24004 iter/s, 5.35704s/12 iters), loss = 0.280218
I0422 01:33:29.965844 16011 solver.cpp:237]     Train net output #0: loss = 0.280218 (* 1 = 0.280218 loss)
I0422 01:33:29.965852 16011 sgd_solver.cpp:105] Iteration 4944, lr = 0.0037556
I0422 01:33:35.082211 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:33:35.297318 16011 solver.cpp:218] Iteration 4956 (2.25085 iter/s, 5.33133s/12 iters), loss = 0.773898
I0422 01:33:35.297365 16011 solver.cpp:237]     Train net output #0: loss = 0.773898 (* 1 = 0.773898 loss)
I0422 01:33:35.297375 16011 sgd_solver.cpp:105] Iteration 4956, lr = 0.00374669
I0422 01:33:40.754139 16011 solver.cpp:218] Iteration 4968 (2.19916 iter/s, 5.45663s/12 iters), loss = 0.479512
I0422 01:33:40.754184 16011 solver.cpp:237]     Train net output #0: loss = 0.479512 (* 1 = 0.479512 loss)
I0422 01:33:40.754194 16011 sgd_solver.cpp:105] Iteration 4968, lr = 0.00373779
I0422 01:33:46.046262 16011 solver.cpp:218] Iteration 4980 (2.2676 iter/s, 5.29194s/12 iters), loss = 0.421874
I0422 01:33:46.046300 16011 solver.cpp:237]     Train net output #0: loss = 0.421874 (* 1 = 0.421874 loss)
I0422 01:33:46.046308 16011 sgd_solver.cpp:105] Iteration 4980, lr = 0.00372892
I0422 01:33:51.216416 16011 solver.cpp:218] Iteration 4992 (2.32109 iter/s, 5.16998s/12 iters), loss = 0.339763
I0422 01:33:51.216464 16011 solver.cpp:237]     Train net output #0: loss = 0.339763 (* 1 = 0.339763 loss)
I0422 01:33:51.216475 16011 sgd_solver.cpp:105] Iteration 4992, lr = 0.00372006
I0422 01:33:53.328917 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_4998.caffemodel
I0422 01:33:57.484251 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_4998.solverstate
I0422 01:34:01.827114 16011 solver.cpp:330] Iteration 4998, Testing net (#0)
I0422 01:34:01.827134 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:34:04.236945 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:34:06.310168 16011 solver.cpp:397]     Test net output #0: accuracy = 0.393382
I0422 01:34:06.310286 16011 solver.cpp:397]     Test net output #1: loss = 3.12422 (* 1 = 3.12422 loss)
I0422 01:34:08.170529 16011 solver.cpp:218] Iteration 5004 (0.707812 iter/s, 16.9537s/12 iters), loss = 0.362196
I0422 01:34:08.170573 16011 solver.cpp:237]     Train net output #0: loss = 0.362196 (* 1 = 0.362196 loss)
I0422 01:34:08.170581 16011 sgd_solver.cpp:105] Iteration 5004, lr = 0.00371123
I0422 01:34:13.430114 16011 solver.cpp:218] Iteration 5016 (2.28163 iter/s, 5.2594s/12 iters), loss = 0.381974
I0422 01:34:13.430160 16011 solver.cpp:237]     Train net output #0: loss = 0.381974 (* 1 = 0.381974 loss)
I0422 01:34:13.430171 16011 sgd_solver.cpp:105] Iteration 5016, lr = 0.00370242
I0422 01:34:18.654031 16011 solver.cpp:218] Iteration 5028 (2.29721 iter/s, 5.22374s/12 iters), loss = 0.509403
I0422 01:34:18.654071 16011 solver.cpp:237]     Train net output #0: loss = 0.509403 (* 1 = 0.509403 loss)
I0422 01:34:18.654080 16011 sgd_solver.cpp:105] Iteration 5028, lr = 0.00369363
I0422 01:34:23.830220 16011 solver.cpp:218] Iteration 5040 (2.31839 iter/s, 5.17601s/12 iters), loss = 0.562006
I0422 01:34:23.830260 16011 solver.cpp:237]     Train net output #0: loss = 0.562006 (* 1 = 0.562006 loss)
I0422 01:34:23.830268 16011 sgd_solver.cpp:105] Iteration 5040, lr = 0.00368486
I0422 01:34:29.281255 16011 solver.cpp:218] Iteration 5052 (2.20149 iter/s, 5.45086s/12 iters), loss = 0.480268
I0422 01:34:29.281289 16011 solver.cpp:237]     Train net output #0: loss = 0.480268 (* 1 = 0.480268 loss)
I0422 01:34:29.281297 16011 sgd_solver.cpp:105] Iteration 5052, lr = 0.00367611
I0422 01:34:31.195761 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:34:34.321099 16011 solver.cpp:218] Iteration 5064 (2.38111 iter/s, 5.03967s/12 iters), loss = 0.527352
I0422 01:34:34.321153 16011 solver.cpp:237]     Train net output #0: loss = 0.527352 (* 1 = 0.527352 loss)
I0422 01:34:34.321164 16011 sgd_solver.cpp:105] Iteration 5064, lr = 0.00366738
I0422 01:34:39.500262 16011 solver.cpp:218] Iteration 5076 (2.31706 iter/s, 5.17897s/12 iters), loss = 0.546381
I0422 01:34:39.500365 16011 solver.cpp:237]     Train net output #0: loss = 0.546381 (* 1 = 0.546381 loss)
I0422 01:34:39.500376 16011 sgd_solver.cpp:105] Iteration 5076, lr = 0.00365868
I0422 01:34:44.617537 16011 solver.cpp:218] Iteration 5088 (2.34511 iter/s, 5.11704s/12 iters), loss = 0.501688
I0422 01:34:44.617591 16011 solver.cpp:237]     Train net output #0: loss = 0.501688 (* 1 = 0.501688 loss)
I0422 01:34:44.617605 16011 sgd_solver.cpp:105] Iteration 5088, lr = 0.00364999
I0422 01:34:49.503427 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_5100.caffemodel
I0422 01:34:52.456782 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_5100.solverstate
I0422 01:34:54.760198 16011 solver.cpp:330] Iteration 5100, Testing net (#0)
I0422 01:34:54.760221 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:34:57.151420 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:34:59.190497 16011 solver.cpp:397]     Test net output #0: accuracy = 0.397059
I0422 01:34:59.190527 16011 solver.cpp:397]     Test net output #1: loss = 3.26971 (* 1 = 3.26971 loss)
I0422 01:34:59.285847 16011 solver.cpp:218] Iteration 5100 (0.818113 iter/s, 14.6679s/12 iters), loss = 0.335177
I0422 01:34:59.285890 16011 solver.cpp:237]     Train net output #0: loss = 0.335177 (* 1 = 0.335177 loss)
I0422 01:34:59.285900 16011 sgd_solver.cpp:105] Iteration 5100, lr = 0.00364132
I0422 01:35:03.782691 16011 solver.cpp:218] Iteration 5112 (2.66864 iter/s, 4.49668s/12 iters), loss = 0.476472
I0422 01:35:03.782737 16011 solver.cpp:237]     Train net output #0: loss = 0.476472 (* 1 = 0.476472 loss)
I0422 01:35:03.782748 16011 sgd_solver.cpp:105] Iteration 5112, lr = 0.00363268
I0422 01:35:08.882321 16011 solver.cpp:218] Iteration 5124 (2.3532 iter/s, 5.09945s/12 iters), loss = 0.305524
I0422 01:35:08.882376 16011 solver.cpp:237]     Train net output #0: loss = 0.305524 (* 1 = 0.305524 loss)
I0422 01:35:08.882388 16011 sgd_solver.cpp:105] Iteration 5124, lr = 0.00362405
I0422 01:35:14.037559 16011 solver.cpp:218] Iteration 5136 (2.32782 iter/s, 5.15505s/12 iters), loss = 0.312386
I0422 01:35:14.037704 16011 solver.cpp:237]     Train net output #0: loss = 0.312386 (* 1 = 0.312386 loss)
I0422 01:35:14.037715 16011 sgd_solver.cpp:105] Iteration 5136, lr = 0.00361545
I0422 01:35:19.234517 16011 solver.cpp:218] Iteration 5148 (2.30917 iter/s, 5.19668s/12 iters), loss = 0.431483
I0422 01:35:19.234561 16011 solver.cpp:237]     Train net output #0: loss = 0.431483 (* 1 = 0.431483 loss)
I0422 01:35:19.234571 16011 sgd_solver.cpp:105] Iteration 5148, lr = 0.00360687
I0422 01:35:23.381356 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:35:24.345108 16011 solver.cpp:218] Iteration 5160 (2.34815 iter/s, 5.11041s/12 iters), loss = 0.474882
I0422 01:35:24.345163 16011 solver.cpp:237]     Train net output #0: loss = 0.474882 (* 1 = 0.474882 loss)
I0422 01:35:24.345176 16011 sgd_solver.cpp:105] Iteration 5160, lr = 0.0035983
I0422 01:35:29.843497 16011 solver.cpp:218] Iteration 5172 (2.18254 iter/s, 5.49819s/12 iters), loss = 0.273668
I0422 01:35:29.843536 16011 solver.cpp:237]     Train net output #0: loss = 0.273668 (* 1 = 0.273668 loss)
I0422 01:35:29.843544 16011 sgd_solver.cpp:105] Iteration 5172, lr = 0.00358976
I0422 01:35:34.974086 16011 solver.cpp:218] Iteration 5184 (2.33899 iter/s, 5.13042s/12 iters), loss = 0.398044
I0422 01:35:34.974126 16011 solver.cpp:237]     Train net output #0: loss = 0.398044 (* 1 = 0.398044 loss)
I0422 01:35:34.974136 16011 sgd_solver.cpp:105] Iteration 5184, lr = 0.00358124
I0422 01:35:40.235122 16011 solver.cpp:218] Iteration 5196 (2.281 iter/s, 5.26086s/12 iters), loss = 0.252894
I0422 01:35:40.235170 16011 solver.cpp:237]     Train net output #0: loss = 0.252893 (* 1 = 0.252893 loss)
I0422 01:35:40.235181 16011 sgd_solver.cpp:105] Iteration 5196, lr = 0.00357273
I0422 01:35:42.356180 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_5202.caffemodel
I0422 01:35:49.968511 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_5202.solverstate
I0422 01:35:57.668174 16011 solver.cpp:330] Iteration 5202, Testing net (#0)
I0422 01:35:57.668198 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:35:59.993991 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:36:02.069339 16011 solver.cpp:397]     Test net output #0: accuracy = 0.409926
I0422 01:36:02.069370 16011 solver.cpp:397]     Test net output #1: loss = 3.01959 (* 1 = 3.01959 loss)
I0422 01:36:03.943975 16011 solver.cpp:218] Iteration 5208 (0.506153 iter/s, 23.7082s/12 iters), loss = 0.33737
I0422 01:36:03.944020 16011 solver.cpp:237]     Train net output #0: loss = 0.33737 (* 1 = 0.33737 loss)
I0422 01:36:03.944027 16011 sgd_solver.cpp:105] Iteration 5208, lr = 0.00356425
I0422 01:36:09.398757 16011 solver.cpp:218] Iteration 5220 (2.19998 iter/s, 5.4546s/12 iters), loss = 0.38272
I0422 01:36:09.398794 16011 solver.cpp:237]     Train net output #0: loss = 0.38272 (* 1 = 0.38272 loss)
I0422 01:36:09.398803 16011 sgd_solver.cpp:105] Iteration 5220, lr = 0.00355579
I0422 01:36:14.525805 16011 solver.cpp:218] Iteration 5232 (2.34061 iter/s, 5.12688s/12 iters), loss = 0.329114
I0422 01:36:14.525848 16011 solver.cpp:237]     Train net output #0: loss = 0.329114 (* 1 = 0.329114 loss)
I0422 01:36:14.525858 16011 sgd_solver.cpp:105] Iteration 5232, lr = 0.00354735
I0422 01:36:19.804714 16011 solver.cpp:218] Iteration 5244 (2.27328 iter/s, 5.27872s/12 iters), loss = 0.434332
I0422 01:36:19.804759 16011 solver.cpp:237]     Train net output #0: loss = 0.434332 (* 1 = 0.434332 loss)
I0422 01:36:19.804767 16011 sgd_solver.cpp:105] Iteration 5244, lr = 0.00353892
I0422 01:36:25.044248 16011 solver.cpp:218] Iteration 5256 (2.29036 iter/s, 5.23935s/12 iters), loss = 0.351448
I0422 01:36:25.044414 16011 solver.cpp:237]     Train net output #0: loss = 0.351448 (* 1 = 0.351448 loss)
I0422 01:36:25.044425 16011 sgd_solver.cpp:105] Iteration 5256, lr = 0.00353052
I0422 01:36:26.396734 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:36:30.213649 16011 solver.cpp:218] Iteration 5268 (2.32149 iter/s, 5.1691s/12 iters), loss = 0.339852
I0422 01:36:30.213690 16011 solver.cpp:237]     Train net output #0: loss = 0.339852 (* 1 = 0.339852 loss)
I0422 01:36:30.213698 16011 sgd_solver.cpp:105] Iteration 5268, lr = 0.00352214
I0422 01:36:35.514889 16011 solver.cpp:218] Iteration 5280 (2.2637 iter/s, 5.30106s/12 iters), loss = 0.515617
I0422 01:36:35.514928 16011 solver.cpp:237]     Train net output #0: loss = 0.515617 (* 1 = 0.515617 loss)
I0422 01:36:35.514937 16011 sgd_solver.cpp:105] Iteration 5280, lr = 0.00351378
I0422 01:36:40.837325 16011 solver.cpp:218] Iteration 5292 (2.25468 iter/s, 5.32225s/12 iters), loss = 0.519283
I0422 01:36:40.837373 16011 solver.cpp:237]     Train net output #0: loss = 0.519282 (* 1 = 0.519282 loss)
I0422 01:36:40.837384 16011 sgd_solver.cpp:105] Iteration 5292, lr = 0.00350544
I0422 01:36:45.704787 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_5304.caffemodel
I0422 01:36:49.123977 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_5304.solverstate
I0422 01:36:55.854729 16011 solver.cpp:330] Iteration 5304, Testing net (#0)
I0422 01:36:55.854817 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:36:58.186484 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:37:00.306424 16011 solver.cpp:397]     Test net output #0: accuracy = 0.397059
I0422 01:37:00.306470 16011 solver.cpp:397]     Test net output #1: loss = 3.0859 (* 1 = 3.0859 loss)
I0422 01:37:00.401571 16011 solver.cpp:218] Iteration 5304 (0.61338 iter/s, 19.5637s/12 iters), loss = 0.385135
I0422 01:37:00.401616 16011 solver.cpp:237]     Train net output #0: loss = 0.385135 (* 1 = 0.385135 loss)
I0422 01:37:00.401628 16011 sgd_solver.cpp:105] Iteration 5304, lr = 0.00349711
I0422 01:37:04.699921 16011 solver.cpp:218] Iteration 5316 (2.79187 iter/s, 4.29819s/12 iters), loss = 0.28448
I0422 01:37:04.699965 16011 solver.cpp:237]     Train net output #0: loss = 0.28448 (* 1 = 0.28448 loss)
I0422 01:37:04.699976 16011 sgd_solver.cpp:105] Iteration 5316, lr = 0.00348881
I0422 01:37:09.863409 16011 solver.cpp:218] Iteration 5328 (2.32409 iter/s, 5.16331s/12 iters), loss = 0.41665
I0422 01:37:09.863451 16011 solver.cpp:237]     Train net output #0: loss = 0.41665 (* 1 = 0.41665 loss)
I0422 01:37:09.863459 16011 sgd_solver.cpp:105] Iteration 5328, lr = 0.00348053
I0422 01:37:15.087829 16011 solver.cpp:218] Iteration 5340 (2.29699 iter/s, 5.22424s/12 iters), loss = 0.325587
I0422 01:37:15.087872 16011 solver.cpp:237]     Train net output #0: loss = 0.325587 (* 1 = 0.325587 loss)
I0422 01:37:15.087880 16011 sgd_solver.cpp:105] Iteration 5340, lr = 0.00347226
I0422 01:37:20.456342 16011 solver.cpp:218] Iteration 5352 (2.23533 iter/s, 5.36833s/12 iters), loss = 0.276587
I0422 01:37:20.456382 16011 solver.cpp:237]     Train net output #0: loss = 0.276587 (* 1 = 0.276587 loss)
I0422 01:37:20.456391 16011 sgd_solver.cpp:105] Iteration 5352, lr = 0.00346402
I0422 01:37:23.945516 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:37:25.555068 16011 solver.cpp:218] Iteration 5364 (2.35361 iter/s, 5.09855s/12 iters), loss = 0.42147
I0422 01:37:25.555112 16011 solver.cpp:237]     Train net output #0: loss = 0.42147 (* 1 = 0.42147 loss)
I0422 01:37:25.555121 16011 sgd_solver.cpp:105] Iteration 5364, lr = 0.0034558
I0422 01:37:30.721642 16011 solver.cpp:218] Iteration 5376 (2.3227 iter/s, 5.1664s/12 iters), loss = 0.41879
I0422 01:37:30.721750 16011 solver.cpp:237]     Train net output #0: loss = 0.41879 (* 1 = 0.41879 loss)
I0422 01:37:30.721760 16011 sgd_solver.cpp:105] Iteration 5376, lr = 0.00344759
I0422 01:37:35.892364 16011 solver.cpp:218] Iteration 5388 (2.32087 iter/s, 5.17048s/12 iters), loss = 0.495192
I0422 01:37:35.892401 16011 solver.cpp:237]     Train net output #0: loss = 0.495192 (* 1 = 0.495192 loss)
I0422 01:37:35.892410 16011 sgd_solver.cpp:105] Iteration 5388, lr = 0.00343941
I0422 01:37:41.333937 16011 solver.cpp:218] Iteration 5400 (2.20532 iter/s, 5.44139s/12 iters), loss = 0.453064
I0422 01:37:41.333987 16011 solver.cpp:237]     Train net output #0: loss = 0.453064 (* 1 = 0.453064 loss)
I0422 01:37:41.333999 16011 sgd_solver.cpp:105] Iteration 5400, lr = 0.00343124
I0422 01:37:43.422302 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_5406.caffemodel
I0422 01:37:49.700217 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_5406.solverstate
I0422 01:37:54.445641 16011 solver.cpp:330] Iteration 5406, Testing net (#0)
I0422 01:37:54.445662 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:37:56.692252 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:37:58.850805 16011 solver.cpp:397]     Test net output #0: accuracy = 0.417279
I0422 01:37:58.850831 16011 solver.cpp:397]     Test net output #1: loss = 3.01969 (* 1 = 3.01969 loss)
I0422 01:38:00.740041 16011 solver.cpp:218] Iteration 5412 (0.618379 iter/s, 19.4056s/12 iters), loss = 0.290878
I0422 01:38:00.740154 16011 solver.cpp:237]     Train net output #0: loss = 0.290878 (* 1 = 0.290878 loss)
I0422 01:38:00.740162 16011 sgd_solver.cpp:105] Iteration 5412, lr = 0.00342309
I0422 01:38:05.907193 16011 solver.cpp:218] Iteration 5424 (2.32247 iter/s, 5.16691s/12 iters), loss = 0.286776
I0422 01:38:05.907235 16011 solver.cpp:237]     Train net output #0: loss = 0.286776 (* 1 = 0.286776 loss)
I0422 01:38:05.907245 16011 sgd_solver.cpp:105] Iteration 5424, lr = 0.00341497
I0422 01:38:11.238400 16011 solver.cpp:218] Iteration 5436 (2.25097 iter/s, 5.33103s/12 iters), loss = 0.265964
I0422 01:38:11.238441 16011 solver.cpp:237]     Train net output #0: loss = 0.265964 (* 1 = 0.265964 loss)
I0422 01:38:11.238451 16011 sgd_solver.cpp:105] Iteration 5436, lr = 0.00340686
I0422 01:38:16.360172 16011 solver.cpp:218] Iteration 5448 (2.34302 iter/s, 5.1216s/12 iters), loss = 0.248508
I0422 01:38:16.360216 16011 solver.cpp:237]     Train net output #0: loss = 0.248508 (* 1 = 0.248508 loss)
I0422 01:38:16.360226 16011 sgd_solver.cpp:105] Iteration 5448, lr = 0.00339877
I0422 01:38:21.534946 16011 solver.cpp:218] Iteration 5460 (2.31902 iter/s, 5.17459s/12 iters), loss = 0.30736
I0422 01:38:21.534989 16011 solver.cpp:237]     Train net output #0: loss = 0.30736 (* 1 = 0.30736 loss)
I0422 01:38:21.534998 16011 sgd_solver.cpp:105] Iteration 5460, lr = 0.0033907
I0422 01:38:22.128860 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:38:26.724305 16011 solver.cpp:218] Iteration 5472 (2.3125 iter/s, 5.18918s/12 iters), loss = 0.319039
I0422 01:38:26.724341 16011 solver.cpp:237]     Train net output #0: loss = 0.319039 (* 1 = 0.319039 loss)
I0422 01:38:26.724350 16011 sgd_solver.cpp:105] Iteration 5472, lr = 0.00338265
I0422 01:38:32.023838 16011 solver.cpp:218] Iteration 5484 (2.26442 iter/s, 5.29936s/12 iters), loss = 0.352657
I0422 01:38:32.024152 16011 solver.cpp:237]     Train net output #0: loss = 0.352657 (* 1 = 0.352657 loss)
I0422 01:38:32.024163 16011 sgd_solver.cpp:105] Iteration 5484, lr = 0.00337462
I0422 01:38:37.242808 16011 solver.cpp:218] Iteration 5496 (2.2995 iter/s, 5.21852s/12 iters), loss = 0.315237
I0422 01:38:37.242849 16011 solver.cpp:237]     Train net output #0: loss = 0.315237 (* 1 = 0.315237 loss)
I0422 01:38:37.242858 16011 sgd_solver.cpp:105] Iteration 5496, lr = 0.00336661
I0422 01:38:41.956235 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_5508.caffemodel
I0422 01:38:50.513958 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_5508.solverstate
I0422 01:38:57.500876 16011 solver.cpp:330] Iteration 5508, Testing net (#0)
I0422 01:38:57.500903 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:38:59.889441 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:39:02.132126 16011 solver.cpp:397]     Test net output #0: accuracy = 0.408701
I0422 01:39:02.132205 16011 solver.cpp:397]     Test net output #1: loss = 3.06995 (* 1 = 3.06995 loss)
I0422 01:39:02.227373 16011 solver.cpp:218] Iteration 5508 (0.480309 iter/s, 24.9839s/12 iters), loss = 0.249427
I0422 01:39:02.227414 16011 solver.cpp:237]     Train net output #0: loss = 0.249427 (* 1 = 0.249427 loss)
I0422 01:39:02.227423 16011 sgd_solver.cpp:105] Iteration 5508, lr = 0.00335861
I0422 01:39:06.426205 16011 solver.cpp:218] Iteration 5520 (2.85804 iter/s, 4.19868s/12 iters), loss = 0.199205
I0422 01:39:06.426242 16011 solver.cpp:237]     Train net output #0: loss = 0.199205 (* 1 = 0.199205 loss)
I0422 01:39:06.426251 16011 sgd_solver.cpp:105] Iteration 5520, lr = 0.00335064
I0422 01:39:08.897722 16011 blocking_queue.cpp:49] Waiting for data
I0422 01:39:11.502802 16011 solver.cpp:218] Iteration 5532 (2.36387 iter/s, 5.07642s/12 iters), loss = 0.380975
I0422 01:39:11.502852 16011 solver.cpp:237]     Train net output #0: loss = 0.380975 (* 1 = 0.380975 loss)
I0422 01:39:11.502864 16011 sgd_solver.cpp:105] Iteration 5532, lr = 0.00334268
I0422 01:39:16.622370 16011 solver.cpp:218] Iteration 5544 (2.34403 iter/s, 5.11938s/12 iters), loss = 0.301108
I0422 01:39:16.622419 16011 solver.cpp:237]     Train net output #0: loss = 0.301108 (* 1 = 0.301108 loss)
I0422 01:39:16.622428 16011 sgd_solver.cpp:105] Iteration 5544, lr = 0.00333475
I0422 01:39:21.990295 16011 solver.cpp:218] Iteration 5556 (2.23558 iter/s, 5.36774s/12 iters), loss = 0.14882
I0422 01:39:21.990336 16011 solver.cpp:237]     Train net output #0: loss = 0.148819 (* 1 = 0.148819 loss)
I0422 01:39:21.990345 16011 sgd_solver.cpp:105] Iteration 5556, lr = 0.00332683
I0422 01:39:24.838874 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:39:27.271188 16011 solver.cpp:218] Iteration 5568 (2.27242 iter/s, 5.2807s/12 iters), loss = 0.370559
I0422 01:39:27.271236 16011 solver.cpp:237]     Train net output #0: loss = 0.370559 (* 1 = 0.370559 loss)
I0422 01:39:27.271246 16011 sgd_solver.cpp:105] Iteration 5568, lr = 0.00331893
I0422 01:39:32.688676 16011 solver.cpp:218] Iteration 5580 (2.21513 iter/s, 5.41729s/12 iters), loss = 0.486361
I0422 01:39:32.691609 16011 solver.cpp:237]     Train net output #0: loss = 0.486361 (* 1 = 0.486361 loss)
I0422 01:39:32.691632 16011 sgd_solver.cpp:105] Iteration 5580, lr = 0.00331105
I0422 01:39:37.800285 16011 solver.cpp:218] Iteration 5592 (2.349 iter/s, 5.10855s/12 iters), loss = 0.25604
I0422 01:39:37.800324 16011 solver.cpp:237]     Train net output #0: loss = 0.25604 (* 1 = 0.25604 loss)
I0422 01:39:37.800334 16011 sgd_solver.cpp:105] Iteration 5592, lr = 0.00330319
I0422 01:39:42.874728 16011 solver.cpp:218] Iteration 5604 (2.36487 iter/s, 5.07427s/12 iters), loss = 0.279265
I0422 01:39:42.874786 16011 solver.cpp:237]     Train net output #0: loss = 0.279265 (* 1 = 0.279265 loss)
I0422 01:39:42.874799 16011 sgd_solver.cpp:105] Iteration 5604, lr = 0.00329535
I0422 01:39:45.098414 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_5610.caffemodel
I0422 01:39:49.251437 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_5610.solverstate
I0422 01:39:53.907225 16011 solver.cpp:330] Iteration 5610, Testing net (#0)
I0422 01:39:53.907250 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:39:56.154158 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:39:58.394354 16011 solver.cpp:397]     Test net output #0: accuracy = 0.412377
I0422 01:39:58.394404 16011 solver.cpp:397]     Test net output #1: loss = 3.17696 (* 1 = 3.17696 loss)
I0422 01:40:00.161257 16011 solver.cpp:218] Iteration 5616 (0.694201 iter/s, 17.2861s/12 iters), loss = 0.324476
I0422 01:40:00.161298 16011 solver.cpp:237]     Train net output #0: loss = 0.324476 (* 1 = 0.324476 loss)
I0422 01:40:00.161307 16011 sgd_solver.cpp:105] Iteration 5616, lr = 0.00328752
I0422 01:40:05.216305 16011 solver.cpp:218] Iteration 5628 (2.37395 iter/s, 5.05487s/12 iters), loss = 0.307361
I0422 01:40:05.216440 16011 solver.cpp:237]     Train net output #0: loss = 0.307361 (* 1 = 0.307361 loss)
I0422 01:40:05.216450 16011 sgd_solver.cpp:105] Iteration 5628, lr = 0.00327972
I0422 01:40:10.413395 16011 solver.cpp:218] Iteration 5640 (2.30911 iter/s, 5.19682s/12 iters), loss = 0.303381
I0422 01:40:10.413435 16011 solver.cpp:237]     Train net output #0: loss = 0.303381 (* 1 = 0.303381 loss)
I0422 01:40:10.413445 16011 sgd_solver.cpp:105] Iteration 5640, lr = 0.00327193
I0422 01:40:15.614214 16011 solver.cpp:218] Iteration 5652 (2.30741 iter/s, 5.20065s/12 iters), loss = 0.280608
I0422 01:40:15.614256 16011 solver.cpp:237]     Train net output #0: loss = 0.280608 (* 1 = 0.280608 loss)
I0422 01:40:15.614265 16011 sgd_solver.cpp:105] Iteration 5652, lr = 0.00326416
I0422 01:40:20.549427 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:40:20.727198 16011 solver.cpp:218] Iteration 5664 (2.34705 iter/s, 5.1128s/12 iters), loss = 0.349659
I0422 01:40:20.727249 16011 solver.cpp:237]     Train net output #0: loss = 0.349659 (* 1 = 0.349659 loss)
I0422 01:40:20.727258 16011 sgd_solver.cpp:105] Iteration 5664, lr = 0.00325641
I0422 01:40:25.796852 16011 solver.cpp:218] Iteration 5676 (2.36711 iter/s, 5.06947s/12 iters), loss = 0.267411
I0422 01:40:25.796893 16011 solver.cpp:237]     Train net output #0: loss = 0.267411 (* 1 = 0.267411 loss)
I0422 01:40:25.796901 16011 sgd_solver.cpp:105] Iteration 5676, lr = 0.00324868
I0422 01:40:30.830971 16011 solver.cpp:218] Iteration 5688 (2.38382 iter/s, 5.03394s/12 iters), loss = 0.229253
I0422 01:40:30.831014 16011 solver.cpp:237]     Train net output #0: loss = 0.229253 (* 1 = 0.229253 loss)
I0422 01:40:30.831023 16011 sgd_solver.cpp:105] Iteration 5688, lr = 0.00324097
I0422 01:40:36.046972 16011 solver.cpp:218] Iteration 5700 (2.30069 iter/s, 5.21582s/12 iters), loss = 0.251247
I0422 01:40:36.047116 16011 solver.cpp:237]     Train net output #0: loss = 0.251247 (* 1 = 0.251247 loss)
I0422 01:40:36.047127 16011 sgd_solver.cpp:105] Iteration 5700, lr = 0.00323328
I0422 01:40:40.739146 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_5712.caffemodel
I0422 01:40:43.743770 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_5712.solverstate
I0422 01:40:46.556687 16011 solver.cpp:330] Iteration 5712, Testing net (#0)
I0422 01:40:46.556707 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:40:48.697904 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:40:50.991928 16011 solver.cpp:397]     Test net output #0: accuracy = 0.422181
I0422 01:40:50.991958 16011 solver.cpp:397]     Test net output #1: loss = 3.10746 (* 1 = 3.10746 loss)
I0422 01:40:51.087193 16011 solver.cpp:218] Iteration 5712 (0.797887 iter/s, 15.0397s/12 iters), loss = 0.247095
I0422 01:40:51.087236 16011 solver.cpp:237]     Train net output #0: loss = 0.247095 (* 1 = 0.247095 loss)
I0422 01:40:51.087245 16011 sgd_solver.cpp:105] Iteration 5712, lr = 0.0032256
I0422 01:40:55.214831 16011 solver.cpp:218] Iteration 5724 (2.90734 iter/s, 4.12748s/12 iters), loss = 0.388136
I0422 01:40:55.214885 16011 solver.cpp:237]     Train net output #0: loss = 0.388136 (* 1 = 0.388136 loss)
I0422 01:40:55.214897 16011 sgd_solver.cpp:105] Iteration 5724, lr = 0.00321794
I0422 01:41:00.323053 16011 solver.cpp:218] Iteration 5736 (2.34924 iter/s, 5.10804s/12 iters), loss = 0.214178
I0422 01:41:00.323096 16011 solver.cpp:237]     Train net output #0: loss = 0.214178 (* 1 = 0.214178 loss)
I0422 01:41:00.323103 16011 sgd_solver.cpp:105] Iteration 5736, lr = 0.0032103
I0422 01:41:05.458950 16011 solver.cpp:218] Iteration 5748 (2.33658 iter/s, 5.13572s/12 iters), loss = 0.485812
I0422 01:41:05.458993 16011 solver.cpp:237]     Train net output #0: loss = 0.485812 (* 1 = 0.485812 loss)
I0422 01:41:05.459002 16011 sgd_solver.cpp:105] Iteration 5748, lr = 0.00320268
I0422 01:41:10.624859 16011 solver.cpp:218] Iteration 5760 (2.323 iter/s, 5.16573s/12 iters), loss = 0.263073
I0422 01:41:10.625351 16011 solver.cpp:237]     Train net output #0: loss = 0.263073 (* 1 = 0.263073 loss)
I0422 01:41:10.625361 16011 sgd_solver.cpp:105] Iteration 5760, lr = 0.00319508
I0422 01:41:12.644246 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:41:15.794126 16011 solver.cpp:218] Iteration 5772 (2.3217 iter/s, 5.16864s/12 iters), loss = 0.261607
I0422 01:41:15.794179 16011 solver.cpp:237]     Train net output #0: loss = 0.261607 (* 1 = 0.261607 loss)
I0422 01:41:15.794190 16011 sgd_solver.cpp:105] Iteration 5772, lr = 0.00318749
I0422 01:41:20.950399 16011 solver.cpp:218] Iteration 5784 (2.32734 iter/s, 5.15609s/12 iters), loss = 0.194075
I0422 01:41:20.950435 16011 solver.cpp:237]     Train net output #0: loss = 0.194075 (* 1 = 0.194075 loss)
I0422 01:41:20.950443 16011 sgd_solver.cpp:105] Iteration 5784, lr = 0.00317992
I0422 01:41:26.074648 16011 solver.cpp:218] Iteration 5796 (2.34189 iter/s, 5.12408s/12 iters), loss = 0.361077
I0422 01:41:26.074687 16011 solver.cpp:237]     Train net output #0: loss = 0.361077 (* 1 = 0.361077 loss)
I0422 01:41:26.074697 16011 sgd_solver.cpp:105] Iteration 5796, lr = 0.00317237
I0422 01:41:31.382591 16011 solver.cpp:218] Iteration 5808 (2.26084 iter/s, 5.30777s/12 iters), loss = 0.285999
I0422 01:41:31.382632 16011 solver.cpp:237]     Train net output #0: loss = 0.285999 (* 1 = 0.285999 loss)
I0422 01:41:31.382642 16011 sgd_solver.cpp:105] Iteration 5808, lr = 0.00316484
I0422 01:41:33.548295 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_5814.caffemodel
I0422 01:41:43.844974 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_5814.solverstate
I0422 01:41:54.113799 16011 solver.cpp:330] Iteration 5814, Testing net (#0)
I0422 01:41:54.113821 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:41:56.301667 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:41:58.637006 16011 solver.cpp:397]     Test net output #0: accuracy = 0.426471
I0422 01:41:58.637035 16011 solver.cpp:397]     Test net output #1: loss = 3.08815 (* 1 = 3.08815 loss)
I0422 01:42:00.686429 16011 solver.cpp:218] Iteration 5820 (0.409513 iter/s, 29.3031s/12 iters), loss = 0.158157
I0422 01:42:00.686470 16011 solver.cpp:237]     Train net output #0: loss = 0.158157 (* 1 = 0.158157 loss)
I0422 01:42:00.686480 16011 sgd_solver.cpp:105] Iteration 5820, lr = 0.00315733
I0422 01:42:05.971922 16011 solver.cpp:218] Iteration 5832 (2.27044 iter/s, 5.28532s/12 iters), loss = 0.295967
I0422 01:42:05.971967 16011 solver.cpp:237]     Train net output #0: loss = 0.295967 (* 1 = 0.295967 loss)
I0422 01:42:05.971976 16011 sgd_solver.cpp:105] Iteration 5832, lr = 0.00314983
I0422 01:42:11.256284 16011 solver.cpp:218] Iteration 5844 (2.27093 iter/s, 5.28418s/12 iters), loss = 0.316471
I0422 01:42:11.256326 16011 solver.cpp:237]     Train net output #0: loss = 0.31647 (* 1 = 0.31647 loss)
I0422 01:42:11.256335 16011 sgd_solver.cpp:105] Iteration 5844, lr = 0.00314235
I0422 01:42:16.665458 16011 solver.cpp:218] Iteration 5856 (2.21853 iter/s, 5.40899s/12 iters), loss = 0.229039
I0422 01:42:16.665915 16011 solver.cpp:237]     Train net output #0: loss = 0.229039 (* 1 = 0.229039 loss)
I0422 01:42:16.665926 16011 sgd_solver.cpp:105] Iteration 5856, lr = 0.00313489
I0422 01:42:20.969233 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:42:21.803853 16011 solver.cpp:218] Iteration 5868 (2.33563 iter/s, 5.1378s/12 iters), loss = 0.212802
I0422 01:42:21.803897 16011 solver.cpp:237]     Train net output #0: loss = 0.212802 (* 1 = 0.212802 loss)
I0422 01:42:21.803907 16011 sgd_solver.cpp:105] Iteration 5868, lr = 0.00312745
I0422 01:42:27.012598 16011 solver.cpp:218] Iteration 5880 (2.3039 iter/s, 5.20857s/12 iters), loss = 0.206556
I0422 01:42:27.012660 16011 solver.cpp:237]     Train net output #0: loss = 0.206556 (* 1 = 0.206556 loss)
I0422 01:42:27.012693 16011 sgd_solver.cpp:105] Iteration 5880, lr = 0.00312002
I0422 01:42:32.390763 16011 solver.cpp:218] Iteration 5892 (2.23133 iter/s, 5.37796s/12 iters), loss = 0.298799
I0422 01:42:32.390816 16011 solver.cpp:237]     Train net output #0: loss = 0.298798 (* 1 = 0.298798 loss)
I0422 01:42:32.390826 16011 sgd_solver.cpp:105] Iteration 5892, lr = 0.00311262
I0422 01:42:37.544764 16011 solver.cpp:218] Iteration 5904 (2.32837 iter/s, 5.15381s/12 iters), loss = 0.293656
I0422 01:42:37.544819 16011 solver.cpp:237]     Train net output #0: loss = 0.293655 (* 1 = 0.293655 loss)
I0422 01:42:37.544828 16011 sgd_solver.cpp:105] Iteration 5904, lr = 0.00310523
I0422 01:42:42.260015 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_5916.caffemodel
I0422 01:42:45.970994 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_5916.solverstate
I0422 01:42:49.321990 16011 solver.cpp:330] Iteration 5916, Testing net (#0)
I0422 01:42:49.322074 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:42:51.572929 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:42:53.931934 16011 solver.cpp:397]     Test net output #0: accuracy = 0.42402
I0422 01:42:53.931977 16011 solver.cpp:397]     Test net output #1: loss = 3.1024 (* 1 = 3.1024 loss)
I0422 01:42:54.026630 16011 solver.cpp:218] Iteration 5916 (0.728093 iter/s, 16.4814s/12 iters), loss = 0.268398
I0422 01:42:54.026679 16011 solver.cpp:237]     Train net output #0: loss = 0.268398 (* 1 = 0.268398 loss)
I0422 01:42:54.026690 16011 sgd_solver.cpp:105] Iteration 5916, lr = 0.00309785
I0422 01:42:58.365576 16011 solver.cpp:218] Iteration 5928 (2.76575 iter/s, 4.33878s/12 iters), loss = 0.20849
I0422 01:42:58.365617 16011 solver.cpp:237]     Train net output #0: loss = 0.208489 (* 1 = 0.208489 loss)
I0422 01:42:58.365626 16011 sgd_solver.cpp:105] Iteration 5928, lr = 0.0030905
I0422 01:43:03.529036 16011 solver.cpp:218] Iteration 5940 (2.3241 iter/s, 5.16328s/12 iters), loss = 0.218152
I0422 01:43:03.529076 16011 solver.cpp:237]     Train net output #0: loss = 0.218152 (* 1 = 0.218152 loss)
I0422 01:43:03.529086 16011 sgd_solver.cpp:105] Iteration 5940, lr = 0.00308316
I0422 01:43:08.748132 16011 solver.cpp:218] Iteration 5952 (2.29933 iter/s, 5.21892s/12 iters), loss = 0.209394
I0422 01:43:08.748176 16011 solver.cpp:237]     Train net output #0: loss = 0.209394 (* 1 = 0.209394 loss)
I0422 01:43:08.748186 16011 sgd_solver.cpp:105] Iteration 5952, lr = 0.00307584
I0422 01:43:14.034901 16011 solver.cpp:218] Iteration 5964 (2.26989 iter/s, 5.28659s/12 iters), loss = 0.478864
I0422 01:43:14.034941 16011 solver.cpp:237]     Train net output #0: loss = 0.478864 (* 1 = 0.478864 loss)
I0422 01:43:14.034951 16011 sgd_solver.cpp:105] Iteration 5964, lr = 0.00306854
I0422 01:43:15.467680 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:43:19.254401 16011 solver.cpp:218] Iteration 5976 (2.29915 iter/s, 5.21933s/12 iters), loss = 0.186968
I0422 01:43:19.254436 16011 solver.cpp:237]     Train net output #0: loss = 0.186968 (* 1 = 0.186968 loss)
I0422 01:43:19.254443 16011 sgd_solver.cpp:105] Iteration 5976, lr = 0.00306125
I0422 01:43:24.428315 16011 solver.cpp:218] Iteration 5988 (2.3194 iter/s, 5.17375s/12 iters), loss = 0.285772
I0422 01:43:24.428465 16011 solver.cpp:237]     Train net output #0: loss = 0.285772 (* 1 = 0.285772 loss)
I0422 01:43:24.428478 16011 sgd_solver.cpp:105] Iteration 5988, lr = 0.00305398
I0422 01:43:29.895603 16011 solver.cpp:218] Iteration 6000 (2.19499 iter/s, 5.467s/12 iters), loss = 0.240497
I0422 01:43:29.895645 16011 solver.cpp:237]     Train net output #0: loss = 0.240497 (* 1 = 0.240497 loss)
I0422 01:43:29.895655 16011 sgd_solver.cpp:105] Iteration 6000, lr = 0.00304673
I0422 01:43:34.968359 16011 solver.cpp:218] Iteration 6012 (2.36566 iter/s, 5.07258s/12 iters), loss = 0.236667
I0422 01:43:34.968403 16011 solver.cpp:237]     Train net output #0: loss = 0.236667 (* 1 = 0.236667 loss)
I0422 01:43:34.968412 16011 sgd_solver.cpp:105] Iteration 6012, lr = 0.0030395
I0422 01:43:37.051863 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_6018.caffemodel
I0422 01:43:40.114115 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_6018.solverstate
I0422 01:43:44.141402 16011 solver.cpp:330] Iteration 6018, Testing net (#0)
I0422 01:43:44.141423 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:43:46.241796 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:43:48.712904 16011 solver.cpp:397]     Test net output #0: accuracy = 0.420343
I0422 01:43:48.712940 16011 solver.cpp:397]     Test net output #1: loss = 3.07796 (* 1 = 3.07796 loss)
I0422 01:43:50.536617 16011 solver.cpp:218] Iteration 6024 (0.77082 iter/s, 15.5678s/12 iters), loss = 0.230448
I0422 01:43:50.536656 16011 solver.cpp:237]     Train net output #0: loss = 0.230448 (* 1 = 0.230448 loss)
I0422 01:43:50.536667 16011 sgd_solver.cpp:105] Iteration 6024, lr = 0.00303228
I0422 01:43:56.010515 16011 solver.cpp:218] Iteration 6036 (2.19229 iter/s, 5.47372s/12 iters), loss = 0.128456
I0422 01:43:56.012161 16011 solver.cpp:237]     Train net output #0: loss = 0.128456 (* 1 = 0.128456 loss)
I0422 01:43:56.012171 16011 sgd_solver.cpp:105] Iteration 6036, lr = 0.00302508
I0422 01:44:01.279860 16011 solver.cpp:218] Iteration 6048 (2.27809 iter/s, 5.26757s/12 iters), loss = 0.171318
I0422 01:44:01.279901 16011 solver.cpp:237]     Train net output #0: loss = 0.171318 (* 1 = 0.171318 loss)
I0422 01:44:01.279909 16011 sgd_solver.cpp:105] Iteration 6048, lr = 0.0030179
I0422 01:44:06.488910 16011 solver.cpp:218] Iteration 6060 (2.30376 iter/s, 5.20888s/12 iters), loss = 0.13027
I0422 01:44:06.488950 16011 solver.cpp:237]     Train net output #0: loss = 0.130269 (* 1 = 0.130269 loss)
I0422 01:44:06.488958 16011 sgd_solver.cpp:105] Iteration 6060, lr = 0.00301074
I0422 01:44:10.049508 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:44:11.667853 16011 solver.cpp:218] Iteration 6072 (2.31715 iter/s, 5.17877s/12 iters), loss = 0.319724
I0422 01:44:11.667904 16011 solver.cpp:237]     Train net output #0: loss = 0.319724 (* 1 = 0.319724 loss)
I0422 01:44:11.667914 16011 sgd_solver.cpp:105] Iteration 6072, lr = 0.00300359
I0422 01:44:16.784407 16011 solver.cpp:218] Iteration 6084 (2.34541 iter/s, 5.11637s/12 iters), loss = 0.24084
I0422 01:44:16.784454 16011 solver.cpp:237]     Train net output #0: loss = 0.24084 (* 1 = 0.24084 loss)
I0422 01:44:16.784463 16011 sgd_solver.cpp:105] Iteration 6084, lr = 0.00299646
I0422 01:44:22.011392 16011 solver.cpp:218] Iteration 6096 (2.29586 iter/s, 5.22679s/12 iters), loss = 0.185638
I0422 01:44:22.011446 16011 solver.cpp:237]     Train net output #0: loss = 0.185638 (* 1 = 0.185638 loss)
I0422 01:44:22.011459 16011 sgd_solver.cpp:105] Iteration 6096, lr = 0.00298934
I0422 01:44:27.335265 16011 solver.cpp:218] Iteration 6108 (2.25408 iter/s, 5.32368s/12 iters), loss = 0.146897
I0422 01:44:27.335446 16011 solver.cpp:237]     Train net output #0: loss = 0.146897 (* 1 = 0.146897 loss)
I0422 01:44:27.335464 16011 sgd_solver.cpp:105] Iteration 6108, lr = 0.00298225
I0422 01:44:32.203114 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_6120.caffemodel
I0422 01:44:39.054750 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_6120.solverstate
I0422 01:44:43.698823 16011 solver.cpp:330] Iteration 6120, Testing net (#0)
I0422 01:44:43.698844 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:44:45.792644 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:44:48.411170 16011 solver.cpp:397]     Test net output #0: accuracy = 0.435049
I0422 01:44:48.411197 16011 solver.cpp:397]     Test net output #1: loss = 3.1012 (* 1 = 3.1012 loss)
I0422 01:44:48.506477 16011 solver.cpp:218] Iteration 6120 (0.566825 iter/s, 21.1705s/12 iters), loss = 0.178441
I0422 01:44:48.506520 16011 solver.cpp:237]     Train net output #0: loss = 0.178441 (* 1 = 0.178441 loss)
I0422 01:44:48.506528 16011 sgd_solver.cpp:105] Iteration 6120, lr = 0.00297517
I0422 01:44:52.802594 16011 solver.cpp:218] Iteration 6132 (2.79332 iter/s, 4.29596s/12 iters), loss = 0.182357
I0422 01:44:52.802639 16011 solver.cpp:237]     Train net output #0: loss = 0.182357 (* 1 = 0.182357 loss)
I0422 01:44:52.802649 16011 sgd_solver.cpp:105] Iteration 6132, lr = 0.0029681
I0422 01:44:58.119514 16011 solver.cpp:218] Iteration 6144 (2.25702 iter/s, 5.31674s/12 iters), loss = 0.203492
I0422 01:44:58.119607 16011 solver.cpp:237]     Train net output #0: loss = 0.203492 (* 1 = 0.203492 loss)
I0422 01:44:58.119617 16011 sgd_solver.cpp:105] Iteration 6144, lr = 0.00296105
I0422 01:45:03.249855 16011 solver.cpp:218] Iteration 6156 (2.33913 iter/s, 5.13012s/12 iters), loss = 0.218003
I0422 01:45:03.249892 16011 solver.cpp:237]     Train net output #0: loss = 0.218003 (* 1 = 0.218003 loss)
I0422 01:45:03.249902 16011 sgd_solver.cpp:105] Iteration 6156, lr = 0.00295402
I0422 01:45:08.412619 16011 solver.cpp:218] Iteration 6168 (2.32441 iter/s, 5.16259s/12 iters), loss = 0.185539
I0422 01:45:08.412662 16011 solver.cpp:237]     Train net output #0: loss = 0.185539 (* 1 = 0.185539 loss)
I0422 01:45:08.412670 16011 sgd_solver.cpp:105] Iteration 6168, lr = 0.00294701
I0422 01:45:09.021492 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:45:13.534204 16011 solver.cpp:218] Iteration 6180 (2.34311 iter/s, 5.12141s/12 iters), loss = 0.233737
I0422 01:45:13.534245 16011 solver.cpp:237]     Train net output #0: loss = 0.233737 (* 1 = 0.233737 loss)
I0422 01:45:13.534255 16011 sgd_solver.cpp:105] Iteration 6180, lr = 0.00294001
I0422 01:45:18.927484 16011 solver.cpp:218] Iteration 6192 (2.22507 iter/s, 5.39309s/12 iters), loss = 0.334336
I0422 01:45:18.927532 16011 solver.cpp:237]     Train net output #0: loss = 0.334336 (* 1 = 0.334336 loss)
I0422 01:45:18.927542 16011 sgd_solver.cpp:105] Iteration 6192, lr = 0.00293303
I0422 01:45:24.189119 16011 solver.cpp:218] Iteration 6204 (2.28074 iter/s, 5.26145s/12 iters), loss = 0.218978
I0422 01:45:24.189160 16011 solver.cpp:237]     Train net output #0: loss = 0.218978 (* 1 = 0.218978 loss)
I0422 01:45:24.189170 16011 sgd_solver.cpp:105] Iteration 6204, lr = 0.00292607
I0422 01:45:29.252002 16011 solver.cpp:218] Iteration 6216 (2.37027 iter/s, 5.0627s/12 iters), loss = 0.21826
I0422 01:45:29.252100 16011 solver.cpp:237]     Train net output #0: loss = 0.21826 (* 1 = 0.21826 loss)
I0422 01:45:29.252110 16011 sgd_solver.cpp:105] Iteration 6216, lr = 0.00291912
I0422 01:45:31.482141 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_6222.caffemodel
I0422 01:45:38.307983 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_6222.solverstate
I0422 01:45:42.255479 16011 solver.cpp:330] Iteration 6222, Testing net (#0)
I0422 01:45:42.255502 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:45:44.177537 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:45:45.489749 16011 blocking_queue.cpp:49] Waiting for data
I0422 01:45:46.705348 16011 solver.cpp:397]     Test net output #0: accuracy = 0.428922
I0422 01:45:46.705380 16011 solver.cpp:397]     Test net output #1: loss = 3.18588 (* 1 = 3.18588 loss)
I0422 01:45:48.636821 16011 solver.cpp:218] Iteration 6228 (0.619059 iter/s, 19.3843s/12 iters), loss = 0.149277
I0422 01:45:48.636868 16011 solver.cpp:237]     Train net output #0: loss = 0.149277 (* 1 = 0.149277 loss)
I0422 01:45:48.636878 16011 sgd_solver.cpp:105] Iteration 6228, lr = 0.00291219
I0422 01:45:53.881019 16011 solver.cpp:218] Iteration 6240 (2.28832 iter/s, 5.24401s/12 iters), loss = 0.121559
I0422 01:45:53.881062 16011 solver.cpp:237]     Train net output #0: loss = 0.121559 (* 1 = 0.121559 loss)
I0422 01:45:53.881072 16011 sgd_solver.cpp:105] Iteration 6240, lr = 0.00290528
I0422 01:45:59.131402 16011 solver.cpp:218] Iteration 6252 (2.28563 iter/s, 5.2502s/12 iters), loss = 0.206316
I0422 01:45:59.131444 16011 solver.cpp:237]     Train net output #0: loss = 0.206316 (* 1 = 0.206316 loss)
I0422 01:45:59.131453 16011 sgd_solver.cpp:105] Iteration 6252, lr = 0.00289838
I0422 01:46:04.289220 16011 solver.cpp:218] Iteration 6264 (2.32665 iter/s, 5.15764s/12 iters), loss = 0.274038
I0422 01:46:04.289384 16011 solver.cpp:237]     Train net output #0: loss = 0.274037 (* 1 = 0.274037 loss)
I0422 01:46:04.289398 16011 sgd_solver.cpp:105] Iteration 6264, lr = 0.0028915
I0422 01:46:07.163552 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:46:09.484529 16011 solver.cpp:218] Iteration 6276 (2.30991 iter/s, 5.19501s/12 iters), loss = 0.399495
I0422 01:46:09.484576 16011 solver.cpp:237]     Train net output #0: loss = 0.399495 (* 1 = 0.399495 loss)
I0422 01:46:09.484584 16011 sgd_solver.cpp:105] Iteration 6276, lr = 0.00288463
I0422 01:46:14.585630 16011 solver.cpp:218] Iteration 6288 (2.35252 iter/s, 5.10092s/12 iters), loss = 0.297286
I0422 01:46:14.585675 16011 solver.cpp:237]     Train net output #0: loss = 0.297286 (* 1 = 0.297286 loss)
I0422 01:46:14.585685 16011 sgd_solver.cpp:105] Iteration 6288, lr = 0.00287779
I0422 01:46:20.032403 16011 solver.cpp:218] Iteration 6300 (2.20322 iter/s, 5.44658s/12 iters), loss = 0.154311
I0422 01:46:20.032452 16011 solver.cpp:237]     Train net output #0: loss = 0.154311 (* 1 = 0.154311 loss)
I0422 01:46:20.032464 16011 sgd_solver.cpp:105] Iteration 6300, lr = 0.00287095
I0422 01:46:25.221845 16011 solver.cpp:218] Iteration 6312 (2.31247 iter/s, 5.18925s/12 iters), loss = 0.102877
I0422 01:46:25.221902 16011 solver.cpp:237]     Train net output #0: loss = 0.102877 (* 1 = 0.102877 loss)
I0422 01:46:25.221915 16011 sgd_solver.cpp:105] Iteration 6312, lr = 0.00286414
I0422 01:46:30.210748 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_6324.caffemodel
I0422 01:46:39.018637 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_6324.solverstate
I0422 01:46:43.894484 16011 solver.cpp:330] Iteration 6324, Testing net (#0)
I0422 01:46:43.894510 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:46:45.840863 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:46:48.402122 16011 solver.cpp:397]     Test net output #0: accuracy = 0.44424
I0422 01:46:48.402161 16011 solver.cpp:397]     Test net output #1: loss = 3.05614 (* 1 = 3.05614 loss)
I0422 01:46:48.497529 16011 solver.cpp:218] Iteration 6324 (0.515573 iter/s, 23.2751s/12 iters), loss = 0.186415
I0422 01:46:48.497565 16011 solver.cpp:237]     Train net output #0: loss = 0.186415 (* 1 = 0.186415 loss)
I0422 01:46:48.497572 16011 sgd_solver.cpp:105] Iteration 6324, lr = 0.00285734
I0422 01:46:52.728653 16011 solver.cpp:218] Iteration 6336 (2.83623 iter/s, 4.23097s/12 iters), loss = 0.147113
I0422 01:46:52.728705 16011 solver.cpp:237]     Train net output #0: loss = 0.147113 (* 1 = 0.147113 loss)
I0422 01:46:52.728718 16011 sgd_solver.cpp:105] Iteration 6336, lr = 0.00285055
I0422 01:46:57.908543 16011 solver.cpp:218] Iteration 6348 (2.31673 iter/s, 5.1797s/12 iters), loss = 0.0675187
I0422 01:46:57.908586 16011 solver.cpp:237]     Train net output #0: loss = 0.0675186 (* 1 = 0.0675186 loss)
I0422 01:46:57.908594 16011 sgd_solver.cpp:105] Iteration 6348, lr = 0.00284379
I0422 01:47:03.116902 16011 solver.cpp:218] Iteration 6360 (2.30407 iter/s, 5.20818s/12 iters), loss = 0.227719
I0422 01:47:03.116952 16011 solver.cpp:237]     Train net output #0: loss = 0.227719 (* 1 = 0.227719 loss)
I0422 01:47:03.116964 16011 sgd_solver.cpp:105] Iteration 6360, lr = 0.00283703
I0422 01:47:08.305290 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:47:08.456661 16011 solver.cpp:218] Iteration 6372 (2.24737 iter/s, 5.33957s/12 iters), loss = 0.231957
I0422 01:47:08.456712 16011 solver.cpp:237]     Train net output #0: loss = 0.231957 (* 1 = 0.231957 loss)
I0422 01:47:08.456722 16011 sgd_solver.cpp:105] Iteration 6372, lr = 0.0028303
I0422 01:47:13.745718 16011 solver.cpp:218] Iteration 6384 (2.26891 iter/s, 5.28887s/12 iters), loss = 0.202271
I0422 01:47:13.745857 16011 solver.cpp:237]     Train net output #0: loss = 0.202271 (* 1 = 0.202271 loss)
I0422 01:47:13.745867 16011 sgd_solver.cpp:105] Iteration 6384, lr = 0.00282358
I0422 01:47:18.853632 16011 solver.cpp:218] Iteration 6396 (2.34942 iter/s, 5.10764s/12 iters), loss = 0.191125
I0422 01:47:18.853677 16011 solver.cpp:237]     Train net output #0: loss = 0.191125 (* 1 = 0.191125 loss)
I0422 01:47:18.853688 16011 sgd_solver.cpp:105] Iteration 6396, lr = 0.00281687
I0422 01:47:24.220269 16011 solver.cpp:218] Iteration 6408 (2.23611 iter/s, 5.36645s/12 iters), loss = 0.203921
I0422 01:47:24.220310 16011 solver.cpp:237]     Train net output #0: loss = 0.203921 (* 1 = 0.203921 loss)
I0422 01:47:24.220319 16011 sgd_solver.cpp:105] Iteration 6408, lr = 0.00281019
I0422 01:47:29.497830 16011 solver.cpp:218] Iteration 6420 (2.27385 iter/s, 5.27738s/12 iters), loss = 0.185819
I0422 01:47:29.497869 16011 solver.cpp:237]     Train net output #0: loss = 0.185819 (* 1 = 0.185819 loss)
I0422 01:47:29.497879 16011 sgd_solver.cpp:105] Iteration 6420, lr = 0.00280351
I0422 01:47:31.693145 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_6426.caffemodel
I0422 01:47:38.502425 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_6426.solverstate
I0422 01:47:50.360576 16011 solver.cpp:330] Iteration 6426, Testing net (#0)
I0422 01:47:50.360646 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:47:52.353168 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:47:54.915125 16011 solver.cpp:397]     Test net output #0: accuracy = 0.446078
I0422 01:47:54.915164 16011 solver.cpp:397]     Test net output #1: loss = 3.07016 (* 1 = 3.07016 loss)
I0422 01:47:56.744778 16011 solver.cpp:218] Iteration 6432 (0.440427 iter/s, 27.2463s/12 iters), loss = 0.114586
I0422 01:47:56.744829 16011 solver.cpp:237]     Train net output #0: loss = 0.114586 (* 1 = 0.114586 loss)
I0422 01:47:56.744839 16011 sgd_solver.cpp:105] Iteration 6432, lr = 0.00279686
I0422 01:48:01.959806 16011 solver.cpp:218] Iteration 6444 (2.30113 iter/s, 5.21484s/12 iters), loss = 0.264921
I0422 01:48:01.959848 16011 solver.cpp:237]     Train net output #0: loss = 0.264921 (* 1 = 0.264921 loss)
I0422 01:48:01.959858 16011 sgd_solver.cpp:105] Iteration 6444, lr = 0.00279022
I0422 01:48:07.221799 16011 solver.cpp:218] Iteration 6456 (2.28058 iter/s, 5.26181s/12 iters), loss = 0.21477
I0422 01:48:07.221843 16011 solver.cpp:237]     Train net output #0: loss = 0.21477 (* 1 = 0.21477 loss)
I0422 01:48:07.221851 16011 sgd_solver.cpp:105] Iteration 6456, lr = 0.00278359
I0422 01:48:12.475524 16011 solver.cpp:218] Iteration 6468 (2.28418 iter/s, 5.25354s/12 iters), loss = 0.198743
I0422 01:48:12.475577 16011 solver.cpp:237]     Train net output #0: loss = 0.198743 (* 1 = 0.198743 loss)
I0422 01:48:12.475589 16011 sgd_solver.cpp:105] Iteration 6468, lr = 0.00277698
I0422 01:48:14.672161 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:48:17.751976 16011 solver.cpp:218] Iteration 6480 (2.27434 iter/s, 5.27626s/12 iters), loss = 0.176107
I0422 01:48:17.752017 16011 solver.cpp:237]     Train net output #0: loss = 0.176107 (* 1 = 0.176107 loss)
I0422 01:48:17.752025 16011 sgd_solver.cpp:105] Iteration 6480, lr = 0.00277039
I0422 01:48:23.063751 16011 solver.cpp:218] Iteration 6492 (2.25921 iter/s, 5.3116s/12 iters), loss = 0.176278
I0422 01:48:23.063901 16011 solver.cpp:237]     Train net output #0: loss = 0.176278 (* 1 = 0.176278 loss)
I0422 01:48:23.063911 16011 sgd_solver.cpp:105] Iteration 6492, lr = 0.00276381
I0422 01:48:28.362120 16011 solver.cpp:218] Iteration 6504 (2.26497 iter/s, 5.29808s/12 iters), loss = 0.109464
I0422 01:48:28.362162 16011 solver.cpp:237]     Train net output #0: loss = 0.109464 (* 1 = 0.109464 loss)
I0422 01:48:28.362171 16011 sgd_solver.cpp:105] Iteration 6504, lr = 0.00275725
I0422 01:48:33.546960 16011 solver.cpp:218] Iteration 6516 (2.31452 iter/s, 5.18466s/12 iters), loss = 0.207709
I0422 01:48:33.547010 16011 solver.cpp:237]     Train net output #0: loss = 0.207709 (* 1 = 0.207709 loss)
I0422 01:48:33.547022 16011 sgd_solver.cpp:105] Iteration 6516, lr = 0.00275071
I0422 01:48:38.321604 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_6528.caffemodel
I0422 01:48:43.736812 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_6528.solverstate
I0422 01:48:48.930289 16011 solver.cpp:330] Iteration 6528, Testing net (#0)
I0422 01:48:48.930312 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:48:50.886986 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:48:53.485245 16011 solver.cpp:397]     Test net output #0: accuracy = 0.454044
I0422 01:48:53.485366 16011 solver.cpp:397]     Test net output #1: loss = 3.094 (* 1 = 3.094 loss)
I0422 01:48:53.581238 16011 solver.cpp:218] Iteration 6528 (0.598989 iter/s, 20.0338s/12 iters), loss = 0.191545
I0422 01:48:53.581283 16011 solver.cpp:237]     Train net output #0: loss = 0.191545 (* 1 = 0.191545 loss)
I0422 01:48:53.581295 16011 sgd_solver.cpp:105] Iteration 6528, lr = 0.00274418
I0422 01:48:57.848466 16011 solver.cpp:218] Iteration 6540 (2.81223 iter/s, 4.26707s/12 iters), loss = 0.151381
I0422 01:48:57.848523 16011 solver.cpp:237]     Train net output #0: loss = 0.151381 (* 1 = 0.151381 loss)
I0422 01:48:57.848532 16011 sgd_solver.cpp:105] Iteration 6540, lr = 0.00273766
I0422 01:49:03.112303 16011 solver.cpp:218] Iteration 6552 (2.27979 iter/s, 5.26364s/12 iters), loss = 0.142209
I0422 01:49:03.112349 16011 solver.cpp:237]     Train net output #0: loss = 0.142209 (* 1 = 0.142209 loss)
I0422 01:49:03.112357 16011 sgd_solver.cpp:105] Iteration 6552, lr = 0.00273116
I0422 01:49:08.493760 16011 solver.cpp:218] Iteration 6564 (2.22996 iter/s, 5.38127s/12 iters), loss = 0.245222
I0422 01:49:08.493811 16011 solver.cpp:237]     Train net output #0: loss = 0.245222 (* 1 = 0.245222 loss)
I0422 01:49:08.493822 16011 sgd_solver.cpp:105] Iteration 6564, lr = 0.00272468
I0422 01:49:12.824280 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:49:13.608368 16011 solver.cpp:218] Iteration 6576 (2.34631 iter/s, 5.11442s/12 iters), loss = 0.238413
I0422 01:49:13.608417 16011 solver.cpp:237]     Train net output #0: loss = 0.238413 (* 1 = 0.238413 loss)
I0422 01:49:13.608425 16011 sgd_solver.cpp:105] Iteration 6576, lr = 0.00271821
I0422 01:49:19.013125 16011 solver.cpp:218] Iteration 6588 (2.22034 iter/s, 5.40457s/12 iters), loss = 0.13319
I0422 01:49:19.013165 16011 solver.cpp:237]     Train net output #0: loss = 0.13319 (* 1 = 0.13319 loss)
I0422 01:49:19.013173 16011 sgd_solver.cpp:105] Iteration 6588, lr = 0.00271175
I0422 01:49:24.083516 16011 solver.cpp:218] Iteration 6600 (2.36676 iter/s, 5.07022s/12 iters), loss = 0.158815
I0422 01:49:24.083619 16011 solver.cpp:237]     Train net output #0: loss = 0.158815 (* 1 = 0.158815 loss)
I0422 01:49:24.083631 16011 sgd_solver.cpp:105] Iteration 6600, lr = 0.00270532
I0422 01:49:29.300523 16011 solver.cpp:218] Iteration 6612 (2.30028 iter/s, 5.21675s/12 iters), loss = 0.19924
I0422 01:49:29.300565 16011 solver.cpp:237]     Train net output #0: loss = 0.19924 (* 1 = 0.19924 loss)
I0422 01:49:29.300573 16011 sgd_solver.cpp:105] Iteration 6612, lr = 0.00269889
I0422 01:49:34.544718 16011 solver.cpp:218] Iteration 6624 (2.28832 iter/s, 5.24401s/12 iters), loss = 0.1985
I0422 01:49:34.544770 16011 solver.cpp:237]     Train net output #0: loss = 0.1985 (* 1 = 0.1985 loss)
I0422 01:49:34.544781 16011 sgd_solver.cpp:105] Iteration 6624, lr = 0.00269248
I0422 01:49:36.586902 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_6630.caffemodel
I0422 01:49:41.670732 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_6630.solverstate
I0422 01:49:47.667865 16011 solver.cpp:330] Iteration 6630, Testing net (#0)
I0422 01:49:47.667886 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:49:49.455034 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:49:52.179515 16011 solver.cpp:397]     Test net output #0: accuracy = 0.4375
I0422 01:49:52.179565 16011 solver.cpp:397]     Test net output #1: loss = 3.06493 (* 1 = 3.06493 loss)
I0422 01:49:54.074760 16011 solver.cpp:218] Iteration 6636 (0.614454 iter/s, 19.5295s/12 iters), loss = 0.330199
I0422 01:49:54.074813 16011 solver.cpp:237]     Train net output #0: loss = 0.330199 (* 1 = 0.330199 loss)
I0422 01:49:54.074826 16011 sgd_solver.cpp:105] Iteration 6636, lr = 0.00268609
I0422 01:49:59.468716 16011 solver.cpp:218] Iteration 6648 (2.22479 iter/s, 5.39376s/12 iters), loss = 0.346393
I0422 01:49:59.468870 16011 solver.cpp:237]     Train net output #0: loss = 0.346393 (* 1 = 0.346393 loss)
I0422 01:49:59.468883 16011 sgd_solver.cpp:105] Iteration 6648, lr = 0.00267971
I0422 01:50:04.613620 16011 solver.cpp:218] Iteration 6660 (2.33253 iter/s, 5.14462s/12 iters), loss = 0.222099
I0422 01:50:04.613662 16011 solver.cpp:237]     Train net output #0: loss = 0.222099 (* 1 = 0.222099 loss)
I0422 01:50:04.613670 16011 sgd_solver.cpp:105] Iteration 6660, lr = 0.00267335
I0422 01:50:09.807679 16011 solver.cpp:218] Iteration 6672 (2.31041 iter/s, 5.19388s/12 iters), loss = 0.32644
I0422 01:50:09.807721 16011 solver.cpp:237]     Train net output #0: loss = 0.32644 (* 1 = 0.32644 loss)
I0422 01:50:09.807730 16011 sgd_solver.cpp:105] Iteration 6672, lr = 0.00266701
I0422 01:50:11.199285 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:50:14.979501 16011 solver.cpp:218] Iteration 6684 (2.32034 iter/s, 5.17165s/12 iters), loss = 0.118853
I0422 01:50:14.979542 16011 solver.cpp:237]     Train net output #0: loss = 0.118853 (* 1 = 0.118853 loss)
I0422 01:50:14.979552 16011 sgd_solver.cpp:105] Iteration 6684, lr = 0.00266067
I0422 01:50:20.476737 16011 solver.cpp:218] Iteration 6696 (2.18299 iter/s, 5.49704s/12 iters), loss = 0.142899
I0422 01:50:20.476789 16011 solver.cpp:237]     Train net output #0: loss = 0.142899 (* 1 = 0.142899 loss)
I0422 01:50:20.476801 16011 sgd_solver.cpp:105] Iteration 6696, lr = 0.00265436
I0422 01:50:26.103365 16011 solver.cpp:218] Iteration 6708 (2.13279 iter/s, 5.62643s/12 iters), loss = 0.0923493
I0422 01:50:26.103418 16011 solver.cpp:237]     Train net output #0: loss = 0.0923493 (* 1 = 0.0923493 loss)
I0422 01:50:26.103431 16011 sgd_solver.cpp:105] Iteration 6708, lr = 0.00264805
I0422 01:50:31.589130 16011 solver.cpp:218] Iteration 6720 (2.18756 iter/s, 5.48557s/12 iters), loss = 0.207818
I0422 01:50:31.589241 16011 solver.cpp:237]     Train net output #0: loss = 0.207818 (* 1 = 0.207818 loss)
I0422 01:50:31.589252 16011 sgd_solver.cpp:105] Iteration 6720, lr = 0.00264177
I0422 01:50:36.272044 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_6732.caffemodel
I0422 01:50:44.741991 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_6732.solverstate
I0422 01:50:49.875353 16011 solver.cpp:330] Iteration 6732, Testing net (#0)
I0422 01:50:49.875382 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:50:51.620602 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:50:54.345553 16011 solver.cpp:397]     Test net output #0: accuracy = 0.440564
I0422 01:50:54.345583 16011 solver.cpp:397]     Test net output #1: loss = 3.05592 (* 1 = 3.05592 loss)
I0422 01:50:54.440587 16011 solver.cpp:218] Iteration 6732 (0.525146 iter/s, 22.8508s/12 iters), loss = 0.0795384
I0422 01:50:54.440634 16011 solver.cpp:237]     Train net output #0: loss = 0.0795384 (* 1 = 0.0795384 loss)
I0422 01:50:54.440644 16011 sgd_solver.cpp:105] Iteration 6732, lr = 0.0026355
I0422 01:50:58.758637 16011 solver.cpp:218] Iteration 6744 (2.77914 iter/s, 4.31789s/12 iters), loss = 0.0577962
I0422 01:50:58.758683 16011 solver.cpp:237]     Train net output #0: loss = 0.0577962 (* 1 = 0.0577962 loss)
I0422 01:50:58.758692 16011 sgd_solver.cpp:105] Iteration 6744, lr = 0.00262924
I0422 01:51:04.237831 16011 solver.cpp:218] Iteration 6756 (2.19018 iter/s, 5.479s/12 iters), loss = 0.135537
I0422 01:51:04.241816 16011 solver.cpp:237]     Train net output #0: loss = 0.135537 (* 1 = 0.135537 loss)
I0422 01:51:04.241827 16011 sgd_solver.cpp:105] Iteration 6756, lr = 0.002623
I0422 01:51:09.419924 16011 solver.cpp:218] Iteration 6768 (2.31751 iter/s, 5.17797s/12 iters), loss = 0.199745
I0422 01:51:09.419970 16011 solver.cpp:237]     Train net output #0: loss = 0.199745 (* 1 = 0.199745 loss)
I0422 01:51:09.419979 16011 sgd_solver.cpp:105] Iteration 6768, lr = 0.00261677
I0422 01:51:12.935070 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:51:14.487138 16011 solver.cpp:218] Iteration 6780 (2.36825 iter/s, 5.06704s/12 iters), loss = 0.228675
I0422 01:51:14.487176 16011 solver.cpp:237]     Train net output #0: loss = 0.228675 (* 1 = 0.228675 loss)
I0422 01:51:14.487185 16011 sgd_solver.cpp:105] Iteration 6780, lr = 0.00261056
I0422 01:51:19.700405 16011 solver.cpp:218] Iteration 6792 (2.3019 iter/s, 5.21309s/12 iters), loss = 0.194082
I0422 01:51:19.700445 16011 solver.cpp:237]     Train net output #0: loss = 0.194082 (* 1 = 0.194082 loss)
I0422 01:51:19.700454 16011 sgd_solver.cpp:105] Iteration 6792, lr = 0.00260436
I0422 01:51:25.039119 16011 solver.cpp:218] Iteration 6804 (2.24781 iter/s, 5.33853s/12 iters), loss = 0.234903
I0422 01:51:25.039172 16011 solver.cpp:237]     Train net output #0: loss = 0.234903 (* 1 = 0.234903 loss)
I0422 01:51:25.039183 16011 sgd_solver.cpp:105] Iteration 6804, lr = 0.00259817
I0422 01:51:30.340169 16011 solver.cpp:218] Iteration 6816 (2.26378 iter/s, 5.30086s/12 iters), loss = 0.210531
I0422 01:51:30.340217 16011 solver.cpp:237]     Train net output #0: loss = 0.210531 (* 1 = 0.210531 loss)
I0422 01:51:30.340229 16011 sgd_solver.cpp:105] Iteration 6816, lr = 0.00259201
I0422 01:51:35.479115 16011 solver.cpp:218] Iteration 6828 (2.33519 iter/s, 5.13876s/12 iters), loss = 0.0897184
I0422 01:51:35.479244 16011 solver.cpp:237]     Train net output #0: loss = 0.0897184 (* 1 = 0.0897184 loss)
I0422 01:51:35.479257 16011 sgd_solver.cpp:105] Iteration 6828, lr = 0.00258585
I0422 01:51:37.654986 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_6834.caffemodel
I0422 01:51:42.691663 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_6834.solverstate
I0422 01:51:45.239413 16011 solver.cpp:330] Iteration 6834, Testing net (#0)
I0422 01:51:45.239431 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:51:46.966922 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:51:49.938951 16011 solver.cpp:397]     Test net output #0: accuracy = 0.448529
I0422 01:51:49.938982 16011 solver.cpp:397]     Test net output #1: loss = 3.12215 (* 1 = 3.12215 loss)
I0422 01:51:51.643733 16011 solver.cpp:218] Iteration 6840 (0.742386 iter/s, 16.1641s/12 iters), loss = 0.0924615
I0422 01:51:51.643788 16011 solver.cpp:237]     Train net output #0: loss = 0.0924615 (* 1 = 0.0924615 loss)
I0422 01:51:51.643800 16011 sgd_solver.cpp:105] Iteration 6840, lr = 0.00257971
I0422 01:51:56.844542 16011 solver.cpp:218] Iteration 6852 (2.30742 iter/s, 5.20061s/12 iters), loss = 0.10162
I0422 01:51:56.844584 16011 solver.cpp:237]     Train net output #0: loss = 0.10162 (* 1 = 0.10162 loss)
I0422 01:51:56.844594 16011 sgd_solver.cpp:105] Iteration 6852, lr = 0.00257359
I0422 01:52:02.235046 16011 solver.cpp:218] Iteration 6864 (2.22621 iter/s, 5.39032s/12 iters), loss = 0.167295
I0422 01:52:02.235090 16011 solver.cpp:237]     Train net output #0: loss = 0.167295 (* 1 = 0.167295 loss)
I0422 01:52:02.235098 16011 sgd_solver.cpp:105] Iteration 6864, lr = 0.00256748
I0422 01:52:07.428445 16011 solver.cpp:218] Iteration 6876 (2.3107 iter/s, 5.19322s/12 iters), loss = 0.138921
I0422 01:52:07.428599 16011 solver.cpp:237]     Train net output #0: loss = 0.138921 (* 1 = 0.138921 loss)
I0422 01:52:07.428611 16011 sgd_solver.cpp:105] Iteration 6876, lr = 0.00256138
I0422 01:52:08.059233 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:52:12.649569 16011 solver.cpp:218] Iteration 6888 (2.29848 iter/s, 5.22083s/12 iters), loss = 0.132048
I0422 01:52:12.649614 16011 solver.cpp:237]     Train net output #0: loss = 0.132048 (* 1 = 0.132048 loss)
I0422 01:52:12.649624 16011 sgd_solver.cpp:105] Iteration 6888, lr = 0.0025553
I0422 01:52:18.274785 16011 solver.cpp:218] Iteration 6900 (2.13332 iter/s, 5.62503s/12 iters), loss = 0.120512
I0422 01:52:18.274832 16011 solver.cpp:237]     Train net output #0: loss = 0.120512 (* 1 = 0.120512 loss)
I0422 01:52:18.274843 16011 sgd_solver.cpp:105] Iteration 6900, lr = 0.00254923
I0422 01:52:23.585211 16011 solver.cpp:218] Iteration 6912 (2.25978 iter/s, 5.31024s/12 iters), loss = 0.264184
I0422 01:52:23.585263 16011 solver.cpp:237]     Train net output #0: loss = 0.264184 (* 1 = 0.264184 loss)
I0422 01:52:23.585274 16011 sgd_solver.cpp:105] Iteration 6912, lr = 0.00254318
I0422 01:52:28.677146 16011 solver.cpp:218] Iteration 6924 (2.35675 iter/s, 5.09175s/12 iters), loss = 0.0977553
I0422 01:52:28.677188 16011 solver.cpp:237]     Train net output #0: loss = 0.0977553 (* 1 = 0.0977553 loss)
I0422 01:52:28.677199 16011 sgd_solver.cpp:105] Iteration 6924, lr = 0.00253714
I0422 01:52:33.253213 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_6936.caffemodel
I0422 01:52:36.447870 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_6936.solverstate
I0422 01:52:40.687328 16011 solver.cpp:330] Iteration 6936, Testing net (#0)
I0422 01:52:40.687412 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:52:41.363867 16011 blocking_queue.cpp:49] Waiting for data
I0422 01:52:42.462553 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:52:45.355268 16011 solver.cpp:397]     Test net output #0: accuracy = 0.440564
I0422 01:52:45.355298 16011 solver.cpp:397]     Test net output #1: loss = 3.06177 (* 1 = 3.06177 loss)
I0422 01:52:45.450865 16011 solver.cpp:218] Iteration 6936 (0.715424 iter/s, 16.7733s/12 iters), loss = 0.0630464
I0422 01:52:45.450907 16011 solver.cpp:237]     Train net output #0: loss = 0.0630464 (* 1 = 0.0630464 loss)
I0422 01:52:45.450917 16011 sgd_solver.cpp:105] Iteration 6936, lr = 0.00253112
I0422 01:52:49.910197 16011 solver.cpp:218] Iteration 6948 (2.69108 iter/s, 4.45917s/12 iters), loss = 0.160607
I0422 01:52:49.910236 16011 solver.cpp:237]     Train net output #0: loss = 0.160607 (* 1 = 0.160607 loss)
I0422 01:52:49.910248 16011 sgd_solver.cpp:105] Iteration 6948, lr = 0.00252511
I0422 01:52:55.211892 16011 solver.cpp:218] Iteration 6960 (2.2635 iter/s, 5.30152s/12 iters), loss = 0.0759902
I0422 01:52:55.211931 16011 solver.cpp:237]     Train net output #0: loss = 0.0759902 (* 1 = 0.0759902 loss)
I0422 01:52:55.211941 16011 sgd_solver.cpp:105] Iteration 6960, lr = 0.00251911
I0422 01:53:00.547930 16011 solver.cpp:218] Iteration 6972 (2.24893 iter/s, 5.33586s/12 iters), loss = 0.1097
I0422 01:53:00.547971 16011 solver.cpp:237]     Train net output #0: loss = 0.1097 (* 1 = 0.1097 loss)
I0422 01:53:00.547979 16011 sgd_solver.cpp:105] Iteration 6972, lr = 0.00251313
I0422 01:53:03.508111 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:53:05.996572 16011 solver.cpp:218] Iteration 6984 (2.20246 iter/s, 5.44846s/12 iters), loss = 0.0667098
I0422 01:53:05.996616 16011 solver.cpp:237]     Train net output #0: loss = 0.0667098 (* 1 = 0.0667098 loss)
I0422 01:53:05.996625 16011 sgd_solver.cpp:105] Iteration 6984, lr = 0.00250717
I0422 01:53:11.265528 16011 solver.cpp:218] Iteration 6996 (2.27757 iter/s, 5.26878s/12 iters), loss = 0.258679
I0422 01:53:11.265645 16011 solver.cpp:237]     Train net output #0: loss = 0.258679 (* 1 = 0.258679 loss)
I0422 01:53:11.265655 16011 sgd_solver.cpp:105] Iteration 6996, lr = 0.00250121
I0422 01:53:16.667433 16011 solver.cpp:218] Iteration 7008 (2.22155 iter/s, 5.40164s/12 iters), loss = 0.0687022
I0422 01:53:16.667490 16011 solver.cpp:237]     Train net output #0: loss = 0.0687022 (* 1 = 0.0687022 loss)
I0422 01:53:16.667502 16011 sgd_solver.cpp:105] Iteration 7008, lr = 0.00249528
I0422 01:53:22.017388 16011 solver.cpp:218] Iteration 7020 (2.24309 iter/s, 5.34977s/12 iters), loss = 0.11537
I0422 01:53:22.017431 16011 solver.cpp:237]     Train net output #0: loss = 0.11537 (* 1 = 0.11537 loss)
I0422 01:53:22.017439 16011 sgd_solver.cpp:105] Iteration 7020, lr = 0.00248935
I0422 01:53:27.357774 16011 solver.cpp:218] Iteration 7032 (2.24711 iter/s, 5.3402s/12 iters), loss = 0.0643847
I0422 01:53:27.357816 16011 solver.cpp:237]     Train net output #0: loss = 0.0643847 (* 1 = 0.0643847 loss)
I0422 01:53:27.357825 16011 sgd_solver.cpp:105] Iteration 7032, lr = 0.00248344
I0422 01:53:29.465014 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_7038.caffemodel
I0422 01:53:41.432580 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_7038.solverstate
I0422 01:53:47.513031 16011 solver.cpp:330] Iteration 7038, Testing net (#0)
I0422 01:53:47.513049 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:53:49.134974 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:53:51.977046 16011 solver.cpp:397]     Test net output #0: accuracy = 0.452206
I0422 01:53:51.977075 16011 solver.cpp:397]     Test net output #1: loss = 2.97685 (* 1 = 2.97685 loss)
I0422 01:53:53.994997 16011 solver.cpp:218] Iteration 7044 (0.450509 iter/s, 26.6365s/12 iters), loss = 0.0769945
I0422 01:53:53.995062 16011 solver.cpp:237]     Train net output #0: loss = 0.0769945 (* 1 = 0.0769945 loss)
I0422 01:53:53.995076 16011 sgd_solver.cpp:105] Iteration 7044, lr = 0.00247755
I0422 01:53:59.065455 16011 solver.cpp:218] Iteration 7056 (2.36674 iter/s, 5.07026s/12 iters), loss = 0.277981
I0422 01:53:59.065510 16011 solver.cpp:237]     Train net output #0: loss = 0.277981 (* 1 = 0.277981 loss)
I0422 01:53:59.065521 16011 sgd_solver.cpp:105] Iteration 7056, lr = 0.00247166
I0422 01:54:04.094548 16011 solver.cpp:218] Iteration 7068 (2.3862 iter/s, 5.02891s/12 iters), loss = 0.131212
I0422 01:54:04.094609 16011 solver.cpp:237]     Train net output #0: loss = 0.131212 (* 1 = 0.131212 loss)
I0422 01:54:04.094620 16011 sgd_solver.cpp:105] Iteration 7068, lr = 0.0024658
I0422 01:54:09.026183 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:54:09.138003 16011 solver.cpp:218] Iteration 7080 (2.37941 iter/s, 5.04326s/12 iters), loss = 0.0920476
I0422 01:54:09.138062 16011 solver.cpp:237]     Train net output #0: loss = 0.0920476 (* 1 = 0.0920476 loss)
I0422 01:54:09.138073 16011 sgd_solver.cpp:105] Iteration 7080, lr = 0.00245994
I0422 01:54:14.168578 16011 solver.cpp:218] Iteration 7092 (2.38551 iter/s, 5.03038s/12 iters), loss = 0.139621
I0422 01:54:14.168671 16011 solver.cpp:237]     Train net output #0: loss = 0.139621 (* 1 = 0.139621 loss)
I0422 01:54:14.168680 16011 sgd_solver.cpp:105] Iteration 7092, lr = 0.0024541
I0422 01:54:19.594615 16011 solver.cpp:218] Iteration 7104 (2.21165 iter/s, 5.42581s/12 iters), loss = 0.0755077
I0422 01:54:19.594656 16011 solver.cpp:237]     Train net output #0: loss = 0.0755077 (* 1 = 0.0755077 loss)
I0422 01:54:19.594666 16011 sgd_solver.cpp:105] Iteration 7104, lr = 0.00244827
I0422 01:54:24.763936 16011 solver.cpp:218] Iteration 7116 (2.32147 iter/s, 5.16915s/12 iters), loss = 0.137506
I0422 01:54:24.763978 16011 solver.cpp:237]     Train net output #0: loss = 0.137506 (* 1 = 0.137506 loss)
I0422 01:54:24.763986 16011 sgd_solver.cpp:105] Iteration 7116, lr = 0.00244246
I0422 01:54:29.962216 16011 solver.cpp:218] Iteration 7128 (2.30853 iter/s, 5.1981s/12 iters), loss = 0.169923
I0422 01:54:29.962256 16011 solver.cpp:237]     Train net output #0: loss = 0.169923 (* 1 = 0.169923 loss)
I0422 01:54:29.962265 16011 sgd_solver.cpp:105] Iteration 7128, lr = 0.00243666
I0422 01:54:34.611191 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_7140.caffemodel
I0422 01:54:41.038422 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_7140.solverstate
I0422 01:54:48.562227 16011 solver.cpp:330] Iteration 7140, Testing net (#0)
I0422 01:54:48.568266 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:54:50.208359 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:54:53.103669 16011 solver.cpp:397]     Test net output #0: accuracy = 0.446078
I0422 01:54:53.103699 16011 solver.cpp:397]     Test net output #1: loss = 3.03483 (* 1 = 3.03483 loss)
I0422 01:54:53.200369 16011 solver.cpp:218] Iteration 7140 (0.516405 iter/s, 23.2376s/12 iters), loss = 0.217639
I0422 01:54:53.200417 16011 solver.cpp:237]     Train net output #0: loss = 0.217639 (* 1 = 0.217639 loss)
I0422 01:54:53.200426 16011 sgd_solver.cpp:105] Iteration 7140, lr = 0.00243088
I0422 01:54:57.495898 16011 solver.cpp:218] Iteration 7152 (2.79371 iter/s, 4.29537s/12 iters), loss = 0.187783
I0422 01:54:57.495951 16011 solver.cpp:237]     Train net output #0: loss = 0.187783 (* 1 = 0.187783 loss)
I0422 01:54:57.495962 16011 sgd_solver.cpp:105] Iteration 7152, lr = 0.00242511
I0422 01:55:02.816510 16011 solver.cpp:218] Iteration 7164 (2.25547 iter/s, 5.3204s/12 iters), loss = 0.127834
I0422 01:55:02.816557 16011 solver.cpp:237]     Train net output #0: loss = 0.127834 (* 1 = 0.127834 loss)
I0422 01:55:02.816566 16011 sgd_solver.cpp:105] Iteration 7164, lr = 0.00241935
I0422 01:55:07.994221 16011 solver.cpp:218] Iteration 7176 (2.31771 iter/s, 5.17752s/12 iters), loss = 0.0657547
I0422 01:55:07.994268 16011 solver.cpp:237]     Train net output #0: loss = 0.0657547 (* 1 = 0.0657547 loss)
I0422 01:55:07.994277 16011 sgd_solver.cpp:105] Iteration 7176, lr = 0.0024136
I0422 01:55:10.186376 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:55:13.157913 16011 solver.cpp:218] Iteration 7188 (2.324 iter/s, 5.16351s/12 iters), loss = 0.259773
I0422 01:55:13.157958 16011 solver.cpp:237]     Train net output #0: loss = 0.259773 (* 1 = 0.259773 loss)
I0422 01:55:13.157968 16011 sgd_solver.cpp:105] Iteration 7188, lr = 0.00240787
I0422 01:55:18.350463 16011 solver.cpp:218] Iteration 7200 (2.31108 iter/s, 5.19237s/12 iters), loss = 0.145145
I0422 01:55:18.350505 16011 solver.cpp:237]     Train net output #0: loss = 0.145145 (* 1 = 0.145145 loss)
I0422 01:55:18.350515 16011 sgd_solver.cpp:105] Iteration 7200, lr = 0.00240216
I0422 01:55:23.385084 16011 solver.cpp:218] Iteration 7212 (2.38358 iter/s, 5.03444s/12 iters), loss = 0.123948
I0422 01:55:23.385200 16011 solver.cpp:237]     Train net output #0: loss = 0.123948 (* 1 = 0.123948 loss)
I0422 01:55:23.385210 16011 sgd_solver.cpp:105] Iteration 7212, lr = 0.00239645
I0422 01:55:28.580991 16011 solver.cpp:218] Iteration 7224 (2.30962 iter/s, 5.19566s/12 iters), loss = 0.197531
I0422 01:55:28.581034 16011 solver.cpp:237]     Train net output #0: loss = 0.197531 (* 1 = 0.197531 loss)
I0422 01:55:28.581043 16011 sgd_solver.cpp:105] Iteration 7224, lr = 0.00239076
I0422 01:55:33.698969 16011 solver.cpp:218] Iteration 7236 (2.34476 iter/s, 5.1178s/12 iters), loss = 0.176502
I0422 01:55:33.699009 16011 solver.cpp:237]     Train net output #0: loss = 0.176502 (* 1 = 0.176502 loss)
I0422 01:55:33.699019 16011 sgd_solver.cpp:105] Iteration 7236, lr = 0.00238509
I0422 01:55:35.726385 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_7242.caffemodel
I0422 01:55:39.248461 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_7242.solverstate
I0422 01:55:42.821591 16011 solver.cpp:330] Iteration 7242, Testing net (#0)
I0422 01:55:42.821611 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:55:44.348151 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:55:47.254249 16011 solver.cpp:397]     Test net output #0: accuracy = 0.440564
I0422 01:55:47.254294 16011 solver.cpp:397]     Test net output #1: loss = 3.02313 (* 1 = 3.02313 loss)
I0422 01:55:49.187875 16011 solver.cpp:218] Iteration 7248 (0.774769 iter/s, 15.4885s/12 iters), loss = 0.15359
I0422 01:55:49.187940 16011 solver.cpp:237]     Train net output #0: loss = 0.15359 (* 1 = 0.15359 loss)
I0422 01:55:49.187950 16011 sgd_solver.cpp:105] Iteration 7248, lr = 0.00237942
I0422 01:55:54.538256 16011 solver.cpp:218] Iteration 7260 (2.24292 iter/s, 5.35018s/12 iters), loss = 0.190402
I0422 01:55:54.538400 16011 solver.cpp:237]     Train net output #0: loss = 0.190402 (* 1 = 0.190402 loss)
I0422 01:55:54.538414 16011 sgd_solver.cpp:105] Iteration 7260, lr = 0.00237378
I0422 01:55:59.645864 16011 solver.cpp:218] Iteration 7272 (2.34956 iter/s, 5.10733s/12 iters), loss = 0.0833881
I0422 01:55:59.645918 16011 solver.cpp:237]     Train net output #0: loss = 0.0833881 (* 1 = 0.0833881 loss)
I0422 01:55:59.645931 16011 sgd_solver.cpp:105] Iteration 7272, lr = 0.00236814
I0422 01:56:04.287650 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:56:05.038650 16011 solver.cpp:218] Iteration 7284 (2.22527 iter/s, 5.3926s/12 iters), loss = 0.125871
I0422 01:56:05.038691 16011 solver.cpp:237]     Train net output #0: loss = 0.125871 (* 1 = 0.125871 loss)
I0422 01:56:05.038700 16011 sgd_solver.cpp:105] Iteration 7284, lr = 0.00236252
I0422 01:56:10.154209 16011 solver.cpp:218] Iteration 7296 (2.34587 iter/s, 5.11538s/12 iters), loss = 0.0813649
I0422 01:56:10.154260 16011 solver.cpp:237]     Train net output #0: loss = 0.0813649 (* 1 = 0.0813649 loss)
I0422 01:56:10.154270 16011 sgd_solver.cpp:105] Iteration 7296, lr = 0.00235691
I0422 01:56:15.345396 16011 solver.cpp:218] Iteration 7308 (2.31169 iter/s, 5.191s/12 iters), loss = 0.149687
I0422 01:56:15.345443 16011 solver.cpp:237]     Train net output #0: loss = 0.149687 (* 1 = 0.149687 loss)
I0422 01:56:15.345453 16011 sgd_solver.cpp:105] Iteration 7308, lr = 0.00235131
I0422 01:56:20.463061 16011 solver.cpp:218] Iteration 7320 (2.3449 iter/s, 5.11748s/12 iters), loss = 0.1058
I0422 01:56:20.463106 16011 solver.cpp:237]     Train net output #0: loss = 0.1058 (* 1 = 0.1058 loss)
I0422 01:56:20.463119 16011 sgd_solver.cpp:105] Iteration 7320, lr = 0.00234573
I0422 01:56:25.933713 16011 solver.cpp:218] Iteration 7332 (2.1936 iter/s, 5.47046s/12 iters), loss = 0.062758
I0422 01:56:25.934026 16011 solver.cpp:237]     Train net output #0: loss = 0.062758 (* 1 = 0.062758 loss)
I0422 01:56:25.934038 16011 sgd_solver.cpp:105] Iteration 7332, lr = 0.00234016
I0422 01:56:30.584977 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_7344.caffemodel
I0422 01:56:37.427115 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_7344.solverstate
I0422 01:56:40.357571 16011 solver.cpp:330] Iteration 7344, Testing net (#0)
I0422 01:56:40.357590 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:56:41.930239 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:56:44.886806 16011 solver.cpp:397]     Test net output #0: accuracy = 0.457108
I0422 01:56:44.886842 16011 solver.cpp:397]     Test net output #1: loss = 3.0896 (* 1 = 3.0896 loss)
I0422 01:56:44.981931 16011 solver.cpp:218] Iteration 7344 (0.630005 iter/s, 19.0475s/12 iters), loss = 0.0965759
I0422 01:56:44.981978 16011 solver.cpp:237]     Train net output #0: loss = 0.0965759 (* 1 = 0.0965759 loss)
I0422 01:56:44.981988 16011 sgd_solver.cpp:105] Iteration 7344, lr = 0.0023346
I0422 01:56:49.530699 16011 solver.cpp:218] Iteration 7356 (2.63818 iter/s, 4.5486s/12 iters), loss = 0.206071
I0422 01:56:49.530756 16011 solver.cpp:237]     Train net output #0: loss = 0.206071 (* 1 = 0.206071 loss)
I0422 01:56:49.530769 16011 sgd_solver.cpp:105] Iteration 7356, lr = 0.00232906
I0422 01:56:54.823140 16011 solver.cpp:218] Iteration 7368 (2.26747 iter/s, 5.29225s/12 iters), loss = 0.0681496
I0422 01:56:54.823187 16011 solver.cpp:237]     Train net output #0: loss = 0.0681496 (* 1 = 0.0681496 loss)
I0422 01:56:54.823197 16011 sgd_solver.cpp:105] Iteration 7368, lr = 0.00232353
I0422 01:57:00.082854 16011 solver.cpp:218] Iteration 7380 (2.28157 iter/s, 5.25953s/12 iters), loss = 0.0680445
I0422 01:57:00.083000 16011 solver.cpp:237]     Train net output #0: loss = 0.0680445 (* 1 = 0.0680445 loss)
I0422 01:57:00.083011 16011 sgd_solver.cpp:105] Iteration 7380, lr = 0.00231802
I0422 01:57:01.511492 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:57:05.337761 16011 solver.cpp:218] Iteration 7392 (2.2837 iter/s, 5.25463s/12 iters), loss = 0.101409
I0422 01:57:05.337803 16011 solver.cpp:237]     Train net output #0: loss = 0.101409 (* 1 = 0.101409 loss)
I0422 01:57:05.337812 16011 sgd_solver.cpp:105] Iteration 7392, lr = 0.00231251
I0422 01:57:10.730664 16011 solver.cpp:218] Iteration 7404 (2.22522 iter/s, 5.39272s/12 iters), loss = 0.108416
I0422 01:57:10.730700 16011 solver.cpp:237]     Train net output #0: loss = 0.108416 (* 1 = 0.108416 loss)
I0422 01:57:10.730710 16011 sgd_solver.cpp:105] Iteration 7404, lr = 0.00230702
I0422 01:57:15.996441 16011 solver.cpp:218] Iteration 7416 (2.27894 iter/s, 5.2656s/12 iters), loss = 0.131777
I0422 01:57:15.996480 16011 solver.cpp:237]     Train net output #0: loss = 0.131777 (* 1 = 0.131777 loss)
I0422 01:57:15.996515 16011 sgd_solver.cpp:105] Iteration 7416, lr = 0.00230154
I0422 01:57:21.052407 16011 solver.cpp:218] Iteration 7428 (2.37351 iter/s, 5.0558s/12 iters), loss = 0.017248
I0422 01:57:21.052445 16011 solver.cpp:237]     Train net output #0: loss = 0.017248 (* 1 = 0.017248 loss)
I0422 01:57:21.052455 16011 sgd_solver.cpp:105] Iteration 7428, lr = 0.00229608
I0422 01:57:26.228579 16011 solver.cpp:218] Iteration 7440 (2.31839 iter/s, 5.176s/12 iters), loss = 0.0942131
I0422 01:57:26.228621 16011 solver.cpp:237]     Train net output #0: loss = 0.0942131 (* 1 = 0.0942131 loss)
I0422 01:57:26.228631 16011 sgd_solver.cpp:105] Iteration 7440, lr = 0.00229063
I0422 01:57:28.413165 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_7446.caffemodel
I0422 01:57:31.400568 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_7446.solverstate
I0422 01:57:33.690088 16011 solver.cpp:330] Iteration 7446, Testing net (#0)
I0422 01:57:33.690107 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:57:35.157251 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:57:38.109973 16011 solver.cpp:397]     Test net output #0: accuracy = 0.457721
I0422 01:57:38.110009 16011 solver.cpp:397]     Test net output #1: loss = 3.02332 (* 1 = 3.02332 loss)
I0422 01:57:39.936532 16011 solver.cpp:218] Iteration 7452 (0.875429 iter/s, 13.7076s/12 iters), loss = 0.208951
I0422 01:57:39.936584 16011 solver.cpp:237]     Train net output #0: loss = 0.208951 (* 1 = 0.208951 loss)
I0422 01:57:39.936595 16011 sgd_solver.cpp:105] Iteration 7452, lr = 0.00228519
I0422 01:57:45.024148 16011 solver.cpp:218] Iteration 7464 (2.35875 iter/s, 5.08744s/12 iters), loss = 0.061112
I0422 01:57:45.024194 16011 solver.cpp:237]     Train net output #0: loss = 0.061112 (* 1 = 0.061112 loss)
I0422 01:57:45.024202 16011 sgd_solver.cpp:105] Iteration 7464, lr = 0.00227976
I0422 01:57:50.359974 16011 solver.cpp:218] Iteration 7476 (2.24903 iter/s, 5.33564s/12 iters), loss = 0.0546429
I0422 01:57:50.360020 16011 solver.cpp:237]     Train net output #0: loss = 0.0546429 (* 1 = 0.0546429 loss)
I0422 01:57:50.360031 16011 sgd_solver.cpp:105] Iteration 7476, lr = 0.00227435
I0422 01:57:54.146641 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:57:55.711036 16011 solver.cpp:218] Iteration 7488 (2.24262 iter/s, 5.35088s/12 iters), loss = 0.0985036
I0422 01:57:55.711074 16011 solver.cpp:237]     Train net output #0: loss = 0.0985035 (* 1 = 0.0985035 loss)
I0422 01:57:55.711082 16011 sgd_solver.cpp:105] Iteration 7488, lr = 0.00226895
I0422 01:58:00.957091 16011 solver.cpp:218] Iteration 7500 (2.28751 iter/s, 5.24589s/12 iters), loss = 0.0583987
I0422 01:58:00.957125 16011 solver.cpp:237]     Train net output #0: loss = 0.0583986 (* 1 = 0.0583986 loss)
I0422 01:58:00.957134 16011 sgd_solver.cpp:105] Iteration 7500, lr = 0.00226357
I0422 01:58:06.462330 16011 solver.cpp:218] Iteration 7512 (2.17981 iter/s, 5.50506s/12 iters), loss = 0.0779181
I0422 01:58:06.462456 16011 solver.cpp:237]     Train net output #0: loss = 0.077918 (* 1 = 0.077918 loss)
I0422 01:58:06.462467 16011 sgd_solver.cpp:105] Iteration 7512, lr = 0.00225819
I0422 01:58:11.593739 16011 solver.cpp:218] Iteration 7524 (2.33866 iter/s, 5.13115s/12 iters), loss = 0.0592113
I0422 01:58:11.593782 16011 solver.cpp:237]     Train net output #0: loss = 0.0592113 (* 1 = 0.0592113 loss)
I0422 01:58:11.593791 16011 sgd_solver.cpp:105] Iteration 7524, lr = 0.00225283
I0422 01:58:16.713307 16011 solver.cpp:218] Iteration 7536 (2.34403 iter/s, 5.11939s/12 iters), loss = 0.112454
I0422 01:58:16.713358 16011 solver.cpp:237]     Train net output #0: loss = 0.112454 (* 1 = 0.112454 loss)
I0422 01:58:16.713371 16011 sgd_solver.cpp:105] Iteration 7536, lr = 0.00224748
I0422 01:58:21.421289 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_7548.caffemodel
I0422 01:58:24.392923 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_7548.solverstate
I0422 01:58:27.476807 16011 solver.cpp:330] Iteration 7548, Testing net (#0)
I0422 01:58:27.476826 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:58:28.907534 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:58:31.965673 16011 solver.cpp:397]     Test net output #0: accuracy = 0.458333
I0422 01:58:31.965711 16011 solver.cpp:397]     Test net output #1: loss = 3.02077 (* 1 = 3.02077 loss)
I0422 01:58:32.061029 16011 solver.cpp:218] Iteration 7548 (0.781896 iter/s, 15.3473s/12 iters), loss = 0.172378
I0422 01:58:32.061082 16011 solver.cpp:237]     Train net output #0: loss = 0.172378 (* 1 = 0.172378 loss)
I0422 01:58:32.061095 16011 sgd_solver.cpp:105] Iteration 7548, lr = 0.00224215
I0422 01:58:36.474943 16011 solver.cpp:218] Iteration 7560 (2.71878 iter/s, 4.41375s/12 iters), loss = 0.191618
I0422 01:58:36.483295 16011 solver.cpp:237]     Train net output #0: loss = 0.191618 (* 1 = 0.191618 loss)
I0422 01:58:36.483306 16011 sgd_solver.cpp:105] Iteration 7560, lr = 0.00223682
I0422 01:58:41.818779 16011 solver.cpp:218] Iteration 7572 (2.24915 iter/s, 5.33535s/12 iters), loss = 0.0824134
I0422 01:58:41.818820 16011 solver.cpp:237]     Train net output #0: loss = 0.0824133 (* 1 = 0.0824133 loss)
I0422 01:58:41.818828 16011 sgd_solver.cpp:105] Iteration 7572, lr = 0.00223151
I0422 01:58:47.184356 16011 solver.cpp:218] Iteration 7584 (2.23655 iter/s, 5.3654s/12 iters), loss = 0.0209561
I0422 01:58:47.184401 16011 solver.cpp:237]     Train net output #0: loss = 0.0209561 (* 1 = 0.0209561 loss)
I0422 01:58:47.184410 16011 sgd_solver.cpp:105] Iteration 7584, lr = 0.00222621
I0422 01:58:47.852587 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:58:52.232137 16011 solver.cpp:218] Iteration 7596 (2.37736 iter/s, 5.04761s/12 iters), loss = 0.154225
I0422 01:58:52.232180 16011 solver.cpp:237]     Train net output #0: loss = 0.154225 (* 1 = 0.154225 loss)
I0422 01:58:52.232188 16011 sgd_solver.cpp:105] Iteration 7596, lr = 0.00222093
I0422 01:58:57.375514 16011 solver.cpp:218] Iteration 7608 (2.33318 iter/s, 5.14319s/12 iters), loss = 0.228969
I0422 01:58:57.375564 16011 solver.cpp:237]     Train net output #0: loss = 0.228968 (* 1 = 0.228968 loss)
I0422 01:58:57.375576 16011 sgd_solver.cpp:105] Iteration 7608, lr = 0.00221565
I0422 01:59:02.578881 16011 solver.cpp:218] Iteration 7620 (2.30628 iter/s, 5.20318s/12 iters), loss = 0.0906397
I0422 01:59:02.578935 16011 solver.cpp:237]     Train net output #0: loss = 0.0906397 (* 1 = 0.0906397 loss)
I0422 01:59:02.578948 16011 sgd_solver.cpp:105] Iteration 7620, lr = 0.00221039
I0422 01:59:05.346174 16011 blocking_queue.cpp:49] Waiting for data
I0422 01:59:08.179091 16011 solver.cpp:218] Iteration 7632 (2.14285 iter/s, 5.60001s/12 iters), loss = 0.0516172
I0422 01:59:08.179229 16011 solver.cpp:237]     Train net output #0: loss = 0.0516171 (* 1 = 0.0516171 loss)
I0422 01:59:08.179239 16011 sgd_solver.cpp:105] Iteration 7632, lr = 0.00220515
I0422 01:59:13.382117 16011 solver.cpp:218] Iteration 7644 (2.30647 iter/s, 5.20276s/12 iters), loss = 0.179298
I0422 01:59:13.382155 16011 solver.cpp:237]     Train net output #0: loss = 0.179298 (* 1 = 0.179298 loss)
I0422 01:59:13.382164 16011 sgd_solver.cpp:105] Iteration 7644, lr = 0.00219991
I0422 01:59:15.484589 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_7650.caffemodel
I0422 01:59:18.818219 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_7650.solverstate
I0422 01:59:21.099007 16011 solver.cpp:330] Iteration 7650, Testing net (#0)
I0422 01:59:21.099028 16011 net.cpp:676] Ignoring source layer train-data
I0422 01:59:22.497428 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:59:25.621096 16011 solver.cpp:397]     Test net output #0: accuracy = 0.459559
I0422 01:59:25.621126 16011 solver.cpp:397]     Test net output #1: loss = 3.05673 (* 1 = 3.05673 loss)
I0422 01:59:27.469981 16011 solver.cpp:218] Iteration 7656 (0.85182 iter/s, 14.0875s/12 iters), loss = 0.0878541
I0422 01:59:27.470024 16011 solver.cpp:237]     Train net output #0: loss = 0.087854 (* 1 = 0.087854 loss)
I0422 01:59:27.470036 16011 sgd_solver.cpp:105] Iteration 7656, lr = 0.00219469
I0422 01:59:32.663187 16011 solver.cpp:218] Iteration 7668 (2.31079 iter/s, 5.19303s/12 iters), loss = 0.0420292
I0422 01:59:32.663234 16011 solver.cpp:237]     Train net output #0: loss = 0.0420291 (* 1 = 0.0420291 loss)
I0422 01:59:32.663244 16011 sgd_solver.cpp:105] Iteration 7668, lr = 0.00218948
I0422 01:59:37.886435 16011 solver.cpp:218] Iteration 7680 (2.2975 iter/s, 5.22307s/12 iters), loss = 0.0584938
I0422 01:59:37.886485 16011 solver.cpp:237]     Train net output #0: loss = 0.0584937 (* 1 = 0.0584937 loss)
I0422 01:59:37.886497 16011 sgd_solver.cpp:105] Iteration 7680, lr = 0.00218428
I0422 01:59:40.711102 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 01:59:42.982472 16011 solver.cpp:218] Iteration 7692 (2.35486 iter/s, 5.09585s/12 iters), loss = 0.0450261
I0422 01:59:42.982525 16011 solver.cpp:237]     Train net output #0: loss = 0.0450261 (* 1 = 0.0450261 loss)
I0422 01:59:42.982537 16011 sgd_solver.cpp:105] Iteration 7692, lr = 0.00217909
I0422 01:59:48.180370 16011 solver.cpp:218] Iteration 7704 (2.30871 iter/s, 5.19771s/12 iters), loss = 0.258306
I0422 01:59:48.180420 16011 solver.cpp:237]     Train net output #0: loss = 0.258306 (* 1 = 0.258306 loss)
I0422 01:59:48.180433 16011 sgd_solver.cpp:105] Iteration 7704, lr = 0.00217392
I0422 01:59:53.496712 16011 solver.cpp:218] Iteration 7716 (2.25727 iter/s, 5.31616s/12 iters), loss = 0.14869
I0422 01:59:53.496765 16011 solver.cpp:237]     Train net output #0: loss = 0.148689 (* 1 = 0.148689 loss)
I0422 01:59:53.496778 16011 sgd_solver.cpp:105] Iteration 7716, lr = 0.00216876
I0422 01:59:58.659473 16011 solver.cpp:218] Iteration 7728 (2.32442 iter/s, 5.16258s/12 iters), loss = 0.189803
I0422 01:59:58.659523 16011 solver.cpp:237]     Train net output #0: loss = 0.189803 (* 1 = 0.189803 loss)
I0422 01:59:58.659533 16011 sgd_solver.cpp:105] Iteration 7728, lr = 0.00216361
I0422 02:00:03.998369 16011 solver.cpp:218] Iteration 7740 (2.24773 iter/s, 5.33871s/12 iters), loss = 0.0915582
I0422 02:00:03.998414 16011 solver.cpp:237]     Train net output #0: loss = 0.0915581 (* 1 = 0.0915581 loss)
I0422 02:00:03.998423 16011 sgd_solver.cpp:105] Iteration 7740, lr = 0.00215847
I0422 02:00:08.954447 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_7752.caffemodel
I0422 02:00:18.035585 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_7752.solverstate
I0422 02:00:20.464778 16011 solver.cpp:330] Iteration 7752, Testing net (#0)
I0422 02:00:20.464805 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:00:21.931948 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:00:25.263341 16011 solver.cpp:397]     Test net output #0: accuracy = 0.462623
I0422 02:00:25.263371 16011 solver.cpp:397]     Test net output #1: loss = 3.02236 (* 1 = 3.02236 loss)
I0422 02:00:25.358773 16011 solver.cpp:218] Iteration 7752 (0.561802 iter/s, 21.3599s/12 iters), loss = 0.0778259
I0422 02:00:25.358816 16011 solver.cpp:237]     Train net output #0: loss = 0.0778258 (* 1 = 0.0778258 loss)
I0422 02:00:25.358825 16011 sgd_solver.cpp:105] Iteration 7752, lr = 0.00215335
I0422 02:00:29.569327 16011 solver.cpp:218] Iteration 7764 (2.85009 iter/s, 4.21039s/12 iters), loss = 0.0684138
I0422 02:00:29.569381 16011 solver.cpp:237]     Train net output #0: loss = 0.0684137 (* 1 = 0.0684137 loss)
I0422 02:00:29.569393 16011 sgd_solver.cpp:105] Iteration 7764, lr = 0.00214823
I0422 02:00:34.736707 16011 solver.cpp:218] Iteration 7776 (2.32235 iter/s, 5.16719s/12 iters), loss = 0.21698
I0422 02:00:34.736749 16011 solver.cpp:237]     Train net output #0: loss = 0.21698 (* 1 = 0.21698 loss)
I0422 02:00:34.736758 16011 sgd_solver.cpp:105] Iteration 7776, lr = 0.00214313
I0422 02:00:40.181342 16011 solver.cpp:218] Iteration 7788 (2.20408 iter/s, 5.44445s/12 iters), loss = 0.0719995
I0422 02:00:40.181382 16011 solver.cpp:237]     Train net output #0: loss = 0.0719993 (* 1 = 0.0719993 loss)
I0422 02:00:40.181391 16011 sgd_solver.cpp:105] Iteration 7788, lr = 0.00213805
I0422 02:00:40.190660 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:00:45.575807 16011 solver.cpp:218] Iteration 7800 (2.22458 iter/s, 5.39428s/12 iters), loss = 0.105222
I0422 02:00:45.575856 16011 solver.cpp:237]     Train net output #0: loss = 0.105222 (* 1 = 0.105222 loss)
I0422 02:00:45.575866 16011 sgd_solver.cpp:105] Iteration 7800, lr = 0.00213297
I0422 02:00:50.819748 16011 solver.cpp:218] Iteration 7812 (2.28843 iter/s, 5.24376s/12 iters), loss = 0.0431534
I0422 02:00:50.819857 16011 solver.cpp:237]     Train net output #0: loss = 0.0431533 (* 1 = 0.0431533 loss)
I0422 02:00:50.819867 16011 sgd_solver.cpp:105] Iteration 7812, lr = 0.00212791
I0422 02:00:56.369370 16011 solver.cpp:218] Iteration 7824 (2.16241 iter/s, 5.54936s/12 iters), loss = 0.161928
I0422 02:00:56.369426 16011 solver.cpp:237]     Train net output #0: loss = 0.161927 (* 1 = 0.161927 loss)
I0422 02:00:56.369438 16011 sgd_solver.cpp:105] Iteration 7824, lr = 0.00212285
I0422 02:01:01.442837 16011 solver.cpp:218] Iteration 7836 (2.36533 iter/s, 5.07328s/12 iters), loss = 0.0393461
I0422 02:01:01.442888 16011 solver.cpp:237]     Train net output #0: loss = 0.039346 (* 1 = 0.039346 loss)
I0422 02:01:01.442899 16011 sgd_solver.cpp:105] Iteration 7836, lr = 0.00211781
I0422 02:01:06.751368 16011 solver.cpp:218] Iteration 7848 (2.26059 iter/s, 5.30834s/12 iters), loss = 0.0570229
I0422 02:01:06.751410 16011 solver.cpp:237]     Train net output #0: loss = 0.0570228 (* 1 = 0.0570228 loss)
I0422 02:01:06.751420 16011 sgd_solver.cpp:105] Iteration 7848, lr = 0.00211279
I0422 02:01:08.946768 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_7854.caffemodel
I0422 02:01:20.100972 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_7854.solverstate
I0422 02:01:26.632091 16011 solver.cpp:330] Iteration 7854, Testing net (#0)
I0422 02:01:26.632184 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:01:27.951131 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:01:31.074170 16011 solver.cpp:397]     Test net output #0: accuracy = 0.46875
I0422 02:01:31.074205 16011 solver.cpp:397]     Test net output #1: loss = 2.99989 (* 1 = 2.99989 loss)
I0422 02:01:32.903858 16011 solver.cpp:218] Iteration 7860 (0.458859 iter/s, 26.1518s/12 iters), loss = 0.0322019
I0422 02:01:32.903898 16011 solver.cpp:237]     Train net output #0: loss = 0.0322017 (* 1 = 0.0322017 loss)
I0422 02:01:32.903908 16011 sgd_solver.cpp:105] Iteration 7860, lr = 0.00210777
I0422 02:01:38.125741 16011 solver.cpp:218] Iteration 7872 (2.2981 iter/s, 5.22171s/12 iters), loss = 0.163485
I0422 02:01:38.125778 16011 solver.cpp:237]     Train net output #0: loss = 0.163485 (* 1 = 0.163485 loss)
I0422 02:01:38.125787 16011 sgd_solver.cpp:105] Iteration 7872, lr = 0.00210277
I0422 02:01:43.341670 16011 solver.cpp:218] Iteration 7884 (2.30072 iter/s, 5.21575s/12 iters), loss = 0.0609848
I0422 02:01:43.341712 16011 solver.cpp:237]     Train net output #0: loss = 0.0609847 (* 1 = 0.0609847 loss)
I0422 02:01:43.341722 16011 sgd_solver.cpp:105] Iteration 7884, lr = 0.00209777
I0422 02:01:45.526679 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:01:48.553251 16011 solver.cpp:218] Iteration 7896 (2.30265 iter/s, 5.21139s/12 iters), loss = 0.049687
I0422 02:01:48.553310 16011 solver.cpp:237]     Train net output #0: loss = 0.0496869 (* 1 = 0.0496869 loss)
I0422 02:01:48.553323 16011 sgd_solver.cpp:105] Iteration 7896, lr = 0.00209279
I0422 02:01:53.848268 16011 solver.cpp:218] Iteration 7908 (2.26636 iter/s, 5.29482s/12 iters), loss = 0.0488462
I0422 02:01:53.848312 16011 solver.cpp:237]     Train net output #0: loss = 0.0488461 (* 1 = 0.0488461 loss)
I0422 02:01:53.848323 16011 sgd_solver.cpp:105] Iteration 7908, lr = 0.00208782
I0422 02:01:59.315635 16011 solver.cpp:218] Iteration 7920 (2.19492 iter/s, 5.46718s/12 iters), loss = 0.0266382
I0422 02:01:59.359975 16011 solver.cpp:237]     Train net output #0: loss = 0.0266381 (* 1 = 0.0266381 loss)
I0422 02:01:59.359990 16011 sgd_solver.cpp:105] Iteration 7920, lr = 0.00208287
I0422 02:02:04.404336 16011 solver.cpp:218] Iteration 7932 (2.37895 iter/s, 5.04424s/12 iters), loss = 0.0912587
I0422 02:02:04.404388 16011 solver.cpp:237]     Train net output #0: loss = 0.0912585 (* 1 = 0.0912585 loss)
I0422 02:02:04.404399 16011 sgd_solver.cpp:105] Iteration 7932, lr = 0.00207792
I0422 02:02:09.570086 16011 solver.cpp:218] Iteration 7944 (2.32308 iter/s, 5.16557s/12 iters), loss = 0.0752823
I0422 02:02:09.570129 16011 solver.cpp:237]     Train net output #0: loss = 0.0752822 (* 1 = 0.0752822 loss)
I0422 02:02:09.570137 16011 sgd_solver.cpp:105] Iteration 7944, lr = 0.00207299
I0422 02:02:14.175437 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_7956.caffemodel
I0422 02:02:26.840314 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_7956.solverstate
I0422 02:02:35.142740 16011 solver.cpp:330] Iteration 7956, Testing net (#0)
I0422 02:02:35.143447 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:02:36.440166 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:02:39.761116 16011 solver.cpp:397]     Test net output #0: accuracy = 0.458333
I0422 02:02:39.761143 16011 solver.cpp:397]     Test net output #1: loss = 3.01979 (* 1 = 3.01979 loss)
I0422 02:02:39.855922 16011 solver.cpp:218] Iteration 7956 (0.396235 iter/s, 30.2851s/12 iters), loss = 0.0823686
I0422 02:02:39.855967 16011 solver.cpp:237]     Train net output #0: loss = 0.0823684 (* 1 = 0.0823684 loss)
I0422 02:02:39.855976 16011 sgd_solver.cpp:105] Iteration 7956, lr = 0.00206807
I0422 02:02:44.231789 16011 solver.cpp:218] Iteration 7968 (2.74242 iter/s, 4.3757s/12 iters), loss = 0.0354392
I0422 02:02:44.231832 16011 solver.cpp:237]     Train net output #0: loss = 0.0354391 (* 1 = 0.0354391 loss)
I0422 02:02:44.231840 16011 sgd_solver.cpp:105] Iteration 7968, lr = 0.00206316
I0422 02:02:49.503929 16011 solver.cpp:218] Iteration 7980 (2.27619 iter/s, 5.27196s/12 iters), loss = 0.0412919
I0422 02:02:49.503979 16011 solver.cpp:237]     Train net output #0: loss = 0.0412918 (* 1 = 0.0412918 loss)
I0422 02:02:49.503990 16011 sgd_solver.cpp:105] Iteration 7980, lr = 0.00205826
I0422 02:02:53.900246 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:02:54.630707 16011 solver.cpp:218] Iteration 7992 (2.34074 iter/s, 5.12659s/12 iters), loss = 0.0985061
I0422 02:02:54.630756 16011 solver.cpp:237]     Train net output #0: loss = 0.0985059 (* 1 = 0.0985059 loss)
I0422 02:02:54.630765 16011 sgd_solver.cpp:105] Iteration 7992, lr = 0.00205337
I0422 02:02:59.883002 16011 solver.cpp:218] Iteration 8004 (2.2848 iter/s, 5.25211s/12 iters), loss = 0.0900296
I0422 02:02:59.883047 16011 solver.cpp:237]     Train net output #0: loss = 0.0900294 (* 1 = 0.0900294 loss)
I0422 02:02:59.883056 16011 sgd_solver.cpp:105] Iteration 8004, lr = 0.0020485
I0422 02:03:05.036741 16011 solver.cpp:218] Iteration 8016 (2.32849 iter/s, 5.15356s/12 iters), loss = 0.0495605
I0422 02:03:05.036782 16011 solver.cpp:237]     Train net output #0: loss = 0.0495603 (* 1 = 0.0495603 loss)
I0422 02:03:05.036790 16011 sgd_solver.cpp:105] Iteration 8016, lr = 0.00204363
I0422 02:03:10.232666 16011 solver.cpp:218] Iteration 8028 (2.30958 iter/s, 5.19575s/12 iters), loss = 0.0707937
I0422 02:03:10.232815 16011 solver.cpp:237]     Train net output #0: loss = 0.0707935 (* 1 = 0.0707935 loss)
I0422 02:03:10.232827 16011 sgd_solver.cpp:105] Iteration 8028, lr = 0.00203878
I0422 02:03:15.429164 16011 solver.cpp:218] Iteration 8040 (2.30937 iter/s, 5.19622s/12 iters), loss = 0.0891285
I0422 02:03:15.429212 16011 solver.cpp:237]     Train net output #0: loss = 0.0891284 (* 1 = 0.0891284 loss)
I0422 02:03:15.429224 16011 sgd_solver.cpp:105] Iteration 8040, lr = 0.00203394
I0422 02:03:20.565687 16011 solver.cpp:218] Iteration 8052 (2.33629 iter/s, 5.13634s/12 iters), loss = 0.181949
I0422 02:03:20.565729 16011 solver.cpp:237]     Train net output #0: loss = 0.181948 (* 1 = 0.181948 loss)
I0422 02:03:20.565739 16011 sgd_solver.cpp:105] Iteration 8052, lr = 0.00202911
I0422 02:03:22.664943 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_8058.caffemodel
I0422 02:03:33.905315 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_8058.solverstate
I0422 02:03:47.188386 16011 solver.cpp:330] Iteration 8058, Testing net (#0)
I0422 02:03:47.188552 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:03:48.397034 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:03:51.589617 16011 solver.cpp:397]     Test net output #0: accuracy = 0.466912
I0422 02:03:51.589648 16011 solver.cpp:397]     Test net output #1: loss = 3.06607 (* 1 = 3.06607 loss)
I0422 02:03:53.430377 16011 solver.cpp:218] Iteration 8064 (0.365143 iter/s, 32.8639s/12 iters), loss = 0.112761
I0422 02:03:53.430420 16011 solver.cpp:237]     Train net output #0: loss = 0.112761 (* 1 = 0.112761 loss)
I0422 02:03:53.430429 16011 sgd_solver.cpp:105] Iteration 8064, lr = 0.00202429
I0422 02:03:58.766211 16011 solver.cpp:218] Iteration 8076 (2.24902 iter/s, 5.33565s/12 iters), loss = 0.0935067
I0422 02:03:58.766263 16011 solver.cpp:237]     Train net output #0: loss = 0.0935065 (* 1 = 0.0935065 loss)
I0422 02:03:58.766276 16011 sgd_solver.cpp:105] Iteration 8076, lr = 0.00201949
I0422 02:04:03.970590 16011 solver.cpp:218] Iteration 8088 (2.30583 iter/s, 5.20419s/12 iters), loss = 0.133031
I0422 02:04:03.970645 16011 solver.cpp:237]     Train net output #0: loss = 0.133031 (* 1 = 0.133031 loss)
I0422 02:04:03.970656 16011 sgd_solver.cpp:105] Iteration 8088, lr = 0.00201469
I0422 02:04:05.444341 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:04:08.999323 16011 solver.cpp:218] Iteration 8100 (2.38637 iter/s, 5.02855s/12 iters), loss = 0.0605687
I0422 02:04:08.999364 16011 solver.cpp:237]     Train net output #0: loss = 0.0605685 (* 1 = 0.0605685 loss)
I0422 02:04:08.999373 16011 sgd_solver.cpp:105] Iteration 8100, lr = 0.00200991
I0422 02:04:14.361856 16011 solver.cpp:218] Iteration 8112 (2.23783 iter/s, 5.36235s/12 iters), loss = 0.136719
I0422 02:04:14.361898 16011 solver.cpp:237]     Train net output #0: loss = 0.136719 (* 1 = 0.136719 loss)
I0422 02:04:14.361907 16011 sgd_solver.cpp:105] Iteration 8112, lr = 0.00200514
I0422 02:04:19.714903 16011 solver.cpp:218] Iteration 8124 (2.24179 iter/s, 5.35286s/12 iters), loss = 0.025002
I0422 02:04:19.770188 16011 solver.cpp:237]     Train net output #0: loss = 0.0250018 (* 1 = 0.0250018 loss)
I0422 02:04:19.770205 16011 sgd_solver.cpp:105] Iteration 8124, lr = 0.00200038
I0422 02:04:25.011209 16011 solver.cpp:218] Iteration 8136 (2.28969 iter/s, 5.24089s/12 iters), loss = 0.0810088
I0422 02:04:25.011256 16011 solver.cpp:237]     Train net output #0: loss = 0.0810086 (* 1 = 0.0810086 loss)
I0422 02:04:25.011265 16011 sgd_solver.cpp:105] Iteration 8136, lr = 0.00199563
I0422 02:04:30.440074 16011 solver.cpp:218] Iteration 8148 (2.21048 iter/s, 5.42868s/12 iters), loss = 0.132414
I0422 02:04:30.440117 16011 solver.cpp:237]     Train net output #0: loss = 0.132414 (* 1 = 0.132414 loss)
I0422 02:04:30.440125 16011 sgd_solver.cpp:105] Iteration 8148, lr = 0.00199089
I0422 02:04:35.096608 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_8160.caffemodel
I0422 02:04:39.144316 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_8160.solverstate
I0422 02:04:44.248941 16011 solver.cpp:330] Iteration 8160, Testing net (#0)
I0422 02:04:44.248965 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:04:45.477571 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:04:48.695968 16011 solver.cpp:397]     Test net output #0: accuracy = 0.479167
I0422 02:04:48.696010 16011 solver.cpp:397]     Test net output #1: loss = 3.10397 (* 1 = 3.10397 loss)
I0422 02:04:48.790832 16011 solver.cpp:218] Iteration 8160 (0.653941 iter/s, 18.3503s/12 iters), loss = 0.0511104
I0422 02:04:48.790877 16011 solver.cpp:237]     Train net output #0: loss = 0.0511103 (* 1 = 0.0511103 loss)
I0422 02:04:48.790887 16011 sgd_solver.cpp:105] Iteration 8160, lr = 0.00198616
I0422 02:04:53.207187 16011 solver.cpp:218] Iteration 8172 (2.71728 iter/s, 4.41619s/12 iters), loss = 0.0164974
I0422 02:04:53.207300 16011 solver.cpp:237]     Train net output #0: loss = 0.0164972 (* 1 = 0.0164972 loss)
I0422 02:04:53.207312 16011 sgd_solver.cpp:105] Iteration 8172, lr = 0.00198145
I0422 02:04:58.453099 16011 solver.cpp:218] Iteration 8184 (2.2876 iter/s, 5.24566s/12 iters), loss = 0.0785054
I0422 02:04:58.453145 16011 solver.cpp:237]     Train net output #0: loss = 0.0785053 (* 1 = 0.0785053 loss)
I0422 02:04:58.453153 16011 sgd_solver.cpp:105] Iteration 8184, lr = 0.00197674
I0422 02:05:02.259589 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:05:03.878571 16011 solver.cpp:218] Iteration 8196 (2.21187 iter/s, 5.42528s/12 iters), loss = 0.0784495
I0422 02:05:03.878614 16011 solver.cpp:237]     Train net output #0: loss = 0.0784493 (* 1 = 0.0784493 loss)
I0422 02:05:03.878625 16011 sgd_solver.cpp:105] Iteration 8196, lr = 0.00197205
I0422 02:05:09.189338 16011 solver.cpp:218] Iteration 8208 (2.25964 iter/s, 5.31059s/12 iters), loss = 0.0630076
I0422 02:05:09.189379 16011 solver.cpp:237]     Train net output #0: loss = 0.0630075 (* 1 = 0.0630075 loss)
I0422 02:05:09.189388 16011 sgd_solver.cpp:105] Iteration 8208, lr = 0.00196737
I0422 02:05:14.696337 16011 solver.cpp:218] Iteration 8220 (2.17912 iter/s, 5.50681s/12 iters), loss = 0.0199663
I0422 02:05:14.696377 16011 solver.cpp:237]     Train net output #0: loss = 0.0199662 (* 1 = 0.0199662 loss)
I0422 02:05:14.696385 16011 sgd_solver.cpp:105] Iteration 8220, lr = 0.0019627
I0422 02:05:19.812305 16011 solver.cpp:218] Iteration 8232 (2.34568 iter/s, 5.11579s/12 iters), loss = 0.105648
I0422 02:05:19.812346 16011 solver.cpp:237]     Train net output #0: loss = 0.105648 (* 1 = 0.105648 loss)
I0422 02:05:19.812356 16011 sgd_solver.cpp:105] Iteration 8232, lr = 0.00195804
I0422 02:05:25.030337 16011 solver.cpp:218] Iteration 8244 (2.29979 iter/s, 5.21786s/12 iters), loss = 0.059001
I0422 02:05:25.030462 16011 solver.cpp:237]     Train net output #0: loss = 0.0590009 (* 1 = 0.0590009 loss)
I0422 02:05:25.030472 16011 sgd_solver.cpp:105] Iteration 8244, lr = 0.00195339
I0422 02:05:30.203883 16011 solver.cpp:218] Iteration 8256 (2.31961 iter/s, 5.17328s/12 iters), loss = 0.0815533
I0422 02:05:30.203933 16011 solver.cpp:237]     Train net output #0: loss = 0.0815531 (* 1 = 0.0815531 loss)
I0422 02:05:30.203944 16011 sgd_solver.cpp:105] Iteration 8256, lr = 0.00194875
I0422 02:05:32.482522 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_8262.caffemodel
I0422 02:05:36.215291 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_8262.solverstate
I0422 02:05:38.524145 16011 solver.cpp:330] Iteration 8262, Testing net (#0)
I0422 02:05:38.524174 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:05:39.692831 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:05:42.996155 16011 solver.cpp:397]     Test net output #0: accuracy = 0.456495
I0422 02:05:42.996203 16011 solver.cpp:397]     Test net output #1: loss = 3.14139 (* 1 = 3.14139 loss)
I0422 02:05:44.893429 16011 solver.cpp:218] Iteration 8268 (0.81693 iter/s, 14.6891s/12 iters), loss = 0.0333922
I0422 02:05:44.893477 16011 solver.cpp:237]     Train net output #0: loss = 0.0333921 (* 1 = 0.0333921 loss)
I0422 02:05:44.893487 16011 sgd_solver.cpp:105] Iteration 8268, lr = 0.00194412
I0422 02:05:50.036753 16011 solver.cpp:218] Iteration 8280 (2.3332 iter/s, 5.14315s/12 iters), loss = 0.0917804
I0422 02:05:50.036793 16011 solver.cpp:237]     Train net output #0: loss = 0.0917803 (* 1 = 0.0917803 loss)
I0422 02:05:50.036803 16011 sgd_solver.cpp:105] Iteration 8280, lr = 0.00193951
I0422 02:05:55.102349 16011 solver.cpp:218] Iteration 8292 (2.369 iter/s, 5.06542s/12 iters), loss = 0.125076
I0422 02:05:55.102483 16011 solver.cpp:237]     Train net output #0: loss = 0.125076 (* 1 = 0.125076 loss)
I0422 02:05:55.102494 16011 sgd_solver.cpp:105] Iteration 8292, lr = 0.0019349
I0422 02:05:55.778976 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:06:00.124006 16011 solver.cpp:218] Iteration 8304 (2.38977 iter/s, 5.0214s/12 iters), loss = 0.0242047
I0422 02:06:00.124043 16011 solver.cpp:237]     Train net output #0: loss = 0.0242046 (* 1 = 0.0242046 loss)
I0422 02:06:00.124053 16011 sgd_solver.cpp:105] Iteration 8304, lr = 0.00193031
I0422 02:06:03.171778 16011 blocking_queue.cpp:49] Waiting for data
I0422 02:06:05.375856 16011 solver.cpp:218] Iteration 8316 (2.28499 iter/s, 5.25167s/12 iters), loss = 0.0491127
I0422 02:06:05.375910 16011 solver.cpp:237]     Train net output #0: loss = 0.0491125 (* 1 = 0.0491125 loss)
I0422 02:06:05.375923 16011 sgd_solver.cpp:105] Iteration 8316, lr = 0.00192573
I0422 02:06:10.653597 16011 solver.cpp:218] Iteration 8328 (2.27378 iter/s, 5.27755s/12 iters), loss = 0.156415
I0422 02:06:10.653636 16011 solver.cpp:237]     Train net output #0: loss = 0.156415 (* 1 = 0.156415 loss)
I0422 02:06:10.653645 16011 sgd_solver.cpp:105] Iteration 8328, lr = 0.00192115
I0422 02:06:15.833148 16011 solver.cpp:218] Iteration 8340 (2.31688 iter/s, 5.17938s/12 iters), loss = 0.0283882
I0422 02:06:15.833186 16011 solver.cpp:237]     Train net output #0: loss = 0.028388 (* 1 = 0.028388 loss)
I0422 02:06:15.833195 16011 sgd_solver.cpp:105] Iteration 8340, lr = 0.00191659
I0422 02:06:21.096233 16011 solver.cpp:218] Iteration 8352 (2.28011 iter/s, 5.26291s/12 iters), loss = 0.086
I0422 02:06:21.096276 16011 solver.cpp:237]     Train net output #0: loss = 0.0859998 (* 1 = 0.0859998 loss)
I0422 02:06:21.096285 16011 sgd_solver.cpp:105] Iteration 8352, lr = 0.00191204
I0422 02:06:25.844712 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_8364.caffemodel
I0422 02:06:28.854589 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_8364.solverstate
I0422 02:06:31.161433 16011 solver.cpp:330] Iteration 8364, Testing net (#0)
I0422 02:06:31.161454 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:06:32.327142 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:06:35.753640 16011 solver.cpp:397]     Test net output #0: accuracy = 0.473652
I0422 02:06:35.753684 16011 solver.cpp:397]     Test net output #1: loss = 3.05234 (* 1 = 3.05234 loss)
I0422 02:06:35.849149 16011 solver.cpp:218] Iteration 8364 (0.813421 iter/s, 14.7525s/12 iters), loss = 0.0876776
I0422 02:06:35.849200 16011 solver.cpp:237]     Train net output #0: loss = 0.0876774 (* 1 = 0.0876774 loss)
I0422 02:06:35.849210 16011 sgd_solver.cpp:105] Iteration 8364, lr = 0.0019075
I0422 02:06:40.152381 16011 solver.cpp:218] Iteration 8376 (2.78871 iter/s, 4.30307s/12 iters), loss = 0.0309387
I0422 02:06:40.152426 16011 solver.cpp:237]     Train net output #0: loss = 0.0309386 (* 1 = 0.0309386 loss)
I0422 02:06:40.152436 16011 sgd_solver.cpp:105] Iteration 8376, lr = 0.00190297
I0422 02:06:45.307283 16011 solver.cpp:218] Iteration 8388 (2.32796 iter/s, 5.15472s/12 iters), loss = 0.0379726
I0422 02:06:45.307330 16011 solver.cpp:237]     Train net output #0: loss = 0.0379725 (* 1 = 0.0379725 loss)
I0422 02:06:45.307340 16011 sgd_solver.cpp:105] Iteration 8388, lr = 0.00189846
I0422 02:06:48.197703 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:06:50.488799 16011 solver.cpp:218] Iteration 8400 (2.31601 iter/s, 5.18133s/12 iters), loss = 0.0878915
I0422 02:06:50.488839 16011 solver.cpp:237]     Train net output #0: loss = 0.0878913 (* 1 = 0.0878913 loss)
I0422 02:06:50.488848 16011 sgd_solver.cpp:105] Iteration 8400, lr = 0.00189395
I0422 02:06:55.685791 16011 solver.cpp:218] Iteration 8412 (2.30911 iter/s, 5.19682s/12 iters), loss = 0.0915368
I0422 02:06:55.685834 16011 solver.cpp:237]     Train net output #0: loss = 0.0915366 (* 1 = 0.0915366 loss)
I0422 02:06:55.685843 16011 sgd_solver.cpp:105] Iteration 8412, lr = 0.00188945
I0422 02:07:00.794411 16011 solver.cpp:218] Iteration 8424 (2.34905 iter/s, 5.10845s/12 iters), loss = 0.0776179
I0422 02:07:00.794569 16011 solver.cpp:237]     Train net output #0: loss = 0.0776177 (* 1 = 0.0776177 loss)
I0422 02:07:00.794579 16011 sgd_solver.cpp:105] Iteration 8424, lr = 0.00188497
I0422 02:07:05.862030 16011 solver.cpp:218] Iteration 8436 (2.36811 iter/s, 5.06734s/12 iters), loss = 0.0147828
I0422 02:07:05.862067 16011 solver.cpp:237]     Train net output #0: loss = 0.0147826 (* 1 = 0.0147826 loss)
I0422 02:07:05.862076 16011 sgd_solver.cpp:105] Iteration 8436, lr = 0.00188049
I0422 02:07:10.951268 16011 solver.cpp:218] Iteration 8448 (2.358 iter/s, 5.08907s/12 iters), loss = 0.0433466
I0422 02:07:10.951313 16011 solver.cpp:237]     Train net output #0: loss = 0.0433464 (* 1 = 0.0433464 loss)
I0422 02:07:10.951323 16011 sgd_solver.cpp:105] Iteration 8448, lr = 0.00187603
I0422 02:07:16.105844 16011 solver.cpp:218] Iteration 8460 (2.32811 iter/s, 5.1544s/12 iters), loss = 0.0961794
I0422 02:07:16.105888 16011 solver.cpp:237]     Train net output #0: loss = 0.0961792 (* 1 = 0.0961792 loss)
I0422 02:07:16.105897 16011 sgd_solver.cpp:105] Iteration 8460, lr = 0.00187157
I0422 02:07:18.204892 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_8466.caffemodel
I0422 02:07:21.181761 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_8466.solverstate
I0422 02:07:23.483844 16011 solver.cpp:330] Iteration 8466, Testing net (#0)
I0422 02:07:23.483862 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:07:24.578745 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:07:27.990110 16011 solver.cpp:397]     Test net output #0: accuracy = 0.470588
I0422 02:07:27.990139 16011 solver.cpp:397]     Test net output #1: loss = 3.03383 (* 1 = 3.03383 loss)
I0422 02:07:29.939757 16011 solver.cpp:218] Iteration 8472 (0.867458 iter/s, 13.8335s/12 iters), loss = 0.0880678
I0422 02:07:29.939815 16011 solver.cpp:237]     Train net output #0: loss = 0.0880676 (* 1 = 0.0880676 loss)
I0422 02:07:29.939826 16011 sgd_solver.cpp:105] Iteration 8472, lr = 0.00186713
I0422 02:07:35.257817 16011 solver.cpp:218] Iteration 8484 (2.25654 iter/s, 5.31787s/12 iters), loss = 0.173085
I0422 02:07:35.257926 16011 solver.cpp:237]     Train net output #0: loss = 0.173085 (* 1 = 0.173085 loss)
I0422 02:07:35.257936 16011 sgd_solver.cpp:105] Iteration 8484, lr = 0.0018627
I0422 02:07:40.411933 16011 solver.cpp:218] Iteration 8496 (2.32835 iter/s, 5.15387s/12 iters), loss = 0.109532
I0422 02:07:40.411976 16011 solver.cpp:237]     Train net output #0: loss = 0.109532 (* 1 = 0.109532 loss)
I0422 02:07:40.411985 16011 sgd_solver.cpp:105] Iteration 8496, lr = 0.00185827
I0422 02:07:40.449549 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:07:45.628185 16011 solver.cpp:218] Iteration 8508 (2.30058 iter/s, 5.21608s/12 iters), loss = 0.108949
I0422 02:07:45.628226 16011 solver.cpp:237]     Train net output #0: loss = 0.108948 (* 1 = 0.108948 loss)
I0422 02:07:45.628235 16011 sgd_solver.cpp:105] Iteration 8508, lr = 0.00185386
I0422 02:07:50.852840 16011 solver.cpp:218] Iteration 8520 (2.29688 iter/s, 5.22448s/12 iters), loss = 0.0170284
I0422 02:07:50.852878 16011 solver.cpp:237]     Train net output #0: loss = 0.0170281 (* 1 = 0.0170281 loss)
I0422 02:07:50.852888 16011 sgd_solver.cpp:105] Iteration 8520, lr = 0.00184946
I0422 02:07:56.391953 16011 solver.cpp:218] Iteration 8532 (2.16648 iter/s, 5.53893s/12 iters), loss = 0.0695816
I0422 02:07:56.391990 16011 solver.cpp:237]     Train net output #0: loss = 0.0695814 (* 1 = 0.0695814 loss)
I0422 02:07:56.392000 16011 sgd_solver.cpp:105] Iteration 8532, lr = 0.00184507
I0422 02:08:01.713882 16011 solver.cpp:218] Iteration 8544 (2.2549 iter/s, 5.32175s/12 iters), loss = 0.0215444
I0422 02:08:01.713925 16011 solver.cpp:237]     Train net output #0: loss = 0.0215442 (* 1 = 0.0215442 loss)
I0422 02:08:01.713934 16011 sgd_solver.cpp:105] Iteration 8544, lr = 0.00184069
I0422 02:08:07.004937 16011 solver.cpp:218] Iteration 8556 (2.26806 iter/s, 5.29087s/12 iters), loss = 0.0786314
I0422 02:08:07.005110 16011 solver.cpp:237]     Train net output #0: loss = 0.0786312 (* 1 = 0.0786312 loss)
I0422 02:08:07.005122 16011 sgd_solver.cpp:105] Iteration 8556, lr = 0.00183632
I0422 02:08:11.595794 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_8568.caffemodel
I0422 02:08:14.579586 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_8568.solverstate
I0422 02:08:17.414876 16011 solver.cpp:330] Iteration 8568, Testing net (#0)
I0422 02:08:17.414899 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:08:18.596766 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:08:21.994007 16011 solver.cpp:397]     Test net output #0: accuracy = 0.473039
I0422 02:08:21.994045 16011 solver.cpp:397]     Test net output #1: loss = 3.00687 (* 1 = 3.00687 loss)
I0422 02:08:22.089026 16011 solver.cpp:218] Iteration 8568 (0.795568 iter/s, 15.0836s/12 iters), loss = 0.0226853
I0422 02:08:22.089079 16011 solver.cpp:237]     Train net output #0: loss = 0.022685 (* 1 = 0.022685 loss)
I0422 02:08:22.089092 16011 sgd_solver.cpp:105] Iteration 8568, lr = 0.00183196
I0422 02:08:26.215771 16011 solver.cpp:218] Iteration 8580 (2.90798 iter/s, 4.12658s/12 iters), loss = 0.111231
I0422 02:08:26.215826 16011 solver.cpp:237]     Train net output #0: loss = 0.111231 (* 1 = 0.111231 loss)
I0422 02:08:26.215837 16011 sgd_solver.cpp:105] Iteration 8580, lr = 0.00182761
I0422 02:08:31.305719 16011 solver.cpp:218] Iteration 8592 (2.35767 iter/s, 5.08976s/12 iters), loss = 0.0572775
I0422 02:08:31.305769 16011 solver.cpp:237]     Train net output #0: loss = 0.0572772 (* 1 = 0.0572772 loss)
I0422 02:08:31.305780 16011 sgd_solver.cpp:105] Iteration 8592, lr = 0.00182327
I0422 02:08:33.490063 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:08:36.333719 16011 solver.cpp:218] Iteration 8604 (2.38672 iter/s, 5.02782s/12 iters), loss = 0.144694
I0422 02:08:36.333755 16011 solver.cpp:237]     Train net output #0: loss = 0.144694 (* 1 = 0.144694 loss)
I0422 02:08:36.333765 16011 sgd_solver.cpp:105] Iteration 8604, lr = 0.00181894
I0422 02:08:41.447005 16011 solver.cpp:218] Iteration 8616 (2.34691 iter/s, 5.11311s/12 iters), loss = 0.0524795
I0422 02:08:41.447129 16011 solver.cpp:237]     Train net output #0: loss = 0.0524793 (* 1 = 0.0524793 loss)
I0422 02:08:41.447142 16011 sgd_solver.cpp:105] Iteration 8616, lr = 0.00181462
I0422 02:08:46.603544 16011 solver.cpp:218] Iteration 8628 (2.32726 iter/s, 5.15628s/12 iters), loss = 0.131108
I0422 02:08:46.603587 16011 solver.cpp:237]     Train net output #0: loss = 0.131108 (* 1 = 0.131108 loss)
I0422 02:08:46.603596 16011 sgd_solver.cpp:105] Iteration 8628, lr = 0.00181031
I0422 02:08:51.799789 16011 solver.cpp:218] Iteration 8640 (2.30944 iter/s, 5.19607s/12 iters), loss = 0.0370488
I0422 02:08:51.799832 16011 solver.cpp:237]     Train net output #0: loss = 0.0370486 (* 1 = 0.0370486 loss)
I0422 02:08:51.799841 16011 sgd_solver.cpp:105] Iteration 8640, lr = 0.00180602
I0422 02:08:57.045037 16011 solver.cpp:218] Iteration 8652 (2.28786 iter/s, 5.24507s/12 iters), loss = 0.0846464
I0422 02:08:57.045078 16011 solver.cpp:237]     Train net output #0: loss = 0.0846462 (* 1 = 0.0846462 loss)
I0422 02:08:57.045087 16011 sgd_solver.cpp:105] Iteration 8652, lr = 0.00180173
I0422 02:09:02.396677 16011 solver.cpp:218] Iteration 8664 (2.24238 iter/s, 5.35145s/12 iters), loss = 0.0794232
I0422 02:09:02.396719 16011 solver.cpp:237]     Train net output #0: loss = 0.079423 (* 1 = 0.079423 loss)
I0422 02:09:02.396730 16011 sgd_solver.cpp:105] Iteration 8664, lr = 0.00179745
I0422 02:09:04.522637 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_8670.caffemodel
I0422 02:09:07.532915 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_8670.solverstate
I0422 02:09:09.857234 16011 solver.cpp:330] Iteration 8670, Testing net (#0)
I0422 02:09:09.857256 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:09:10.826941 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:09:14.275332 16011 solver.cpp:397]     Test net output #0: accuracy = 0.473652
I0422 02:09:14.275537 16011 solver.cpp:397]     Test net output #1: loss = 3.02593 (* 1 = 3.02593 loss)
I0422 02:09:16.255208 16011 solver.cpp:218] Iteration 8676 (0.865916 iter/s, 13.8582s/12 iters), loss = 0.178912
I0422 02:09:16.255247 16011 solver.cpp:237]     Train net output #0: loss = 0.178912 (* 1 = 0.178912 loss)
I0422 02:09:16.255256 16011 sgd_solver.cpp:105] Iteration 8676, lr = 0.00179318
I0422 02:09:21.426795 16011 solver.cpp:218] Iteration 8688 (2.32045 iter/s, 5.17141s/12 iters), loss = 0.101434
I0422 02:09:21.426831 16011 solver.cpp:237]     Train net output #0: loss = 0.101434 (* 1 = 0.101434 loss)
I0422 02:09:21.426841 16011 sgd_solver.cpp:105] Iteration 8688, lr = 0.00178893
I0422 02:09:25.843910 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:09:26.545612 16011 solver.cpp:218] Iteration 8700 (2.34437 iter/s, 5.11865s/12 iters), loss = 0.184854
I0422 02:09:26.545662 16011 solver.cpp:237]     Train net output #0: loss = 0.184854 (* 1 = 0.184854 loss)
I0422 02:09:26.545675 16011 sgd_solver.cpp:105] Iteration 8700, lr = 0.00178468
I0422 02:09:31.588707 16011 solver.cpp:218] Iteration 8712 (2.37958 iter/s, 5.04292s/12 iters), loss = 0.0394547
I0422 02:09:31.588755 16011 solver.cpp:237]     Train net output #0: loss = 0.0394545 (* 1 = 0.0394545 loss)
I0422 02:09:31.588766 16011 sgd_solver.cpp:105] Iteration 8712, lr = 0.00178044
I0422 02:09:36.778321 16011 solver.cpp:218] Iteration 8724 (2.31239 iter/s, 5.18943s/12 iters), loss = 0.0842967
I0422 02:09:36.778357 16011 solver.cpp:237]     Train net output #0: loss = 0.0842965 (* 1 = 0.0842965 loss)
I0422 02:09:36.778365 16011 sgd_solver.cpp:105] Iteration 8724, lr = 0.00177621
I0422 02:09:41.936347 16011 solver.cpp:218] Iteration 8736 (2.32655 iter/s, 5.15785s/12 iters), loss = 0.0578979
I0422 02:09:41.936385 16011 solver.cpp:237]     Train net output #0: loss = 0.0578977 (* 1 = 0.0578977 loss)
I0422 02:09:41.936395 16011 sgd_solver.cpp:105] Iteration 8736, lr = 0.001772
I0422 02:09:47.224355 16011 solver.cpp:218] Iteration 8748 (2.26936 iter/s, 5.28783s/12 iters), loss = 0.0845195
I0422 02:09:47.224469 16011 solver.cpp:237]     Train net output #0: loss = 0.0845193 (* 1 = 0.0845193 loss)
I0422 02:09:47.224481 16011 sgd_solver.cpp:105] Iteration 8748, lr = 0.00176779
I0422 02:09:52.459749 16011 solver.cpp:218] Iteration 8760 (2.2922 iter/s, 5.23515s/12 iters), loss = 0.0695915
I0422 02:09:52.459794 16011 solver.cpp:237]     Train net output #0: loss = 0.0695913 (* 1 = 0.0695913 loss)
I0422 02:09:52.459805 16011 sgd_solver.cpp:105] Iteration 8760, lr = 0.00176359
I0422 02:09:57.305824 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_8772.caffemodel
I0422 02:10:03.552541 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_8772.solverstate
I0422 02:10:05.848760 16011 solver.cpp:330] Iteration 8772, Testing net (#0)
I0422 02:10:05.848788 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:10:06.757688 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:10:10.261399 16011 solver.cpp:397]     Test net output #0: accuracy = 0.463848
I0422 02:10:10.261431 16011 solver.cpp:397]     Test net output #1: loss = 3.01987 (* 1 = 3.01987 loss)
I0422 02:10:10.356695 16011 solver.cpp:218] Iteration 8772 (0.670523 iter/s, 17.8965s/12 iters), loss = 0.0711453
I0422 02:10:10.356750 16011 solver.cpp:237]     Train net output #0: loss = 0.0711451 (* 1 = 0.0711451 loss)
I0422 02:10:10.356762 16011 sgd_solver.cpp:105] Iteration 8772, lr = 0.00175941
I0422 02:10:14.669710 16011 solver.cpp:218] Iteration 8784 (2.78238 iter/s, 4.31285s/12 iters), loss = 0.0866905
I0422 02:10:14.669754 16011 solver.cpp:237]     Train net output #0: loss = 0.0866903 (* 1 = 0.0866903 loss)
I0422 02:10:14.669762 16011 sgd_solver.cpp:105] Iteration 8784, lr = 0.00175523
I0422 02:10:20.129652 16011 solver.cpp:218] Iteration 8796 (2.1979 iter/s, 5.45976s/12 iters), loss = 0.079093
I0422 02:10:20.129812 16011 solver.cpp:237]     Train net output #0: loss = 0.0790928 (* 1 = 0.0790928 loss)
I0422 02:10:20.129823 16011 sgd_solver.cpp:105] Iteration 8796, lr = 0.00175106
I0422 02:10:21.721061 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:10:25.733304 16011 solver.cpp:218] Iteration 8808 (2.14157 iter/s, 5.60335s/12 iters), loss = 0.0454604
I0422 02:10:25.733345 16011 solver.cpp:237]     Train net output #0: loss = 0.0454602 (* 1 = 0.0454602 loss)
I0422 02:10:25.733355 16011 sgd_solver.cpp:105] Iteration 8808, lr = 0.0017469
I0422 02:10:30.915015 16011 solver.cpp:218] Iteration 8820 (2.31592 iter/s, 5.18154s/12 iters), loss = 0.0435772
I0422 02:10:30.915063 16011 solver.cpp:237]     Train net output #0: loss = 0.043577 (* 1 = 0.043577 loss)
I0422 02:10:30.915073 16011 sgd_solver.cpp:105] Iteration 8820, lr = 0.00174276
I0422 02:10:36.051803 16011 solver.cpp:218] Iteration 8832 (2.33617 iter/s, 5.13661s/12 iters), loss = 0.133898
I0422 02:10:36.051842 16011 solver.cpp:237]     Train net output #0: loss = 0.133898 (* 1 = 0.133898 loss)
I0422 02:10:36.051852 16011 sgd_solver.cpp:105] Iteration 8832, lr = 0.00173862
I0422 02:10:41.442504 16011 solver.cpp:218] Iteration 8844 (2.22613 iter/s, 5.39052s/12 iters), loss = 0.0511543
I0422 02:10:41.442557 16011 solver.cpp:237]     Train net output #0: loss = 0.0511542 (* 1 = 0.0511542 loss)
I0422 02:10:41.442569 16011 sgd_solver.cpp:105] Iteration 8844, lr = 0.00173449
I0422 02:10:46.606295 16011 solver.cpp:218] Iteration 8856 (2.32396 iter/s, 5.1636s/12 iters), loss = 0.0607552
I0422 02:10:46.606343 16011 solver.cpp:237]     Train net output #0: loss = 0.060755 (* 1 = 0.060755 loss)
I0422 02:10:46.606355 16011 sgd_solver.cpp:105] Iteration 8856, lr = 0.00173037
I0422 02:10:51.686784 16011 solver.cpp:218] Iteration 8868 (2.36206 iter/s, 5.08031s/12 iters), loss = 0.0515266
I0422 02:10:51.686929 16011 solver.cpp:237]     Train net output #0: loss = 0.0515264 (* 1 = 0.0515264 loss)
I0422 02:10:51.686941 16011 sgd_solver.cpp:105] Iteration 8868, lr = 0.00172626
I0422 02:10:53.774224 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_8874.caffemodel
I0422 02:11:02.317960 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_8874.solverstate
I0422 02:11:07.382055 16011 solver.cpp:330] Iteration 8874, Testing net (#0)
I0422 02:11:07.382079 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:11:08.438365 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:11:11.988477 16011 solver.cpp:397]     Test net output #0: accuracy = 0.480392
I0422 02:11:11.988550 16011 solver.cpp:397]     Test net output #1: loss = 3.06602 (* 1 = 3.06602 loss)
I0422 02:11:13.808025 16011 solver.cpp:218] Iteration 8880 (0.542482 iter/s, 22.1206s/12 iters), loss = 0.101724
I0422 02:11:13.808086 16011 solver.cpp:237]     Train net output #0: loss = 0.101724 (* 1 = 0.101724 loss)
I0422 02:11:13.808101 16011 sgd_solver.cpp:105] Iteration 8880, lr = 0.00172217
I0422 02:11:19.061528 16011 solver.cpp:218] Iteration 8892 (2.28428 iter/s, 5.25331s/12 iters), loss = 0.023168
I0422 02:11:19.061573 16011 solver.cpp:237]     Train net output #0: loss = 0.0231678 (* 1 = 0.0231678 loss)
I0422 02:11:19.061581 16011 sgd_solver.cpp:105] Iteration 8892, lr = 0.00171808
I0422 02:11:22.797968 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:11:24.256753 16011 solver.cpp:218] Iteration 8904 (2.30989 iter/s, 5.19505s/12 iters), loss = 0.0839246
I0422 02:11:24.256795 16011 solver.cpp:237]     Train net output #0: loss = 0.0839244 (* 1 = 0.0839244 loss)
I0422 02:11:24.256804 16011 sgd_solver.cpp:105] Iteration 8904, lr = 0.001714
I0422 02:11:29.515655 16011 solver.cpp:218] Iteration 8916 (2.28192 iter/s, 5.25872s/12 iters), loss = 0.0278308
I0422 02:11:29.515704 16011 solver.cpp:237]     Train net output #0: loss = 0.0278306 (* 1 = 0.0278306 loss)
I0422 02:11:29.515714 16011 sgd_solver.cpp:105] Iteration 8916, lr = 0.00170993
I0422 02:11:34.631239 16011 solver.cpp:218] Iteration 8928 (2.34586 iter/s, 5.1154s/12 iters), loss = 0.0126855
I0422 02:11:34.631294 16011 solver.cpp:237]     Train net output #0: loss = 0.0126854 (* 1 = 0.0126854 loss)
I0422 02:11:34.631305 16011 sgd_solver.cpp:105] Iteration 8928, lr = 0.00170587
I0422 02:11:39.824997 16011 solver.cpp:218] Iteration 8940 (2.31055 iter/s, 5.19357s/12 iters), loss = 0.0267469
I0422 02:11:39.825042 16011 solver.cpp:237]     Train net output #0: loss = 0.0267467 (* 1 = 0.0267467 loss)
I0422 02:11:39.825050 16011 sgd_solver.cpp:105] Iteration 8940, lr = 0.00170182
I0422 02:11:45.099942 16011 solver.cpp:218] Iteration 8952 (2.27498 iter/s, 5.27476s/12 iters), loss = 0.0350624
I0422 02:11:45.099983 16011 solver.cpp:237]     Train net output #0: loss = 0.0350622 (* 1 = 0.0350622 loss)
I0422 02:11:45.099992 16011 sgd_solver.cpp:105] Iteration 8952, lr = 0.00169778
I0422 02:11:50.185233 16011 solver.cpp:218] Iteration 8964 (2.35983 iter/s, 5.08512s/12 iters), loss = 0.0245959
I0422 02:11:50.185276 16011 solver.cpp:237]     Train net output #0: loss = 0.0245957 (* 1 = 0.0245957 loss)
I0422 02:11:50.185286 16011 sgd_solver.cpp:105] Iteration 8964, lr = 0.00169375
I0422 02:11:54.982887 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_8976.caffemodel
I0422 02:12:05.073832 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_8976.solverstate
I0422 02:12:10.793359 16011 solver.cpp:330] Iteration 8976, Testing net (#0)
I0422 02:12:10.793377 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:12:11.643999 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:12:15.257632 16011 solver.cpp:397]     Test net output #0: accuracy = 0.47549
I0422 02:12:15.257669 16011 solver.cpp:397]     Test net output #1: loss = 3.0866 (* 1 = 3.0866 loss)
I0422 02:12:15.352866 16011 solver.cpp:218] Iteration 8976 (0.476815 iter/s, 25.167s/12 iters), loss = 0.0277951
I0422 02:12:15.352921 16011 solver.cpp:237]     Train net output #0: loss = 0.027795 (* 1 = 0.027795 loss)
I0422 02:12:15.352931 16011 sgd_solver.cpp:105] Iteration 8976, lr = 0.00168973
I0422 02:12:19.584072 16011 solver.cpp:218] Iteration 8988 (2.83618 iter/s, 4.23104s/12 iters), loss = 0.139792
I0422 02:12:19.584108 16011 solver.cpp:237]     Train net output #0: loss = 0.139792 (* 1 = 0.139792 loss)
I0422 02:12:19.584117 16011 sgd_solver.cpp:105] Iteration 8988, lr = 0.00168571
I0422 02:12:23.056764 16011 blocking_queue.cpp:49] Waiting for data
I0422 02:12:24.974689 16011 solver.cpp:218] Iteration 9000 (2.22616 iter/s, 5.39044s/12 iters), loss = 0.0442543
I0422 02:12:24.974730 16011 solver.cpp:237]     Train net output #0: loss = 0.0442542 (* 1 = 0.0442542 loss)
I0422 02:12:24.974738 16011 sgd_solver.cpp:105] Iteration 9000, lr = 0.00168171
I0422 02:12:25.745961 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:12:30.204450 16011 solver.cpp:218] Iteration 9012 (2.29464 iter/s, 5.22958s/12 iters), loss = 0.0164088
I0422 02:12:30.204530 16011 solver.cpp:237]     Train net output #0: loss = 0.0164087 (* 1 = 0.0164087 loss)
I0422 02:12:30.204541 16011 sgd_solver.cpp:105] Iteration 9012, lr = 0.00167772
I0422 02:12:35.452812 16011 solver.cpp:218] Iteration 9024 (2.28652 iter/s, 5.24815s/12 iters), loss = 0.0324857
I0422 02:12:35.452853 16011 solver.cpp:237]     Train net output #0: loss = 0.0324855 (* 1 = 0.0324855 loss)
I0422 02:12:35.452862 16011 sgd_solver.cpp:105] Iteration 9024, lr = 0.00167374
I0422 02:12:40.671546 16011 solver.cpp:218] Iteration 9036 (2.29949 iter/s, 5.21855s/12 iters), loss = 0.0345535
I0422 02:12:40.671595 16011 solver.cpp:237]     Train net output #0: loss = 0.0345533 (* 1 = 0.0345533 loss)
I0422 02:12:40.671607 16011 sgd_solver.cpp:105] Iteration 9036, lr = 0.00166976
I0422 02:12:46.081462 16011 solver.cpp:218] Iteration 9048 (2.21823 iter/s, 5.40973s/12 iters), loss = 0.0736445
I0422 02:12:46.081504 16011 solver.cpp:237]     Train net output #0: loss = 0.0736444 (* 1 = 0.0736444 loss)
I0422 02:12:46.081512 16011 sgd_solver.cpp:105] Iteration 9048, lr = 0.0016658
I0422 02:12:51.132596 16011 solver.cpp:218] Iteration 9060 (2.37579 iter/s, 5.05096s/12 iters), loss = 0.027516
I0422 02:12:51.132637 16011 solver.cpp:237]     Train net output #0: loss = 0.0275158 (* 1 = 0.0275158 loss)
I0422 02:12:51.132645 16011 sgd_solver.cpp:105] Iteration 9060, lr = 0.00166184
I0422 02:12:56.305438 16011 solver.cpp:218] Iteration 9072 (2.31989 iter/s, 5.17267s/12 iters), loss = 0.0804859
I0422 02:12:56.305552 16011 solver.cpp:237]     Train net output #0: loss = 0.0804857 (* 1 = 0.0804857 loss)
I0422 02:12:56.305562 16011 sgd_solver.cpp:105] Iteration 9072, lr = 0.0016579
I0422 02:12:58.447033 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_9078.caffemodel
I0422 02:13:01.434834 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_9078.solverstate
I0422 02:13:05.099361 16011 solver.cpp:330] Iteration 9078, Testing net (#0)
I0422 02:13:05.099383 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:13:05.953804 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:13:09.696033 16011 solver.cpp:397]     Test net output #0: accuracy = 0.473039
I0422 02:13:09.696063 16011 solver.cpp:397]     Test net output #1: loss = 3.15145 (* 1 = 3.15145 loss)
I0422 02:13:11.595841 16011 solver.cpp:218] Iteration 9084 (0.784831 iter/s, 15.2899s/12 iters), loss = 0.0499865
I0422 02:13:11.595885 16011 solver.cpp:237]     Train net output #0: loss = 0.0499863 (* 1 = 0.0499863 loss)
I0422 02:13:11.595896 16011 sgd_solver.cpp:105] Iteration 9084, lr = 0.00165396
I0422 02:13:16.726156 16011 solver.cpp:218] Iteration 9096 (2.33912 iter/s, 5.13013s/12 iters), loss = 0.0518681
I0422 02:13:16.726212 16011 solver.cpp:237]     Train net output #0: loss = 0.051868 (* 1 = 0.051868 loss)
I0422 02:13:16.726223 16011 sgd_solver.cpp:105] Iteration 9096, lr = 0.00165003
I0422 02:13:20.010277 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:13:22.111364 16011 solver.cpp:218] Iteration 9108 (2.22841 iter/s, 5.38502s/12 iters), loss = 0.103666
I0422 02:13:22.111411 16011 solver.cpp:237]     Train net output #0: loss = 0.103665 (* 1 = 0.103665 loss)
I0422 02:13:22.111423 16011 sgd_solver.cpp:105] Iteration 9108, lr = 0.00164612
I0422 02:13:27.256641 16011 solver.cpp:218] Iteration 9120 (2.33232 iter/s, 5.14509s/12 iters), loss = 0.0342457
I0422 02:13:27.256803 16011 solver.cpp:237]     Train net output #0: loss = 0.0342455 (* 1 = 0.0342455 loss)
I0422 02:13:27.256814 16011 sgd_solver.cpp:105] Iteration 9120, lr = 0.00164221
I0422 02:13:32.381390 16011 solver.cpp:218] Iteration 9132 (2.34171 iter/s, 5.12445s/12 iters), loss = 0.0167395
I0422 02:13:32.381434 16011 solver.cpp:237]     Train net output #0: loss = 0.0167393 (* 1 = 0.0167393 loss)
I0422 02:13:32.381443 16011 sgd_solver.cpp:105] Iteration 9132, lr = 0.00163831
I0422 02:13:37.610770 16011 solver.cpp:218] Iteration 9144 (2.29481 iter/s, 5.22919s/12 iters), loss = 0.0751903
I0422 02:13:37.610829 16011 solver.cpp:237]     Train net output #0: loss = 0.0751901 (* 1 = 0.0751901 loss)
I0422 02:13:37.610841 16011 sgd_solver.cpp:105] Iteration 9144, lr = 0.00163442
I0422 02:13:42.750362 16011 solver.cpp:218] Iteration 9156 (2.3349 iter/s, 5.1394s/12 iters), loss = 0.117875
I0422 02:13:42.750419 16011 solver.cpp:237]     Train net output #0: loss = 0.117875 (* 1 = 0.117875 loss)
I0422 02:13:42.750432 16011 sgd_solver.cpp:105] Iteration 9156, lr = 0.00163054
I0422 02:13:47.986721 16011 solver.cpp:218] Iteration 9168 (2.29176 iter/s, 5.23616s/12 iters), loss = 0.0353258
I0422 02:13:47.986773 16011 solver.cpp:237]     Train net output #0: loss = 0.0353256 (* 1 = 0.0353256 loss)
I0422 02:13:47.986788 16011 sgd_solver.cpp:105] Iteration 9168, lr = 0.00162667
I0422 02:13:52.765374 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_9180.caffemodel
I0422 02:13:55.765206 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_9180.solverstate
I0422 02:13:58.054034 16011 solver.cpp:330] Iteration 9180, Testing net (#0)
I0422 02:13:58.054116 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:13:58.941174 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:14:02.848671 16011 solver.cpp:397]     Test net output #0: accuracy = 0.476103
I0422 02:14:02.848706 16011 solver.cpp:397]     Test net output #1: loss = 3.18383 (* 1 = 3.18383 loss)
I0422 02:14:02.944113 16011 solver.cpp:218] Iteration 9180 (0.802301 iter/s, 14.957s/12 iters), loss = 0.0384687
I0422 02:14:02.944159 16011 solver.cpp:237]     Train net output #0: loss = 0.0384685 (* 1 = 0.0384685 loss)
I0422 02:14:02.944166 16011 sgd_solver.cpp:105] Iteration 9180, lr = 0.00162281
I0422 02:14:07.419456 16011 solver.cpp:218] Iteration 9192 (2.68146 iter/s, 4.47518s/12 iters), loss = 0.0544302
I0422 02:14:07.419508 16011 solver.cpp:237]     Train net output #0: loss = 0.05443 (* 1 = 0.05443 loss)
I0422 02:14:07.419519 16011 sgd_solver.cpp:105] Iteration 9192, lr = 0.00161895
I0422 02:14:12.580430 16011 solver.cpp:218] Iteration 9204 (2.32523 iter/s, 5.16079s/12 iters), loss = 0.0408486
I0422 02:14:12.580479 16011 solver.cpp:237]     Train net output #0: loss = 0.0408484 (* 1 = 0.0408484 loss)
I0422 02:14:12.580511 16011 sgd_solver.cpp:105] Iteration 9204, lr = 0.00161511
I0422 02:14:12.665108 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:14:17.691550 16011 solver.cpp:218] Iteration 9216 (2.3479 iter/s, 5.11094s/12 iters), loss = 0.0426307
I0422 02:14:17.691598 16011 solver.cpp:237]     Train net output #0: loss = 0.0426305 (* 1 = 0.0426305 loss)
I0422 02:14:17.691607 16011 sgd_solver.cpp:105] Iteration 9216, lr = 0.00161128
I0422 02:14:22.814621 16011 solver.cpp:218] Iteration 9228 (2.34243 iter/s, 5.12288s/12 iters), loss = 0.00834646
I0422 02:14:22.814677 16011 solver.cpp:237]     Train net output #0: loss = 0.00834628 (* 1 = 0.00834628 loss)
I0422 02:14:22.814689 16011 sgd_solver.cpp:105] Iteration 9228, lr = 0.00160745
I0422 02:14:28.303429 16011 solver.cpp:218] Iteration 9240 (2.18634 iter/s, 5.48862s/12 iters), loss = 0.0913549
I0422 02:14:28.308256 16011 solver.cpp:237]     Train net output #0: loss = 0.0913547 (* 1 = 0.0913547 loss)
I0422 02:14:28.308266 16011 sgd_solver.cpp:105] Iteration 9240, lr = 0.00160363
I0422 02:14:33.418519 16011 solver.cpp:218] Iteration 9252 (2.34828 iter/s, 5.11013s/12 iters), loss = 0.0462764
I0422 02:14:33.418570 16011 solver.cpp:237]     Train net output #0: loss = 0.0462762 (* 1 = 0.0462762 loss)
I0422 02:14:33.418581 16011 sgd_solver.cpp:105] Iteration 9252, lr = 0.00159983
I0422 02:14:38.558547 16011 solver.cpp:218] Iteration 9264 (2.3347 iter/s, 5.13985s/12 iters), loss = 0.0255025
I0422 02:14:38.558588 16011 solver.cpp:237]     Train net output #0: loss = 0.0255023 (* 1 = 0.0255023 loss)
I0422 02:14:38.558598 16011 sgd_solver.cpp:105] Iteration 9264, lr = 0.00159603
I0422 02:14:43.775395 16011 solver.cpp:218] Iteration 9276 (2.30032 iter/s, 5.21667s/12 iters), loss = 0.0653707
I0422 02:14:43.775436 16011 solver.cpp:237]     Train net output #0: loss = 0.0653706 (* 1 = 0.0653706 loss)
I0422 02:14:43.775446 16011 sgd_solver.cpp:105] Iteration 9276, lr = 0.00159224
I0422 02:14:46.017879 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_9282.caffemodel
I0422 02:14:49.024948 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_9282.solverstate
I0422 02:14:52.929976 16011 solver.cpp:330] Iteration 9282, Testing net (#0)
I0422 02:14:52.929997 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:14:53.691236 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:14:57.432073 16011 solver.cpp:397]     Test net output #0: accuracy = 0.470588
I0422 02:14:57.432111 16011 solver.cpp:397]     Test net output #1: loss = 3.15709 (* 1 = 3.15709 loss)
I0422 02:14:59.317435 16011 solver.cpp:218] Iteration 9288 (0.77212 iter/s, 15.5416s/12 iters), loss = 0.0639499
I0422 02:14:59.317557 16011 solver.cpp:237]     Train net output #0: loss = 0.0639497 (* 1 = 0.0639497 loss)
I0422 02:14:59.317566 16011 sgd_solver.cpp:105] Iteration 9288, lr = 0.00158846
I0422 02:15:04.518280 16011 solver.cpp:218] Iteration 9300 (2.30743 iter/s, 5.20059s/12 iters), loss = 0.0596648
I0422 02:15:04.518322 16011 solver.cpp:237]     Train net output #0: loss = 0.0596646 (* 1 = 0.0596646 loss)
I0422 02:15:04.518330 16011 sgd_solver.cpp:105] Iteration 9300, lr = 0.00158469
I0422 02:15:06.796164 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:15:09.688616 16011 solver.cpp:218] Iteration 9312 (2.32101 iter/s, 5.17016s/12 iters), loss = 0.0689207
I0422 02:15:09.688659 16011 solver.cpp:237]     Train net output #0: loss = 0.0689205 (* 1 = 0.0689205 loss)
I0422 02:15:09.688668 16011 sgd_solver.cpp:105] Iteration 9312, lr = 0.00158092
I0422 02:15:14.769429 16011 solver.cpp:218] Iteration 9324 (2.36191 iter/s, 5.08064s/12 iters), loss = 0.113913
I0422 02:15:14.769479 16011 solver.cpp:237]     Train net output #0: loss = 0.113913 (* 1 = 0.113913 loss)
I0422 02:15:14.769490 16011 sgd_solver.cpp:105] Iteration 9324, lr = 0.00157717
I0422 02:15:19.962718 16011 solver.cpp:218] Iteration 9336 (2.31076 iter/s, 5.1931s/12 iters), loss = 0.0451922
I0422 02:15:19.962774 16011 solver.cpp:237]     Train net output #0: loss = 0.045192 (* 1 = 0.045192 loss)
I0422 02:15:19.962788 16011 sgd_solver.cpp:105] Iteration 9336, lr = 0.00157343
I0422 02:15:25.061894 16011 solver.cpp:218] Iteration 9348 (2.35341 iter/s, 5.09899s/12 iters), loss = 0.0129772
I0422 02:15:25.061935 16011 solver.cpp:237]     Train net output #0: loss = 0.0129771 (* 1 = 0.0129771 loss)
I0422 02:15:25.061944 16011 sgd_solver.cpp:105] Iteration 9348, lr = 0.00156969
I0422 02:15:30.234935 16011 solver.cpp:218] Iteration 9360 (2.3198 iter/s, 5.17286s/12 iters), loss = 0.0403478
I0422 02:15:30.235025 16011 solver.cpp:237]     Train net output #0: loss = 0.0403477 (* 1 = 0.0403477 loss)
I0422 02:15:30.235038 16011 sgd_solver.cpp:105] Iteration 9360, lr = 0.00156596
I0422 02:15:35.325103 16011 solver.cpp:218] Iteration 9372 (2.35759 iter/s, 5.08995s/12 iters), loss = 0.0729448
I0422 02:15:35.325142 16011 solver.cpp:237]     Train net output #0: loss = 0.0729446 (* 1 = 0.0729446 loss)
I0422 02:15:35.325152 16011 sgd_solver.cpp:105] Iteration 9372, lr = 0.00156225
I0422 02:15:40.079427 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_9384.caffemodel
I0422 02:15:46.936579 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_9384.solverstate
I0422 02:15:49.215971 16011 solver.cpp:330] Iteration 9384, Testing net (#0)
I0422 02:15:49.215997 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:15:49.984153 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:15:53.921245 16011 solver.cpp:397]     Test net output #0: accuracy = 0.482843
I0422 02:15:53.921278 16011 solver.cpp:397]     Test net output #1: loss = 3.1299 (* 1 = 3.1299 loss)
I0422 02:15:54.016446 16011 solver.cpp:218] Iteration 9384 (0.642025 iter/s, 18.6909s/12 iters), loss = 0.116345
I0422 02:15:54.016517 16011 solver.cpp:237]     Train net output #0: loss = 0.116345 (* 1 = 0.116345 loss)
I0422 02:15:54.016527 16011 sgd_solver.cpp:105] Iteration 9384, lr = 0.00155854
I0422 02:15:58.533030 16011 solver.cpp:218] Iteration 9396 (2.65699 iter/s, 4.51639s/12 iters), loss = 0.0921858
I0422 02:15:58.533078 16011 solver.cpp:237]     Train net output #0: loss = 0.0921856 (* 1 = 0.0921856 loss)
I0422 02:15:58.533088 16011 sgd_solver.cpp:105] Iteration 9396, lr = 0.00155484
I0422 02:16:03.024853 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:16:03.715473 16011 solver.cpp:218] Iteration 9408 (2.31559 iter/s, 5.18226s/12 iters), loss = 0.101779
I0422 02:16:03.715517 16011 solver.cpp:237]     Train net output #0: loss = 0.101779 (* 1 = 0.101779 loss)
I0422 02:16:03.715525 16011 sgd_solver.cpp:105] Iteration 9408, lr = 0.00155114
I0422 02:16:08.881657 16011 solver.cpp:218] Iteration 9420 (2.32288 iter/s, 5.166s/12 iters), loss = 0.0382659
I0422 02:16:08.881712 16011 solver.cpp:237]     Train net output #0: loss = 0.0382658 (* 1 = 0.0382658 loss)
I0422 02:16:08.881722 16011 sgd_solver.cpp:105] Iteration 9420, lr = 0.00154746
I0422 02:16:14.181975 16011 solver.cpp:218] Iteration 9432 (2.26409 iter/s, 5.30013s/12 iters), loss = 0.0631021
I0422 02:16:14.182013 16011 solver.cpp:237]     Train net output #0: loss = 0.063102 (* 1 = 0.063102 loss)
I0422 02:16:14.182021 16011 sgd_solver.cpp:105] Iteration 9432, lr = 0.00154379
I0422 02:16:19.374557 16011 solver.cpp:218] Iteration 9444 (2.31107 iter/s, 5.19241s/12 iters), loss = 0.0299922
I0422 02:16:19.374599 16011 solver.cpp:237]     Train net output #0: loss = 0.029992 (* 1 = 0.029992 loss)
I0422 02:16:19.374608 16011 sgd_solver.cpp:105] Iteration 9444, lr = 0.00154012
I0422 02:16:24.443552 16011 solver.cpp:218] Iteration 9456 (2.36741 iter/s, 5.06882s/12 iters), loss = 0.119337
I0422 02:16:24.443591 16011 solver.cpp:237]     Train net output #0: loss = 0.119337 (* 1 = 0.119337 loss)
I0422 02:16:24.443600 16011 sgd_solver.cpp:105] Iteration 9456, lr = 0.00153647
I0422 02:16:29.693219 16011 solver.cpp:218] Iteration 9468 (2.28594 iter/s, 5.24949s/12 iters), loss = 0.0501353
I0422 02:16:29.693267 16011 solver.cpp:237]     Train net output #0: loss = 0.0501351 (* 1 = 0.0501351 loss)
I0422 02:16:29.693279 16011 sgd_solver.cpp:105] Iteration 9468, lr = 0.00153282
I0422 02:16:34.866165 16011 solver.cpp:218] Iteration 9480 (2.31984 iter/s, 5.17277s/12 iters), loss = 0.0679037
I0422 02:16:34.866305 16011 solver.cpp:237]     Train net output #0: loss = 0.0679035 (* 1 = 0.0679035 loss)
I0422 02:16:34.866319 16011 sgd_solver.cpp:105] Iteration 9480, lr = 0.00152918
I0422 02:16:37.034183 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_9486.caffemodel
I0422 02:16:44.396559 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_9486.solverstate
I0422 02:16:47.380013 16011 solver.cpp:330] Iteration 9486, Testing net (#0)
I0422 02:16:47.380033 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:16:48.091143 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:16:51.865933 16011 solver.cpp:397]     Test net output #0: accuracy = 0.476103
I0422 02:16:51.865960 16011 solver.cpp:397]     Test net output #1: loss = 3.1151 (* 1 = 3.1151 loss)
I0422 02:16:53.724597 16011 solver.cpp:218] Iteration 9492 (0.63634 iter/s, 18.8578s/12 iters), loss = 0.0420134
I0422 02:16:53.724647 16011 solver.cpp:237]     Train net output #0: loss = 0.0420132 (* 1 = 0.0420132 loss)
I0422 02:16:53.724658 16011 sgd_solver.cpp:105] Iteration 9492, lr = 0.00152555
I0422 02:16:58.899690 16011 solver.cpp:218] Iteration 9504 (2.31888 iter/s, 5.17491s/12 iters), loss = 0.021889
I0422 02:16:58.899735 16011 solver.cpp:237]     Train net output #0: loss = 0.0218888 (* 1 = 0.0218888 loss)
I0422 02:16:58.899744 16011 sgd_solver.cpp:105] Iteration 9504, lr = 0.00152193
I0422 02:17:00.396633 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:17:04.022325 16011 solver.cpp:218] Iteration 9516 (2.34262 iter/s, 5.12246s/12 iters), loss = 0.046219
I0422 02:17:04.022361 16011 solver.cpp:237]     Train net output #0: loss = 0.0462188 (* 1 = 0.0462188 loss)
I0422 02:17:04.022369 16011 sgd_solver.cpp:105] Iteration 9516, lr = 0.00151831
I0422 02:17:09.287693 16011 solver.cpp:218] Iteration 9528 (2.27912 iter/s, 5.26519s/12 iters), loss = 0.0196358
I0422 02:17:09.287847 16011 solver.cpp:237]     Train net output #0: loss = 0.0196356 (* 1 = 0.0196356 loss)
I0422 02:17:09.287858 16011 sgd_solver.cpp:105] Iteration 9528, lr = 0.00151471
I0422 02:17:14.427387 16011 solver.cpp:218] Iteration 9540 (2.3349 iter/s, 5.13941s/12 iters), loss = 0.0135066
I0422 02:17:14.427440 16011 solver.cpp:237]     Train net output #0: loss = 0.0135064 (* 1 = 0.0135064 loss)
I0422 02:17:14.427451 16011 sgd_solver.cpp:105] Iteration 9540, lr = 0.00151111
I0422 02:17:19.504091 16011 solver.cpp:218] Iteration 9552 (2.36382 iter/s, 5.07652s/12 iters), loss = 0.0393529
I0422 02:17:19.504133 16011 solver.cpp:237]     Train net output #0: loss = 0.0393527 (* 1 = 0.0393527 loss)
I0422 02:17:19.504142 16011 sgd_solver.cpp:105] Iteration 9552, lr = 0.00150752
I0422 02:17:24.659368 16011 solver.cpp:218] Iteration 9564 (2.32779 iter/s, 5.1551s/12 iters), loss = 0.0179257
I0422 02:17:24.659413 16011 solver.cpp:237]     Train net output #0: loss = 0.0179255 (* 1 = 0.0179255 loss)
I0422 02:17:24.659423 16011 sgd_solver.cpp:105] Iteration 9564, lr = 0.00150395
I0422 02:17:29.726047 16011 solver.cpp:218] Iteration 9576 (2.3685 iter/s, 5.0665s/12 iters), loss = 0.0552339
I0422 02:17:29.726087 16011 solver.cpp:237]     Train net output #0: loss = 0.0552338 (* 1 = 0.0552338 loss)
I0422 02:17:29.726095 16011 sgd_solver.cpp:105] Iteration 9576, lr = 0.00150037
I0422 02:17:34.407245 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_9588.caffemodel
I0422 02:17:37.388532 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_9588.solverstate
I0422 02:17:39.694700 16011 solver.cpp:330] Iteration 9588, Testing net (#0)
I0422 02:17:39.694774 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:17:40.322438 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:17:44.188338 16011 solver.cpp:397]     Test net output #0: accuracy = 0.48652
I0422 02:17:44.188381 16011 solver.cpp:397]     Test net output #1: loss = 3.12794 (* 1 = 3.12794 loss)
I0422 02:17:44.283640 16011 solver.cpp:218] Iteration 9588 (0.824334 iter/s, 14.5572s/12 iters), loss = 0.0830011
I0422 02:17:44.283689 16011 solver.cpp:237]     Train net output #0: loss = 0.083001 (* 1 = 0.083001 loss)
I0422 02:17:44.283701 16011 sgd_solver.cpp:105] Iteration 9588, lr = 0.00149681
I0422 02:17:48.593322 16011 solver.cpp:218] Iteration 9600 (2.78453 iter/s, 4.30952s/12 iters), loss = 0.0421404
I0422 02:17:48.593374 16011 solver.cpp:237]     Train net output #0: loss = 0.0421402 (* 1 = 0.0421402 loss)
I0422 02:17:48.593384 16011 sgd_solver.cpp:105] Iteration 9600, lr = 0.00149326
I0422 02:17:52.599393 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:17:54.163556 16011 solver.cpp:218] Iteration 9612 (2.15438 iter/s, 5.57004s/12 iters), loss = 0.0392073
I0422 02:17:54.163599 16011 solver.cpp:237]     Train net output #0: loss = 0.0392071 (* 1 = 0.0392071 loss)
I0422 02:17:54.163607 16011 sgd_solver.cpp:105] Iteration 9612, lr = 0.00148971
I0422 02:17:59.301462 16011 solver.cpp:218] Iteration 9624 (2.33566 iter/s, 5.13773s/12 iters), loss = 0.0200706
I0422 02:17:59.301525 16011 solver.cpp:237]     Train net output #0: loss = 0.0200704 (* 1 = 0.0200704 loss)
I0422 02:17:59.301537 16011 sgd_solver.cpp:105] Iteration 9624, lr = 0.00148618
I0422 02:18:04.386490 16011 solver.cpp:218] Iteration 9636 (2.35996 iter/s, 5.08483s/12 iters), loss = 0.0970456
I0422 02:18:04.386548 16011 solver.cpp:237]     Train net output #0: loss = 0.0970454 (* 1 = 0.0970454 loss)
I0422 02:18:04.386560 16011 sgd_solver.cpp:105] Iteration 9636, lr = 0.00148265
I0422 02:18:09.417768 16011 solver.cpp:218] Iteration 9648 (2.38517 iter/s, 5.03109s/12 iters), loss = 0.0427365
I0422 02:18:09.417820 16011 solver.cpp:237]     Train net output #0: loss = 0.0427363 (* 1 = 0.0427363 loss)
I0422 02:18:09.417831 16011 sgd_solver.cpp:105] Iteration 9648, lr = 0.00147913
I0422 02:18:14.533627 16011 solver.cpp:218] Iteration 9660 (2.34573 iter/s, 5.11567s/12 iters), loss = 0.0422189
I0422 02:18:14.533787 16011 solver.cpp:237]     Train net output #0: loss = 0.0422187 (* 1 = 0.0422187 loss)
I0422 02:18:14.533802 16011 sgd_solver.cpp:105] Iteration 9660, lr = 0.00147562
I0422 02:18:19.665140 16011 solver.cpp:218] Iteration 9672 (2.33862 iter/s, 5.13122s/12 iters), loss = 0.0190025
I0422 02:18:19.665182 16011 solver.cpp:237]     Train net output #0: loss = 0.0190023 (* 1 = 0.0190023 loss)
I0422 02:18:19.665191 16011 sgd_solver.cpp:105] Iteration 9672, lr = 0.00147211
I0422 02:18:24.907955 16011 solver.cpp:218] Iteration 9684 (2.28892 iter/s, 5.24264s/12 iters), loss = 0.00971833
I0422 02:18:24.907994 16011 solver.cpp:237]     Train net output #0: loss = 0.00971815 (* 1 = 0.00971815 loss)
I0422 02:18:24.908002 16011 sgd_solver.cpp:105] Iteration 9684, lr = 0.00146862
I0422 02:18:26.996376 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_9690.caffemodel
I0422 02:18:32.206030 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_9690.solverstate
I0422 02:18:36.039904 16011 solver.cpp:330] Iteration 9690, Testing net (#0)
I0422 02:18:36.039928 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:18:36.661037 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:18:39.538961 16011 blocking_queue.cpp:49] Waiting for data
I0422 02:18:40.544694 16011 solver.cpp:397]     Test net output #0: accuracy = 0.48652
I0422 02:18:40.544728 16011 solver.cpp:397]     Test net output #1: loss = 3.12962 (* 1 = 3.12962 loss)
I0422 02:18:42.356465 16011 solver.cpp:218] Iteration 9696 (0.687756 iter/s, 17.4481s/12 iters), loss = 0.153347
I0422 02:18:42.356524 16011 solver.cpp:237]     Train net output #0: loss = 0.153347 (* 1 = 0.153347 loss)
I0422 02:18:42.356534 16011 sgd_solver.cpp:105] Iteration 9696, lr = 0.00146513
I0422 02:18:47.594667 16011 solver.cpp:218] Iteration 9708 (2.29095 iter/s, 5.23801s/12 iters), loss = 0.0160575
I0422 02:18:47.594815 16011 solver.cpp:237]     Train net output #0: loss = 0.0160573 (* 1 = 0.0160573 loss)
I0422 02:18:47.594828 16011 sgd_solver.cpp:105] Iteration 9708, lr = 0.00146165
I0422 02:18:48.353622 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:18:52.873241 16011 solver.cpp:218] Iteration 9720 (2.27346 iter/s, 5.2783s/12 iters), loss = 0.0277667
I0422 02:18:52.873286 16011 solver.cpp:237]     Train net output #0: loss = 0.0277665 (* 1 = 0.0277665 loss)
I0422 02:18:52.873296 16011 sgd_solver.cpp:105] Iteration 9720, lr = 0.00145818
I0422 02:18:58.006861 16011 solver.cpp:218] Iteration 9732 (2.33761 iter/s, 5.13344s/12 iters), loss = 0.0253291
I0422 02:18:58.006901 16011 solver.cpp:237]     Train net output #0: loss = 0.0253289 (* 1 = 0.0253289 loss)
I0422 02:18:58.006911 16011 sgd_solver.cpp:105] Iteration 9732, lr = 0.00145472
I0422 02:19:03.188947 16011 solver.cpp:218] Iteration 9744 (2.31575 iter/s, 5.18191s/12 iters), loss = 0.056572
I0422 02:19:03.188988 16011 solver.cpp:237]     Train net output #0: loss = 0.0565718 (* 1 = 0.0565718 loss)
I0422 02:19:03.188998 16011 sgd_solver.cpp:105] Iteration 9744, lr = 0.00145127
I0422 02:19:08.350080 16011 solver.cpp:218] Iteration 9756 (2.32515 iter/s, 5.16096s/12 iters), loss = 0.0344082
I0422 02:19:08.350121 16011 solver.cpp:237]     Train net output #0: loss = 0.034408 (* 1 = 0.034408 loss)
I0422 02:19:08.350129 16011 sgd_solver.cpp:105] Iteration 9756, lr = 0.00144782
I0422 02:19:13.496096 16011 solver.cpp:218] Iteration 9768 (2.33198 iter/s, 5.14585s/12 iters), loss = 0.044023
I0422 02:19:13.496134 16011 solver.cpp:237]     Train net output #0: loss = 0.0440229 (* 1 = 0.0440229 loss)
I0422 02:19:13.496143 16011 sgd_solver.cpp:105] Iteration 9768, lr = 0.00144438
I0422 02:19:18.609023 16011 solver.cpp:218] Iteration 9780 (2.34707 iter/s, 5.11275s/12 iters), loss = 0.0268628
I0422 02:19:18.609174 16011 solver.cpp:237]     Train net output #0: loss = 0.0268626 (* 1 = 0.0268626 loss)
I0422 02:19:18.609186 16011 sgd_solver.cpp:105] Iteration 9780, lr = 0.00144095
I0422 02:19:23.519973 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_9792.caffemodel
I0422 02:19:29.371747 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_9792.solverstate
I0422 02:19:37.915755 16011 solver.cpp:330] Iteration 9792, Testing net (#0)
I0422 02:19:37.915773 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:19:38.515009 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:19:42.411096 16011 solver.cpp:397]     Test net output #0: accuracy = 0.476716
I0422 02:19:42.411141 16011 solver.cpp:397]     Test net output #1: loss = 3.12699 (* 1 = 3.12699 loss)
I0422 02:19:42.506716 16011 solver.cpp:218] Iteration 9792 (0.502155 iter/s, 23.897s/12 iters), loss = 0.0547925
I0422 02:19:42.506757 16011 solver.cpp:237]     Train net output #0: loss = 0.0547923 (* 1 = 0.0547923 loss)
I0422 02:19:42.506765 16011 sgd_solver.cpp:105] Iteration 9792, lr = 0.00143753
I0422 02:19:46.886215 16011 solver.cpp:218] Iteration 9804 (2.74014 iter/s, 4.37934s/12 iters), loss = 0.0217642
I0422 02:19:46.886260 16011 solver.cpp:237]     Train net output #0: loss = 0.021764 (* 1 = 0.021764 loss)
I0422 02:19:46.886269 16011 sgd_solver.cpp:105] Iteration 9804, lr = 0.00143412
I0422 02:19:50.046859 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:19:52.293715 16011 solver.cpp:218] Iteration 9816 (2.21921 iter/s, 5.40732s/12 iters), loss = 0.0129426
I0422 02:19:52.293753 16011 solver.cpp:237]     Train net output #0: loss = 0.0129424 (* 1 = 0.0129424 loss)
I0422 02:19:52.293762 16011 sgd_solver.cpp:105] Iteration 9816, lr = 0.00143072
I0422 02:19:57.832270 16011 solver.cpp:218] Iteration 9828 (2.1667 iter/s, 5.53837s/12 iters), loss = 0.112998
I0422 02:19:57.832310 16011 solver.cpp:237]     Train net output #0: loss = 0.112998 (* 1 = 0.112998 loss)
I0422 02:19:57.832319 16011 sgd_solver.cpp:105] Iteration 9828, lr = 0.00142732
I0422 02:20:03.095825 16011 solver.cpp:218] Iteration 9840 (2.2799 iter/s, 5.26338s/12 iters), loss = 0.0657918
I0422 02:20:03.095865 16011 solver.cpp:237]     Train net output #0: loss = 0.0657916 (* 1 = 0.0657916 loss)
I0422 02:20:03.095875 16011 sgd_solver.cpp:105] Iteration 9840, lr = 0.00142393
I0422 02:20:08.378533 16011 solver.cpp:218] Iteration 9852 (2.27164 iter/s, 5.28253s/12 iters), loss = 0.033768
I0422 02:20:08.378580 16011 solver.cpp:237]     Train net output #0: loss = 0.0337679 (* 1 = 0.0337679 loss)
I0422 02:20:08.378592 16011 sgd_solver.cpp:105] Iteration 9852, lr = 0.00142055
I0422 02:20:13.607273 16011 solver.cpp:218] Iteration 9864 (2.29509 iter/s, 5.22856s/12 iters), loss = 0.0329888
I0422 02:20:13.607322 16011 solver.cpp:237]     Train net output #0: loss = 0.0329886 (* 1 = 0.0329886 loss)
I0422 02:20:13.607332 16011 sgd_solver.cpp:105] Iteration 9864, lr = 0.00141718
I0422 02:20:18.819044 16011 solver.cpp:218] Iteration 9876 (2.30256 iter/s, 5.21159s/12 iters), loss = 0.0495945
I0422 02:20:18.819092 16011 solver.cpp:237]     Train net output #0: loss = 0.0495943 (* 1 = 0.0495943 loss)
I0422 02:20:18.819100 16011 sgd_solver.cpp:105] Iteration 9876, lr = 0.00141381
I0422 02:20:24.109454 16011 solver.cpp:218] Iteration 9888 (2.26834 iter/s, 5.29022s/12 iters), loss = 0.0496031
I0422 02:20:24.109609 16011 solver.cpp:237]     Train net output #0: loss = 0.049603 (* 1 = 0.049603 loss)
I0422 02:20:24.109623 16011 sgd_solver.cpp:105] Iteration 9888, lr = 0.00141045
I0422 02:20:26.312780 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_9894.caffemodel
I0422 02:20:29.923334 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_9894.solverstate
I0422 02:20:33.781160 16011 solver.cpp:330] Iteration 9894, Testing net (#0)
I0422 02:20:33.781188 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:20:34.278043 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:20:38.403257 16011 solver.cpp:397]     Test net output #0: accuracy = 0.479779
I0422 02:20:38.403308 16011 solver.cpp:397]     Test net output #1: loss = 3.07158 (* 1 = 3.07158 loss)
I0422 02:20:40.302119 16011 solver.cpp:218] Iteration 9900 (0.741101 iter/s, 16.1921s/12 iters), loss = 0.0402221
I0422 02:20:40.302160 16011 solver.cpp:237]     Train net output #0: loss = 0.0402219 (* 1 = 0.0402219 loss)
I0422 02:20:40.302167 16011 sgd_solver.cpp:105] Iteration 9900, lr = 0.00140711
I0422 02:20:45.560580 16011 solver.cpp:218] Iteration 9912 (2.28211 iter/s, 5.25828s/12 iters), loss = 0.0235143
I0422 02:20:45.560631 16011 solver.cpp:237]     Train net output #0: loss = 0.0235142 (* 1 = 0.0235142 loss)
I0422 02:20:45.560643 16011 sgd_solver.cpp:105] Iteration 9912, lr = 0.00140377
I0422 02:20:45.677793 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:20:50.884088 16011 solver.cpp:218] Iteration 9924 (2.25423 iter/s, 5.32332s/12 iters), loss = 0.0378566
I0422 02:20:50.884142 16011 solver.cpp:237]     Train net output #0: loss = 0.0378564 (* 1 = 0.0378564 loss)
I0422 02:20:50.884155 16011 sgd_solver.cpp:105] Iteration 9924, lr = 0.00140043
I0422 02:20:56.055258 16011 solver.cpp:218] Iteration 9936 (2.32064 iter/s, 5.17098s/12 iters), loss = 0.056882
I0422 02:20:56.055380 16011 solver.cpp:237]     Train net output #0: loss = 0.0568818 (* 1 = 0.0568818 loss)
I0422 02:20:56.055393 16011 sgd_solver.cpp:105] Iteration 9936, lr = 0.00139711
I0422 02:21:01.168030 16011 solver.cpp:218] Iteration 9948 (2.34718 iter/s, 5.11252s/12 iters), loss = 0.0969088
I0422 02:21:01.168085 16011 solver.cpp:237]     Train net output #0: loss = 0.0969087 (* 1 = 0.0969087 loss)
I0422 02:21:01.168098 16011 sgd_solver.cpp:105] Iteration 9948, lr = 0.00139379
I0422 02:21:06.465224 16011 solver.cpp:218] Iteration 9960 (2.26543 iter/s, 5.297s/12 iters), loss = 0.0225642
I0422 02:21:06.465270 16011 solver.cpp:237]     Train net output #0: loss = 0.022564 (* 1 = 0.022564 loss)
I0422 02:21:06.465279 16011 sgd_solver.cpp:105] Iteration 9960, lr = 0.00139048
I0422 02:21:11.632771 16011 solver.cpp:218] Iteration 9972 (2.32226 iter/s, 5.16737s/12 iters), loss = 0.0465792
I0422 02:21:11.632810 16011 solver.cpp:237]     Train net output #0: loss = 0.0465791 (* 1 = 0.0465791 loss)
I0422 02:21:11.632818 16011 sgd_solver.cpp:105] Iteration 9972, lr = 0.00138718
I0422 02:21:17.024544 16011 solver.cpp:218] Iteration 9984 (2.22569 iter/s, 5.39159s/12 iters), loss = 0.0144263
I0422 02:21:17.024585 16011 solver.cpp:237]     Train net output #0: loss = 0.0144261 (* 1 = 0.0144261 loss)
I0422 02:21:17.024595 16011 sgd_solver.cpp:105] Iteration 9984, lr = 0.00138389
I0422 02:21:21.746690 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_9996.caffemodel
I0422 02:21:25.990552 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_9996.solverstate
I0422 02:21:29.161376 16011 solver.cpp:330] Iteration 9996, Testing net (#0)
I0422 02:21:29.161468 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:21:29.692226 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:21:33.946254 16011 solver.cpp:397]     Test net output #0: accuracy = 0.481005
I0422 02:21:33.946302 16011 solver.cpp:397]     Test net output #1: loss = 3.05919 (* 1 = 3.05919 loss)
I0422 02:21:34.042076 16011 solver.cpp:218] Iteration 9996 (0.705174 iter/s, 17.0171s/12 iters), loss = 0.0595506
I0422 02:21:34.042146 16011 solver.cpp:237]     Train net output #0: loss = 0.0595504 (* 1 = 0.0595504 loss)
I0422 02:21:34.042161 16011 sgd_solver.cpp:105] Iteration 9996, lr = 0.0013806
I0422 02:21:38.454613 16011 solver.cpp:218] Iteration 10008 (2.71964 iter/s, 4.41235s/12 iters), loss = 0.0137177
I0422 02:21:38.454663 16011 solver.cpp:237]     Train net output #0: loss = 0.0137175 (* 1 = 0.0137175 loss)
I0422 02:21:38.454674 16011 sgd_solver.cpp:105] Iteration 10008, lr = 0.00137732
I0422 02:21:40.962152 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:21:43.827338 16011 solver.cpp:218] Iteration 10020 (2.23358 iter/s, 5.37253s/12 iters), loss = 0.0690147
I0422 02:21:43.827389 16011 solver.cpp:237]     Train net output #0: loss = 0.0690145 (* 1 = 0.0690145 loss)
I0422 02:21:43.827399 16011 sgd_solver.cpp:105] Iteration 10020, lr = 0.00137405
I0422 02:21:49.102037 16011 solver.cpp:218] Iteration 10032 (2.27509 iter/s, 5.27451s/12 iters), loss = 0.0524521
I0422 02:21:49.102082 16011 solver.cpp:237]     Train net output #0: loss = 0.0524519 (* 1 = 0.0524519 loss)
I0422 02:21:49.102092 16011 sgd_solver.cpp:105] Iteration 10032, lr = 0.00137079
I0422 02:21:54.446842 16011 solver.cpp:218] Iteration 10044 (2.24525 iter/s, 5.34462s/12 iters), loss = 0.0144953
I0422 02:21:54.446888 16011 solver.cpp:237]     Train net output #0: loss = 0.0144951 (* 1 = 0.0144951 loss)
I0422 02:21:54.446897 16011 sgd_solver.cpp:105] Iteration 10044, lr = 0.00136754
I0422 02:21:59.792460 16011 solver.cpp:218] Iteration 10056 (2.2449 iter/s, 5.34544s/12 iters), loss = 0.0566662
I0422 02:21:59.792621 16011 solver.cpp:237]     Train net output #0: loss = 0.056666 (* 1 = 0.056666 loss)
I0422 02:21:59.792631 16011 sgd_solver.cpp:105] Iteration 10056, lr = 0.00136429
I0422 02:22:04.905478 16011 solver.cpp:218] Iteration 10068 (2.34708 iter/s, 5.11273s/12 iters), loss = 0.0466657
I0422 02:22:04.905521 16011 solver.cpp:237]     Train net output #0: loss = 0.0466656 (* 1 = 0.0466656 loss)
I0422 02:22:04.905529 16011 sgd_solver.cpp:105] Iteration 10068, lr = 0.00136105
I0422 02:22:10.018343 16011 solver.cpp:218] Iteration 10080 (2.3471 iter/s, 5.11269s/12 iters), loss = 0.0349168
I0422 02:22:10.018384 16011 solver.cpp:237]     Train net output #0: loss = 0.0349166 (* 1 = 0.0349166 loss)
I0422 02:22:10.018393 16011 sgd_solver.cpp:105] Iteration 10080, lr = 0.00135782
I0422 02:22:15.244815 16011 solver.cpp:218] Iteration 10092 (2.29608 iter/s, 5.2263s/12 iters), loss = 0.0198872
I0422 02:22:15.244859 16011 solver.cpp:237]     Train net output #0: loss = 0.0198871 (* 1 = 0.0198871 loss)
I0422 02:22:15.244868 16011 sgd_solver.cpp:105] Iteration 10092, lr = 0.0013546
I0422 02:22:17.302889 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_10098.caffemodel
I0422 02:22:20.278626 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_10098.solverstate
I0422 02:22:22.552076 16011 solver.cpp:330] Iteration 10098, Testing net (#0)
I0422 02:22:22.552095 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:22:23.001101 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:22:27.102543 16011 solver.cpp:397]     Test net output #0: accuracy = 0.474877
I0422 02:22:27.102579 16011 solver.cpp:397]     Test net output #1: loss = 3.07507 (* 1 = 3.07507 loss)
I0422 02:22:29.228662 16011 solver.cpp:218] Iteration 10104 (0.858156 iter/s, 13.9835s/12 iters), loss = 0.0290568
I0422 02:22:29.228701 16011 solver.cpp:237]     Train net output #0: loss = 0.0290566 (* 1 = 0.0290566 loss)
I0422 02:22:29.228710 16011 sgd_solver.cpp:105] Iteration 10104, lr = 0.00135138
I0422 02:22:33.707870 16030 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:22:34.349391 16011 solver.cpp:218] Iteration 10116 (2.34349 iter/s, 5.12056s/12 iters), loss = 0.0366711
I0422 02:22:34.349434 16011 solver.cpp:237]     Train net output #0: loss = 0.0366709 (* 1 = 0.0366709 loss)
I0422 02:22:34.349442 16011 sgd_solver.cpp:105] Iteration 10116, lr = 0.00134817
I0422 02:22:39.513058 16011 solver.cpp:218] Iteration 10128 (2.32401 iter/s, 5.16349s/12 iters), loss = 0.00638939
I0422 02:22:39.513103 16011 solver.cpp:237]     Train net output #0: loss = 0.00638923 (* 1 = 0.00638923 loss)
I0422 02:22:39.513110 16011 sgd_solver.cpp:105] Iteration 10128, lr = 0.00134497
I0422 02:22:44.918344 16011 solver.cpp:218] Iteration 10140 (2.22012 iter/s, 5.4051s/12 iters), loss = 0.0545988
I0422 02:22:44.918385 16011 solver.cpp:237]     Train net output #0: loss = 0.0545986 (* 1 = 0.0545986 loss)
I0422 02:22:44.918393 16011 sgd_solver.cpp:105] Iteration 10140, lr = 0.00134178
I0422 02:22:49.956754 16011 solver.cpp:218] Iteration 10152 (2.38179 iter/s, 5.03824s/12 iters), loss = 0.0646202
I0422 02:22:49.956796 16011 solver.cpp:237]     Train net output #0: loss = 0.06462 (* 1 = 0.06462 loss)
I0422 02:22:49.956805 16011 sgd_solver.cpp:105] Iteration 10152, lr = 0.00133859
I0422 02:22:55.304924 16011 solver.cpp:218] Iteration 10164 (2.24383 iter/s, 5.34799s/12 iters), loss = 0.0564841
I0422 02:22:55.304966 16011 solver.cpp:237]     Train net output #0: loss = 0.0564839 (* 1 = 0.0564839 loss)
I0422 02:22:55.304976 16011 sgd_solver.cpp:105] Iteration 10164, lr = 0.00133541
I0422 02:23:00.385617 16011 solver.cpp:218] Iteration 10176 (2.36196 iter/s, 5.08052s/12 iters), loss = 0.0416516
I0422 02:23:00.385660 16011 solver.cpp:237]     Train net output #0: loss = 0.0416514 (* 1 = 0.0416514 loss)
I0422 02:23:00.385668 16011 sgd_solver.cpp:105] Iteration 10176, lr = 0.00133224
I0422 02:23:05.533035 16011 solver.cpp:218] Iteration 10188 (2.33135 iter/s, 5.14723s/12 iters), loss = 0.0442659
I0422 02:23:05.549590 16011 solver.cpp:237]     Train net output #0: loss = 0.0442657 (* 1 = 0.0442657 loss)
I0422 02:23:05.549605 16011 sgd_solver.cpp:105] Iteration 10188, lr = 0.00132908
I0422 02:23:10.389766 16011 solver.cpp:447] Snapshotting to binary proto file snapshot_iter_10200.caffemodel
I0422 02:23:13.345336 16011 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshot_iter_10200.solverstate
I0422 02:23:15.687561 16011 solver.cpp:310] Iteration 10200, loss = 0.0427225
I0422 02:23:15.687593 16011 solver.cpp:330] Iteration 10200, Testing net (#0)
I0422 02:23:15.687602 16011 net.cpp:676] Ignoring source layer train-data
I0422 02:23:16.125723 16055 data_layer.cpp:73] Restarting data prefetching from start.
I0422 02:23:20.225283 16011 solver.cpp:397]     Test net output #0: accuracy = 0.47549
I0422 02:23:20.225313 16011 solver.cpp:397]     Test net output #1: loss = 3.093 (* 1 = 3.093 loss)
I0422 02:23:20.225318 16011 solver.cpp:315] Optimization Done.
I0422 02:23:20.225322 16011 caffe.cpp:259] Optimization Done.
